Isaac Asimov

INTRODUCCIÓN

Primera parte

II. E PLURIBUS UNUM

III. LAS DOS MASAS

IV. EL GENERAL VICTORIOSO

Segunda parte

VI. EL BRAZO DEL GIGANTE

VII. EL MUNDO DEL SOL ROJO

VIII. EL AMOR HACE GIRAR EL MUNDO

Tercera parte

X. VERDE, VERDE, VERDE ES EL COLOR...

Cuarta parte

XII. VOLVIENDO AL PUNTO DE PARTIDA

Quinta Parte

XIV. DONDE TODO EL CIELO ES RESPLANDOR

50. FINAL

XV. ¡ARRIBA!

Sexta parte

1. AÑO DE ESTADOS UNIDOS

2. EL AÑO DE NORTEAMÉRICA

3. AÑO DE LA HISTORIA

4. EL AÑO DE LA CIVILIZACIÓN

5.EL AÑO HUMANO

6. EL AÑO HOMÍNIDO

7. EL AÑO FÓSIL

8. EL AÑO TERRESTRE

XVII. LOS DIFERENTES AÑOS DEL UNIVERSO

9. EL AÑO DEL UNIVERSO

10. AÑO DEL SISTEMA SOLAR

11. EL AÑO SOLAR

12. EL AÑO DE LA ENANA ROJA





* * *





Isaac Asimov



El monstruo subatómico





INTRODUCCIÓN





Con más de 300 libros publicados en mi haber, he tenido que aceptar el hecho de
que soy «un autor prolífico». Así es como, invariablemente, me llaman.

No estoy seguro de que, si me diesen a elegir, quisiese verme bendecido por esa
casi inevitable combinación de dos palabras. Supongo que resultaría más
agradable si, de una forma rutinaria, me llamasen, por ejemplo, «autor dotado»
o «estupendo escritor», o incluso «genio de la pluma». Desgraciadamente, todo
tiene el aspecto de que habrá una larga y fría espera antes de que se produzca
esa relación, por lo que aceptaré lo de «escritor prolífico».

Pero si pienso en ello, compruebo que existen ventajas en eso de ser un
«escritor prolífico». Para empezar, si eres un escritor prolífico, es
inevitable que te resulte fácil escribir. No se puede sufrir una agonía al ir
eligiendo cada palabra a cuentagotas y ser prolífico. Al mismo tiempo no
existen suficientes minutos en una hora para esto, ni tampoco el alma humana
puede aguantar tanto.

En realidad, escribir me es fácil, y disfruto también con ello. Disfruto
increíblemente, por lo que soy un hombre afortunado.

Y lo que es más, si eres un escritor prolífico, eres capaz de escribir con
rapidez. No tienes elección. Si lo deseas puedes escribir despacio. O puedes
dejar listos veintiún libros en un año (incluyendo, como es natural, algunos
relativamente pequeños), como hice en 1983. Lo que no se puede hacer es
escribir despacio veintiún libros en un año.

Pues si, puedo escribir con rapidez, con mucha rapidez. Escribo tan rápidamente
como tecleo y, con el procesador de texto, hago un centenar de palabras por
minuto (si no contamos el tiempo perdido en hacer correcciones). Escribir
deprisa es la mayor de mis ventajas.

Esto me lleva al aspecto sórdido de ser prolífico puesto que también tiene sus
desventajas, y su inconveniente mayor es que escribo muy deprisa. Sí, también
constituye una desventaja.

Como podrán ver por este libro que tienen en las manos (o por lo menos, después
de que hayan terminado de leerlo), escribo con aparente autoridad sobre una
amplia variedad de temas. Y si ha leído las más de dos docenas de otros libros
de ensayos científicos (por no mencionar los libros que he escrito acerca de
otros temas, desde comentarios a la Biblia a libros de humor), el ámbito aún
parecerá más asombroso.

Pues bien, si quiero librarme de esa aura de que lo sé todo, que cierto modo he
formado a mi alrededor, resulta absolutamente necesario que evite cometer
errores tontos. Y lo haría también, si fuera por el inconveniente de mi gran
velocidad al escribir. Accidentalmente, puedo decir algo ridículo y luego,
antes de que tenga oportunidad de verlo y decir: «¡Eh, esto está equivocado!»,
me encuentro en el párrafo siguiente con mi mente ocupada por completo en otra
cosa.

En el capitulo «Brazo del gigante» de este libro, calculé cuidadosamente el
tamaño de la estrella Betelgeuse por trigonometría, y debí de confundir el
radio con el diámetro, y acabé por hacer la estrella exactamente con un
diámetro el doble del que debería ser.

Envié «Brazo del gigante» a The Magazine of Fantasy and Science Fiction, que
imprimió estos artículos por primera vez, y luego, un mes más tarde, escribí
una continuación del tema, el capítulo titulado «El mundo del Sol Rojo».

Necesité de nuevo el tamaño de Betelgeuse, y me dio demasiada pereza mirar el
ensayo anterior. Simplemente, volví a calcularlo, y a vez no cometí el error y
obtuve la cifra exacta. Advertí que las dos cifras en los dos artículos no
coincidían. Naturalmente que no.

¿Cómo lo averigüé (dado que obviamente ahora lo sé)? ¡Muy fácil! En cuanto
apareció el primer ensayo en la revista, Mr. Jogn (sic) Fortier, descrito por
sí mismo como «un devoto y adicto lector», cogió la máquina de escribir para
señalar el error. Ni siquiera usó la trigonometría para este fin, sino unos
ordinarios cálculos aritméticos. (Yo hubiera podido hacer lo mismo, de haber
sido lo suficientemente listo.)

Y lo que es más, señaló algo todavía más ridículo que aparecía el mismo
artículo. Las cosas fueron así...

Yo deseaba mencionar el tamaño aparente de Júpiter, su «diámetro angular», tal
y como se ve desde la Tierra. Realmente no tenía la menor importancia para el
artículo, era sólo algo accesorio, cogido por los pelos. Comprobé el diámetro
angular de Júpiter, y el valor máximo, cuando se encuentra más cerca de la
Tierra, es de 50 segundos de arco.

¡Correcto! ¡ Muy bien! Excepto que de alguna manera, durante el tiempo
transcurrido entre que mis ojos abandonaron el libro de referencia y el momento
en que enfocaron la máquina de escribir, una extraña mutación cambió la frase
en mi cabeza por «50 minutos de arco»... Pero yo deseaba segundos de arco, y
sabía muy bien que cada minuto de arco equivale a 60 segundos de arco, por lo
que multipliqué 50 por 60 y, concienzudamente, mecanografié la afirmación que
el diámetro angular de Júpiter era de 3.000 segundos de arco.

Y así fue también como apareció en la revista. De haber dejado de escribir a
toda velocidad el tiempo suficiente para pensar durante un quinto de segundo,
hubiera recordado que la Luna tenía un diámetro angular de 30 minutos de arco,
o 1.800 segundos de arco, y que, por lo tanto, estaba proporcionando al
firmamento de la Tierra un Júpiter mucho más grande en apariencia que la Luna.

Mi rostro se tiñó del más bonito rojo cereza cuando Mr. Fortier lo indicó.
Naturalmente, eliminé al instante esta afirmación errónea, y en este libro
aparecen las cifras correctas.

O, también, en el capítulo titulado «Donde todo el firmamento es sol», al
principio hice la afirmación gratuita de que el oro, salvo por el valor
artificial que le concede la gente a causa de su belleza y rareza, era inútil,
que no tenía ningún uso que valiera la pena mencionar.

Al instante, dos queridos amigos míos, Lester del Rey (que se menciona en la
introducción del último capitulo) y Jay Kay Klein, me escribieron unas largas
cartas, haciendo una lista de toda clase de usos que tendría el oro en el caso
de que fuese más abundante y barato. Para este libro, eliminé esa ofensiva
frase como si se hubiera convertido en hierro candente en mis manos. Que en
cierto modo, era lo que había ocurrido.

Y así son las cosas. Puedo escribir con la rapidez con que lo hago porque tengo
unos lectores con vista de lince que comprueban cada una de las observaciones
que realizo y me informan de cada error y desliz al instante, para que pueda
corregirlo y aprender de mis errores.

¿Qué haría sin ellos? ¿Puedo aprovechar esta oportunidad para dar las gracias a
todos —a todos— quienes me han enviado una carta para corregirme y me han
ayudado a aprender? Déjenme también decir que todas las cartas de esta clase
que he recibido han sido, sin excepciones, redactadas en un tono de lo más
agradable y educado. Y también les doy a ustedes humildemente las gracias por
ello.





Primera parte





FÍSICA





I. EL MONSTRUO SUBATÓMICO





De vez en cuando me dicen que me he «equivocado de vocación». Naturalmente,
esto me lo dicen, como broma sin mala intención, y por lo general cuando he
dado una charla divertida o he cantado alguna canción cómica. Así pues, la idea
es que debería haber sido comediante o cantante, quizás.

Sin embargo, no puedo dejar pasar por alto esta observación, y, con la
experiencia, he descubierto que la respuesta más efectiva a ese «Has equivocado
tu vocación, Isaac», es:

—Lo sé, amigo mío, ¿pero quién quiere un viejo semental de cabello gris?

Pero nadie está a prueba de tonterías. He empleado esta réplica por lo menos
cincuenta veces con el mayor de los éxitos, pero hace unos cuantos días, al
intentarlo de nuevo, me llegó esta instantánea respuesta:

—¡Una vieja ninfomaníaca de cabello gris!

Y con esto me devolvieron la pelota elegantemente, y tuve que aguardar un buen
rato hasta que cesaron las risas. (Incluidas las mías).

Pero, en realidad, no he errado mi vocación, y todo el mundo lo sabe. Mi
vocación es ser escritor, y eso es lo que soy. En particular, mi vocación es
explicar, y eso es lo que hago también. Por lo tanto, si no les importa,
proseguiré con mi vocación.



Por ejemplo: ¿cómo se mide la energía?

Verán, el trabajo significa un gasto de energía, y, por así decirlo, no es otra
cosa que energía en acción. Una forma de definir el trabajo es decir que
implica el vencimiento de una resistencia a cierta distancia en particular. Se
vence la resistencia ejerciendo fuerza.

Por ejemplo, la atracción gravitatoria de la Tierra tiende a tener un objeto
sobre el suelo. Para levantarlo, hay que ejercer una fuerza que venza la
resistencia gravitatoria.

Cuanto mayor sea el peso del objeto a levantar, mayor será la fuerza que se
habrá de hacer y mayor el trabajo que se realiza. Cuanto más larga sea la
distancia en la que se alce el peso, más trabajo se efectuará. Así pues, el
trabajo (y la energía consumida), es igual a la fuerza por la distancia.

Si usted levanta un peso de 1 libra en una distancia de un pie (453,6 g x 30,48
cm), ha hecho 1 «pie-libra» de trabajo. (Observe se pone primero la distancia
en esta unidad de trabajo. No existe razón para no colocar primero el peso y
llamarlo 1 «libra-pie» pero nadie lo hace y en todos los idiomas y culturas la
explicación de «nadie lo hace» es la frase más sin respuesta que hay.)

Entonces, si usted pesa 150 libras y sube un tramo de escaleras que le hace
ascender 8 pies, habrá realizado 150 x 8, o 1.200 pies de trabajo. Dado que he
observado que, con frecuencia, un tramo de escaleras tiene 13 escalones, el
trabajo efectuado por alguien que pese 150 libras al subir un escalón es de
1.200/13, o sea 92,3 pies-libras.

Pero «pies» y «libras» son unidades del sistema común que los físicos miran con
desprecio. El sistema métrico decimal es utilizado universalmente fuera de
Estados Unidos, y los científicos lo emplean incluso en los Estados Unidos. La
unidad de distancia del sistema métrico es el metro, que equivale a 3,281 pies;
el kilogramo, que equivale a 2,2046 libras, se usa para el peso.

Una unidad de energía en el sistema métrico sería, pues, 1 «kilográmetro» (aquí
el peso está primero, y usted no dirá «metro-kilogramo» porque —todos a la vez—
«nadie lo hace»). Un kilográmetro es igual a 2,2046 libras por 3,281 pies, o
7,233 pies-libras. Por lo tanto, para una persona de 150 libras de peso, subir
un escalón de un tramo de escaleras significa efectuar 12,76 kilográmetros de
trabajo.



El empleo del peso como parte de una unidad de trabajo no es lo ideal. No es
erróneo hacerlo así, puesto que el peso es una fuerza, pero ése es precisamente
el problema. Las unidades empleadas popularmente para el peso (libras o
kilogramos) no son, estrictamente hablando, unidades de fuerza, sino unidades
de masa. La confusión surge porque el peso ha sido comprendido desde los
tiempos prehistóricos, en tanto que el concepto de masa fue aclarado por vez
primera por Isaac Newton y la masa es tan similar al peso en circunstancias
ordinarias, que incluso los científicos caen en la trampa de emplear las
unidades de peso, establecidas hace tanto tiempo, también como masa, creando
con ello la confusión.

Si nos olvidamos del peso y tratamos sólo con la masa, la definición de fuerza
(que surge de la segunda ley del movimiento de Newton) es la de masa
multiplicada por aceleración. Supongamos que imaginamos una fuerza capaz de
acelerar una masa de 1 kilogramo por una cantidad igual a 1 metro por segundo
cada segundo. Esa fuerza es igual a 1 kilográmetro por segundo cada segundo, o
(empleando abreviaciones) 1 kgm/seg2. Para mayor brevedad, a 1 kgm/seg2 se le
llama «1 newton» en honor del gran científico. Por lo tanto, la fuerza
requerida para levantar un peso de 1 kilogramo es de 9,8 newtons. Inversamente,
1 newton es la fuerza requerida para levantar un peso de 0,102 kilogramos.

Dado que trabajo es fuerza por distancia, la unidad de trabajo debería ser 1
newton de fuerza consumida en una distancia de 1 metro. Esto sería 1
newton-metro. Al newton-metro se le suele denominar «julio», por el físico
inglés James Prescott Joule, que realizó importantes trabajos sobre energía.
Por tanto, la unidad de trabajo es 1 julio, y puesto que el newton equivale a
un peso de 0,102 kilogramos, 1 julio es igual a 0,102 kilográmetros. Por
consiguiente, levantar 150 libras sobre un escalón de un tramo de escaleras
representa una cantidad de trabajo igual a 125 julios.

Como ven, el julio es una buena unidad de energía para la vida cotidiana, dado
que una acción corriente representa un número pequeño que se maneja con
facilidad.

Sin embargo, supongamos que se quiere tratar con cantidades de trabajo o de
energía mucho más pequeñas. Entonces se tendrían que utilizar diminutas
fracciones de un julio. Sería útil tener una unidad más pequeña.

En vez de una fuerza que imparte a un kilogramo una aceleración de 1 metro por
segundo cada segundo, imaginemos una fuerza que imparte a 1 gramo una
aceleración de 1 centímetro por segundo cada segundo. En ese caso se tendrá una
fuerza de 1 gramo-centímetro por segundo cada segundo, o 1 g.cm/seg2, que puede
definirse como «1 dina» (la primera sílaba de una palabra griega que significa
«poder»).

Dado que un gramo es 1/1.000 de un kilogramo, y un centímetro es 1/100 de un
metro, una fuerza de una dina produce 1/100 de la aceleración en 1/1.000 de la
masa, en comparación con la fuerza de 1 newton. Por consiguiente, 1 dina es
igual a 1/100 x 1/1.000, o 1/100.000 de newton. Es lo mismo que decir que 1
newton = 100.000 dinas.

Si suponemos que se gasta 1 dina en una distancia de 1 centímetro, esto nos da
como unidad de trabajo «1 dina-centímetro», o «ergio» (primera sílaba de una
voz griega que significa «trabajo»). Dado que un julio es el resultado de un
newton consumido una distancia de 1 metro, mientras que un ergio es el
resultado una dina (1/100.000 de un newton) gastada en una distancia de 1
centímetro (1/100 de un metro), 1 ergio es igual a 1/100.000 x 1/100, o
1/10.000.000 de un julio. Es lo mismo que decir que 1 julio = 10.000.000 ergios.

Una persona de 150 libras de peso que suba un escalón de un tramo de escaleras
realiza 13.000.000 de ergios de trabajo. Este número muy incómodo para la vida
corriente, pero muy manejable para científicos que trabajan con pequeñas
cantidades de energía.

Sin embargo, incluso el ergio es con mucho una unidad demasiado grande cuando
se tiene que tratar con átomos individuales y partículas subatómicas. Para
estas cosas, necesitamos una unidad aún más pequeña.



Así, en vez de emplear una masa de un kilogramo o un gramo, utilicemos la masa
más pequeña que definitivamente se sabe que existe. Se trata de la masa de un
electrón, que es de 0,00000000000000000000000000091095 gramos, o 9,1095 x 10-28
gramos. Para evitar todos estos ceros, podemos tomar la masa de un electrón
como igual a «1 electrón».

Un electrón lleva una carga eléctrica, y por tanto incluye una aceleración en
un campo eléctrico. Esta propiedad del campo eléctrico que induce una
aceleración es su voltaje, por lo que podemos suponer que un electrón recibe
una aceleración producida por 1 voltio





[1].

Dada la masa y la carga del electrón, el trabajo realizado cuando se le expone
a la aceleración producida por 1 voltio es «1 electrón-voltio». En forma
abreviada, es «1 eV».

Ésta es una unidad de trabajo verdaderamente muy pequeña.

En realidad, 1 electrón-voltio es igual a sólo un poco más de una billonésima
de ergio. Para ser más precisos, 1 electrón-voltio = 0,000000000016 ergios, o
1,6 x 1012 ergios. (A propósito, recuerden que todas las unidades de trabajo
sirven también como unidades de energía.)

Cabe decir que la masa es una forma de energía, una forma muy concentrada. Por
lo tanto, la masa puede expresarse en unidades de energía, pero la masa es una
energía tan concentrada, que las unidades de energía corrientes son incómodas
para emplearlas con respecto a masas ordinarias.

Por ejemplo, tomemos una masa de 1 gramo. No es mucho. Es sólo la masa de un
colibrí aún no crecido del todo. La energía equivalente de esta masa, según la
célebre ecuación de Albert Einstein, es e=mc2, donde e es la energía, m la masa
y e la velocidad de la luz. Estamos tomando la masa como 1 gramo, y la
velocidad de la luz es de 29.980.000.000 centímetros por segundo (una
combinación que nos dará la energía equivalente en ergios). La energía
contenida en 1 gramo de masa es, pues, 1 x 29.980.000.000 x 29.980.000.000 x
898.800.000.000.000.000.000 o bien 8,988 x 1020 ergios. Admitirán que es
muchísimo más fácil hablar de 1 gramo que de casi un cuatrillón de ergios.

Sin embargo, cuando volvemos al electrón las cosas se invierten. Cuando
multiplicamos la pequeña masa de un electrón, 9,1095 x 1028 gramos, por el
equivalente en energía de 1 gramo, que es 8,988 x 1020 ergios, el resultado es
el equivalente en energía de la masa de un electrón de 8,1876 x l0-7 ergios. En
otras palabras, el equivalente en energía de la masa de un electrón es un poco
menor que una millonésima de un ergio, la cual resulta difícil de manejar.

No obstante, si convertimos ese equivalente de energía en electrón-voltios, que
son mucho más diminutos que los ergios, el resultado será que el equivalente de
energía de la masa de un electrón es igual a, aproximadamente, 511.000
electrón-voltios.

Naturalmente, 511.000 puede aún considerarse un numero demasiado grande para
resultar cómodo, pero 1.000 electrón-voltios equivalen a 1 kilo-electrón-voltio
(keV), y 1.000.000 electrón-voltios es igual a 1 megaelectrón-voltio (MeV), por
lo que podemos decir que el equivalente de energía de la masa de un electrón es
aproximadamente igual a medio MeV.

El electrón (y su número opuesto, el positrón) posee, como ya he dicho antes,
las masas más pequeñas de cualquier objeto que, con certeza, sabemos que tiene
masa. Es posible incluso que no pueda existir ninguna masa menor que sea
todavía mayor que cero. Existe alguna posibilidad de que los varios neutrinos
puedan tener masas aún más pequeñas, masas tan pequeñas como de 40
electrón-voltios, pero eso hasta ahora no se ha demostrado.

¿Y qué hay de las partículas con más masa?

Los electrones constituyen las regiones exteriores de los átomos, pero protones
y neutrones forman los núcleos de los átomos, y los protones y neutrones tienen
bastante más masa que los electrones. Un protón posee el equivalente de energía
de 938.200.000 electrón-voltios, o 938,2 MeV, y eso es 1.836 veces más masa que
un electrón. El neutrón tiene un equivalente de energía de 939.500.000
electrón-voltios, o 939,5 MeV, y así tiene 1.838,5 veces más masa que el
electrón y 1,0014 veces más masa que el protón.

Una energía de 1.000.000.000 electrón-voltios es 1 giga-electrón-voltio (1
GeV), por lo que podemos decir que el protón y el neutrón están muy cerca de 1
GeV en equivalente de energía.

Existen partículas subatómicas con más masa que el protón y el neutrón. Por
ejemplo, la partícula W (algo de lo que quizás hablaré en un próximo ensayo) ha
sido descubierta recientemente y tiene aproximadamente 80 veces más masa que un
protón, por lo que su equivalente de energía es de unos 80 GeV, o bien
80.000.000.000 de electrón-voltios. Los núcleos de los elementos con más masa
poseen equivalentes de energía de casi 250 GeV, que es aún más de tres veces
mayor, pero esos núcleos son conglomerados de más de 250 partículas subatómicas.

Sin embargo, si deseamos un auténtico monstruo subatómico, deberemos realizar
primero una digresión.



Electricidad y magnetismo están íntimamente relacionados; en realidad, resultan
inseparables. Todo lo que posee un campo eléctrico tiene un campo magnético, y
viceversa. De hecho, los científicos normalmente hablan de un campo
electromagnético, más que de un campo eléctrico o magnético por separado.
Hablan de la luz como de una radiación electromagnética, y de la interacción
electromagnética como de una de las cuatro interacciones fundamentales de la
Naturaleza.

Naturalmente, pues, no resulta sorprendente que la electricidad y el
magnetismo, cuando se consideran por separado, muestren numerosas semejanzas.
Así, un imán tiene dos polos, que presentan extremos opuestos, por así decirlo,
de propiedades magnéticas Les llamados «polo norte» y «polo sur». Existe una
atracción entre los polos norte y sur, y una repulsión entre dos polos norte o
entre dos polos sur.

De forma semejante, un sistema eléctrico tiene dos extremo opuestos, que
llamamos «carga positiva» y «carga negativa» Existe una atracción entre una
carga positiva y otra negativa, una repulsión entre dos cargas positivas o
entre dos cargas negativas.

En cada caso, la atracción y la repulsión son de intensidades iguales, y tanto
la atracción como la repulsión se hallan en proporción inversa al cuadrado de
la distancia.

Sin embargo, queda una enorme diferencia de una clase.

Suponga que tiene una varilla de material aislante en la que, de una forma u
otra, ha producido en un extremo una carga negativa y en la otra, una carga
positiva. Así, pues, si se rompe la varilla por la mitad, una de esas mitades
tiene una carga completamente negativa, y la otra mitad es enteramente
positiva. Y lo que es más, existen partículas subatómicas, como los electrones,
que llevan sólo una carga negativa y otros, como los protones, que llevan sólo
una carga positiva.

No obstante, supongamos que tiene un imán largo, con un polo norte en un
extremo y un polo sur en el otro. Si lo rompemos por la mitad, ¿existe una
mitad enteramente polo norte y otra mitad enteramente polo sur?

¡No! Si se parte un imán en dos, la mitad del polo norte, al instante,
desarrolla un polo sur en donde se ha roto, mientras que mitad del polo sur
desarrolla en el punto de ruptura un polo norte. Es imposible hacer nada para
que cualquier objeto posea sólo 1 polo magnético; ambos están siempre
presentes. Incluso las partículas subatómicas que poseen una carga eléctrica y,
por ende, un campo magnético asociado, poseen un polo norte y un polo sur.

Tampoco parece que existan partículas subatómicas concretas que lleven solo
polos norte o sólo polos sur, aunque hay incontables partículas subatómicas que
llevan sólo cargas positivas o sólo cargas negativas. No parece existir algo,
en otras palabras, como un «monopolo magnético».

Hacia 1870, cuando el físico escocés James Clerk Maxwell elaboró por primera
vez las relaciones matemáticas que describían el campo electromagnético como un
fenómeno unificado, presentó el mundo con cuatro concisas ecuaciones que
parecían totalmente suficientes para el propósito para el que habían sido
ideadas. En caso de haber existido monopolos magnéticos, las cuatro ecuaciones
hubieran sido bellamente simétricas, con lo que electricidad y magnetismo
habrían representado una especie de imagen de espejo uno del otro. Sin embargo,
Maxwell dio por supuesto que los polos magnéticos siempre existían por parejas
mientras que las cargas eléctricas no, y esto, forzosamente, introducía una
asimetría.

A los científicos les disgustan las asimetrías, puesto que ofenden el sentido
estético e interfieren en la simplicidad (el desiderátum de la ciencia
perfecta), así que ha existido siempre una constante sensación de que el
monopolo debería existir; de que su no existencia representa un defecto en el
diseño cósmico.

Después de que fuese descubierto el electrón, se llegó a saber finalmente que
la carga eléctrica está cuantificada; es decir, que todas las cargas eléctricas
son múltiplos exactos de algún valor fundamental más pequeño.

Así, todos los electrones poseen una idéntica carga negativa y todos los
protones una carga positiva idéntica, y las dos clases de carga son exactamente
iguales la una a la otra en tamaño. Todos los otros objetos con carga conocidos
tienen una carga eléctrica que es exactamente igual a la del electrón, o a la
del protón, o es un múltiplo exacto de una u otra.

Se cree que los quarks tienen cargas iguales a 1/3 y 2/3 de la del electrón o
protón, pero los quarks no han sido nunca aislados; e incluso aunque lo fuesen,
esto meramente representaría que el valor fundamental más pequeño es un tercio
de lo que se creía que era. El principio de la cuantificación permanecería.

¿Por qué la carga eléctrica debe cuantificarse? ¿Por qué no podría existir en
un valor desigual, exactamente como lo hace la masa? A fin de cuentas, la masa
de un protón es un múltiplo enteramente desigual de la masa de un electrón.
¿Por qué no habría de ocurrir lo mismo con la carga?

En 1931, el físico inglés Paul A. M. Dirac planteó la cuestión de una forma
matemática, y llegó a la decisión de que esta cuantificación de la carga seria
una necesidad lógica si existiesen los monopolos magnéticos. En realidad, aun
cuando hubiese sólo un monopolo en algún lugar del Universo, la cuantificación
de la carga seria una necesidad.

Resulta tentador argumentar a la inversa, naturalmente: pues que la carga
eléctrica está cuantificada, los monopolos magnéticos deben existir en algún
lugar. Parecía acertado buscarlos.

Pero ¿dónde y cómo pueden encontrarse, si es que existen? Los físicos no lo
sabían y, lo que era peor, no estaban seguros de cuáles podrían ser las
propiedades de esos monopolos. Parece natural suponer que eran partículas con
bastante masa, porque no serlo no serían muy comunes y no podrían producirse
con facilidad en el laboratorio; y esto explicaría el por qué nadie había
tropezado con ellos de manera accidental.

No existió ninguna guía teórica hasta los años setenta, cuando había gente
elaborando algunas grandes teorías unificadas con propósito de combinar las
interacciones débiles, fuertes y electromagnéticas, todo ello bajo una simple
serie de ecuaciones (véase Contando los eones, del mismo autor.)

En 1974, un físico neerlandés, Gerardt Hooft, y un físico soviético, Alexandr
Poliakov, mostraron, de forma independiente que de las grandes teorías
unificadas podía deducirse que monopolos magnéticos debían existir, y que no
tienen meramente mucha masa, sino que son unos monstruos.

Aunque un monopolo sería aún más pequeño que un protón, envuelta en su pequeñez
podría haber una masa de entre diez trillones y diez cuatrillones de veces la
del protón. Si se encontrase en el extremo superior de este ámbito, un monopolo
tendría un equivalente en energía de 10.000.000.000.000.000.000.000.000.000
electrón-voltios (1028 eV).

¿Y qué cantidad sería eso en masa? Al parecer, un monopolo magnético podría
tener una masa de hasta 1,8 x 10-9 gramos. Esto equivale a la masa de 20
espermatozoides humanos, todos metidos en una sola partícula subatómica.

¿Cómo pueden formarse estos monstruos subatómicos? No existe modo alguno de que
los seres humanos puedan encerrar tanta energía en un volumen subatómico de
espacio, ni en actualidad ni en un futuro previsible. En realidad, no existe
ningún proceso natural que tenga lugar en alguna parte del Universo ahora (por
lo que sabemos) que pudiera crear una partícula con una masa tan monstruosa.

La única posibilidad es volver al Big Bang, o gran explosión inicial, cuando
las temperaturas eran increíblemente elevadas y las energías estaban
increíblemente concentradas (véase también el libro citado de Contando los
eones). Se calcula que los monopolos debieron formarse sólo 10-34 segundos
después del Big Bang. Después, el Universo habría sido demasiado frío y
demasiado grande para este propósito.

Probablemente, se formaron los monopolos norte y sur, quizás en cantidades
enormes. Probablemente, un gran número de ellos se aniquilaron los unos a los
otros, pero cierto número debió de sobrevivir, simplemente porque, por pura
casualidad, no llegaron a encontrar otros del tipo opuesto. Después de que los
monopolos sobrevivieran cierto tiempo, la firme expansión del Universo hizo
cada vez menos probable que se produjesen colisiones, y esto aseguró su
ulterior supervivencia. Por lo tanto, hoy existe cierto número de ellos
flotando en torno del Universo.

¿Cuántos? No demasiados, pues por encima de cierto número el efecto
gravitatorio de esas monstruosas partículas hubiera asegurado que el Universo,
antes de ahora, alcanzase un tamaño máximo y se derrumbase de nuevo por su
propio impulso gravitatorio. En otras palabras, podemos calcular una densidad
máxima de monopolos en el Universo simplemente reconociendo el hecho de que
nosotros mismos existimos.

Sin embargo, aunque en escaso número, un monopolo debería, de vez en cuando,
moverse en las proximidades de un aparato de grabación. ¿Cómo podría detectarse?

En un principio, los científicos, suponían que los monopolos se movían a casi
la velocidad de la luz, como lo hacen las partículas de rayos cósmicos; y como
las partículas de rayos cósmicos, los monopolos deberían estrellarse contra
otras partículas en su camino y producir una lluvia de radiación secundaria que
se podría detectar con facilidad, y a partir de la cual el mismo monopolo se
podría identificar.

Ahora que se cree que el monopolo es de una masa monstruosa, las cosas han
cambiado. Estos enormes monopolos no podrían acumular suficiente energía para
moverse muy rápidamente, y se estima que deben de viajar a una velocidad de un
par de centenares de kilómetros por segundo; es decir, menos de una milésima
parte de la velocidad de la luz. A tan bajas velocidades, los monopolos
simplemente se deslizarían al lado y a través de la materia, sin dejar ninguna
señal de la que hablar. Es posible que esto explique el que hasta aquí no se
hubieran descubierto los monopolos.

Bueno, entonces, ¿qué debe hacerse?

Un físico de la Universidad de Stanford, Blas Cabrera, tuvo una idea. Un imán
que impulse energía a través de una bobina de cable enviará una oleada de
corriente eléctrica a través de ese cable. (Esto se conoce desde hace un siglo
y medio.) ¿Por qué no instalar una bobina así y esperar? Tal vez pasaría un
monopolo magnético a través de la bobina y señalaría su paso mediante una
corriente eléctrica. Cabrera calculó las posibilidades de que esto sucediera
basándose en la densidad más alta del monopolo dado el hecho de que el Universo
existe, y decidió que semejante eventualidad podía ocurrir como promedio, cada
seis meses.

Por lo tanto, Cabrera instaló una bobina de metal de niobio, y la mantuvo a una
temperatura cercana al cero absoluto. En esas condiciones, el niobio es
superconductor y posee una resistencia cero ante una corriente eléctrica. Esto
significa que si de alguna forma comienza a fluir por el mismo una corriente,
esa corriente fluirá de manera indefinida. Un monopolo que pase a través de la
bobina no dará lugar a una oleada instantánea de corriente, sino una corriente
continua.

Naturalmente, una corriente podría ser iniciada por cualquier viejo campo
magnético que se encontrase cerca; el propio campo magnético de la Tierra, los
que son establecidos por cualquiera de los mecanismos técnicos que le rodean,
incluso por pedazos de metal que se estén moviendo porque se encuentran en el
bolsillo de alguien.

Por tanto, Cabrera colocó el carrete dentro de un globo de plomo
superconductor, el cual estaba dentro de un segundo globo plomo superconductor.
Los campos magnéticos ordinarios no traspasarían el plomo superconductor, pero
un monopolo magnético lo haría.

Aguardó durante cuatro meses y no sucedió nada. El nivel corriente, señalado en
un rollo móvil de papel, permaneció durante todo ese tiempo cerca de cero. Esto
en sí era bueno. Demostraba que había excluido con éxito los campos magnéticos
al azar.

Luego, a la 1:53 de la tarde del 14 de febrero de 1982, se produjo un flujo
repentino de electricidad, y en la cantidad exacta que cabría esperar si
hubiese pasado a través de allí un monopolo magnético.

Cabrera comprobó todas las posibles eventualidades que podían haber iniciado la
corriente sin la ayuda de un monopolo, y pudo encontrar nada. El monopolo
parecía la única alternativa posible.

Así pues, ¿se ha detectado el esquivo monopolo? En este caso se trata de una
notable proeza y de un fuerte apoyo a la gran teoría unificada.

Sin embargo, el problema es que no se repitió ese suceso único, y resulta
difícil basar algo en un solo caso.

Asimismo, la estimación de Cabrera del número de monopolos que están flotando
por ahí se basaba en el hecho de que el Universo se encuentra aún en expansión.
Algunas personas creen que existe una restricción más fuerte derivada de la
posibilidad de que esos monopolos que flotan por la galaxia borren el campo
magnético galáctico general. Puesto que el campo magnético galáctico aún existe
(aunque sea muy débil), esto podría establecer un valor máximo de la densidad
del monopolo aún mucho más bajo, tan bajo tal vez como 1/10.000 de la cifra de
Cabrera.

Si eso fuese así, cabría esperar que pasase un monopolo a través de su carrete
una vez cada 5.000 años como promedio. Y en este caso que hubiese pasado uno
después de esperar sólo cuatro meses es pedir una suerte excesiva, y se hace
difícil creer que se tratase de un monopolo.

Sólo se puede hacer una cosa, y los físicos lo están haciendo. Continúan sus
investigaciones. Cabrera está construyendo una versión mayor y mejor de su
mecanismo, lo cual incrementará en cincuenta veces sus posibilidades de hallar
un monopolo. Otros físicos están ideando otras formas de abordar su
descubrimiento.

En los próximos años, la búsqueda del monopolo aumentará enormemente en
intensidad, porque hay mucho en juego. Su descubrimiento definitivo nos
proporcionará una indicación de las propiedades del monstruo subatómico y de
sus números. Y a partir de ello, podemos aprender cosas acerca del principio
del Universo, por no hablar de su presente y de su futuro, algo que, en caso
contrario, tal vez jamás averiguaríamos.

Y, naturalmente, hay un Premio Nobel que está esperando a alguien.





II. E PLURIBUS UNUM





Mi querida esposa, Janet, es una auténtica escritora, que ya había vendido
bastante antes de conocerme. En la actualidad, ha publicado dos novelas (The
Second Experiment y The Last Immortal), bajo su nombre de soltera, J. O.
Jeppson, y ha colaborado conmigo en la antología de ciencia-ficción humorística
(incluyendo versos y chistes) titulada Laughing Space. Los tres libros han sido
publicados por Houghton Miffin. Además, Doubleday ha publicado un libro de sus
relatos cortos.

Y lo que es mejor aún, ha publicado un alegre libro de ciencia-ficción juvenil
que lleva el título de Norby, the Mixed-up Robot (Walker, 1983), en
colaboración conmigo, y la autoría incluso reconoce nuestro matrimonio. El
nombre de los autores es el de «Janet e lsaac Asimov». Es el primero de una
serie, y el segundo, Norby's Other Secret, se editó en 1984. Es agradable
vernos unidos así, en letras de molde.

En realidad, la unificación es muy agradable en numerosos campos. Los
norteamericanos están sin duda contentos de que trece Estados independientes
decidieran unirse en un solo Gobierno federal. Esto es lo que ha hecho de E
pluribus unum (en latín, «De muchos, uno») una frase tan asociada con los
Estados Unidos. Y a los científicos les gusta también la unidad, y les complace
mostrar que sucesos que pueden parecer totalmente distintos son, en realidad,
aspectos diferentes de un solo fenómeno.

Empecemos con la «acción a distancia».

Normalmente, si se quiere conseguir alguna acción como impartir movimiento a un
objeto que está en reposo, debe establecerse un contacto físico con el mismo,
directa o indirectamente. Se le puede golpear con la mano o con el pie, o con
un palo o una maza que se sostenga. Se puede sujetarlo en la mano mientras uno
hace que la mano se mueva, y luego soltarlo. Se puede arrojar un objeto de esta
manera y hacerlo chocar contra un segundo objeto, al que de este modo imparte
movimiento. En realidad, es posible mover un objeto y lograr que ese movimiento
se transmita, poco a poco, a numerosos objetos (como al caer una hilera de
fichas de dominó). Se puede también soplar, consiguiendo que el aire se mueva
y, gracias a su impacto, que se desplace otra cosa.

Sin embargo, ¿podría conseguirse que un objeto distante se moviera sin tocarlo,
y sin permitir que algo que usted haya tocado previamente lo toque? En ese
caso, tendríamos una acción a distancia.

Por ejemplo, supongamos que usted sostiene una bola de billar a la altura de
los ojos sobre el suelo. Usted la sujeta bien para que esté perfectamente
inmóvil y luego, de repente, la suelta. Usted la ha estado tocando,
ciertamente, pero al soltarla ha dejado de tocarla. Sólo después de dejar de
tocarla cae al suelo. Ha sido movida sin que hubiera ningún contacto físico.

La Tierra atrae la bola, y a esto le llamamos «gravitación». La gravitación
parece ser un ejemplo de acción a distancia.

O pensemos en la Luz. Si sale el Sol, o se enciende una lámpara, una habitación
queda iluminada al instante. El sol o la lámpara originan la iluminación sin
que nada material parezca intervenir en el proceso. Y esto también parece una
acción a distancia. Digamos de paso que la sensación de calor que producen el
Sol o la lámpara puede sentirse a cierta distancia. Y éste es otro ejemplo.

También se cree que hacia el año 600 a. de C., el filósofo griego Tales
(624-546 a. de C.) estudió, por primera vez, una piedra negra que poseía la
capacidad de atraer objetos de hierro a distancia. Dado que la piedra en
cuestión procedía de los alrededores de la ciudad griega de Magnesia, en la
costa de Asia Menor, Tales la llamó ho magnetes lithos («la piedra magnésica»)
y el efecto se ha llamado desde entonces «magnetismo».

Tales descubrió asimismo que si se frota una varilla de ámbar, ésta puede
atraer objetos ligeros a distancia. La varilla de ámbar atrae objetos que no se
ven afectados por un imán, por lo que constituye un fenómeno diferente. Dado
que la voz griega para ámbar es elektron, el efecto ha sido denominado desde
entonces «electricidad». El magnetismo y la electricidad parecen representar,
también, acciones a distancia.

Finalmente, tenemos el sonido y el olor. Si una campana suena a distancia,
usted la oye aunque no exista contacto físico entre la campana y usted. O
coloque un bisté encima de una llama y lo olerá a distancia.

Tenemos, pues, siete de estos fenómenos: gravitación, luz, calor, magnetismo,
electricidad, sonido y olor.

En realidad, los científicos se sienten incómodos con la noción de acción a
distancia. Existen tantos ejemplos de efectos que sólo pueden producirse con
alguna clase de contacto, que los pocos ejemplos que parecen omitir el contacto
suenan a falsos. Tal vez haya contacto, pero de una forma tan sutil que no lo
notamos.

El olor es el fenómeno de este tipo más fácil de explicar. El filete encima del
fuego chisporrotea y humea. Resulta obvio que se sueltan pequeñas partículas y
flotan en el aire. Cuando alcanzan la nariz de alguien, entran en acción con
sus membranas y son interpretadas como olor. Con el tiempo, esto se vio
confirmado por entero. El olor es un fenómeno que implica contacto, y no es una
acción a distancia.

En cuanto al sonido, el filósofo griego Aristóteles (384-322 a. de C.), hacia
el año 350 a. de C., tras haber observado que los objetos que emitían sonidos
vibraban, sugirió que las vibraciones golpean el aire que está inmediatamente a
su alrededor y lo hacen vibrar; este aire hace vibrar el aire que le rodea y
así sucesivamente, como una serie de invisibles fichas de dominó. Al final, la
vibración progresiva alcanza el oído y lo hace vibrar, y así oímos el sonido.

En esto, como en realidad sucedió, Aristóteles estaba perfectamente en lo
cierto: pero ¿cómo podía probarse su sugerencia? Si el sonido es conducido por
el aire, no debería transmitirse en el caso de que no hubiera ya aire. Si una
campana suena en el vacío, no debería emitir ningún sonido. El problema era que
ni Aristóteles ni nadie más de su tiempo, ni durante casi dos mil años después,
pudo producir el vacío y probar el asunto.

En 1644, el físico italiano Evangelista Torricelli (1608-47) puso un largo tubo
lleno de mercurio en posición vertical en un plato con mercurio, y vio que se
derramaba un poco del mismo. El peso de la atmósfera de la Tierra sólo sostenía
76 cm de mercurio. Cuando el mercurio se derramó, dejó detrás, entre el nivel
sumergido y el extremo cerrado del tubo, un espacio que no contenía nada, ni
siquiera aire; por lo menos, nada excepto algunas pequeñas trazas de vapor de
mercurio. De esta forma, los seres humanos consiguieron el primer vacío
decente, pero se trataba de uno muy pequeño, cerrado y no demasiado útil para
la experimentación.

Unos años más tarde, en 1650, el físico Otto von Guericke (1602-86) inventó un
artilugio mecánico que, poco a poco, succionaba al exterior el aire de un
contenedor. Esto le permitió conseguir un vacío a voluntad. Por primera vez,
los físicos fueron capaces de experimentar con vacíos.

En 1657, el físico irlandés Robert Boyle (1627-91) oyó hablar de la bomba de
aire de Guericke, y consiguió que su ayudante, Robert Hooke (1635-1703), ideara
una mejor. En poco tiempo demostró que una campana que se hacía sonar dentro de
un contenedor de cristal en el que se había hecho el vacío, no emitía ningún
sonido. En cuanto se permitía que el aire entrara en el recipiente, la campana
sonaba. Aristóteles tenía razón, y el sonido, al igual que el olor, no
representaba una acción a distancia.

(No obstante, tres siglos y cuarto después, los que hacen películas aún
permiten a las naves espaciales avanzar a través del espacio con un zumbido y
estallar con estrépito. Supongo que, o bien los que hacen películas son
ignorantes, o, más probablemente, dan por supuesto que el público lo es y creen
que tienen un derecho divino para proteger y preservar esa ignorancia.)

La cuestión es, por lo tanto qué fenómenos se harán sentir por sí mismos a
través de un vacío. El hecho de que la presión del aire sólo sostenga una
columna de mercurio de 76 cm de altura significa que el aire únicamente puede
extenderse unos cuantos kilómetros por encima de la superficie de la Tierra. A
partir de una altura de unos 16 kilómetros, sólo quedan unas relativamente
delgadas volutas de aire. Esto significa que el espacio de 150.000.000 de
kilómetros que hay entre el Sol y la Tierra no es virtualmente, más que, vacío,
y sin embargo sentimos el calor del Sol y vemos su luz, mientras que la Tierra
responde a la atracción gravitatoria del Sol dando vueltas indefinidamente a su
alrededor. Y lo que es más, resultó tan fácil demostrar que un imán o un objeto
electrificado ejercía sus efectos a través de un vacío como el demostrar que
una campana que sonaba no lo hacía.

Esto nos deja cinco fenómenos que representan acción a distancia: luz, calor,
gravitación, magnetismo y electricidad.

No obstante, los científicos, todavía no estaban ansiosos por aceptar la acción
a distancia. El científico inglés Isaac Newton (1642-1727) sugirió que la luz
consistía en una pulverización de partículas muy finas que se movían
rígidamente en líneas rectas. La fuente luminosa emitiría las partículas y los
ojos las absorberían, en medio, la luz podría ser reflejada por algo y los ojos
verían ese algo por la luz reflejada. Dado que las partículas tocaban el objeto
y luego el ojo, no era una acción a distancia, sino una acción por contacto.

Esta teoría de las partículas de luz explicaba varias cosas, como el hecho de
que los objetos opacos arrojen sombras bien definidas. Sin embargo, dejaba
algunos interrogantes. ¿Por qué, la luz que pasaba a través de un prisma se
descomponía en un arco iris de colores? ¿Por qué las partículas de luz roja se
refractaban menos que las de la luz violeta? Había explicaciones para ello pero
no eran del todo convincentes.

En 1803, el científico inglés Thomas Young (1773-1829) llevó a cabo unos
experimentos que mostraban que la luz estaba formada por ondas (véase «X»
representa lo desconocido, del mismo autor). Las ondas tenían longitudes muy
diferentes; las de la luz roja eran el doble de largas que las de la luz
violeta, y la diferencia en la refracción se explicaba con facilidad de este
modo. La razón para las sombras bien definidas (las olas del mar y las ondas
del sonido no las arrojan) radica en que las longitudes de onda de la luz son
muy pequeñas. Incluso así, las sombras no están en realidad, perfectamente
definidas. Existe una pequeña borrosidad («difracción») y esto pudo demostrarse.

Las ondas de la luz hicieron volver a los físicos a la acción a distancia con
una venganza. Se podía afirmar que las ondas viajaban a través de un vacío...,
¿pero cómo? Las ondas del agua se propagan a través del movimiento de las
moléculas del agua superficial en ángulos rectos respecto a la dirección de
propagación (ondas transversales). Las ondas sonoras se propagan gracias al
movimiento de las partículas de aire hacia detrás y hacia delante, en la
dirección de propagación (ondas longitudinales). Pero cuando las ondas de la
luz viajan por el vacío, no existe material de ninguna clase que se mueva hacia
arriba y hacia abajo, hacia atrás o hacia delante. En ese caso, ¿cómo tiene
lugar la propagación?

La única conclusión a la que pudieron llegar los científicos fue que un vacío
no podía no contener nada; que contenía algo que subía y bajaba (se descubrió
que las ondas de la luz eran transversales, al igual que las ondas del agua).
Por lo tanto, postularon la existencia del «éter», una palabra pedida prestada
a Aristóteles. Se trataba de una sustancia tan fina y sutil que no se podía
detectar con los toscos métodos de la ciencia, sólo podía inferirse del
comportamiento de la luz. Permeabilizaba todo el espacio y la materia,
reduciendo lo que parecía acción a distancia a una acción por contacto: por
contacto etéreo.

(Finalmente se descubrió que el éter era un concepto innecesario, pero ésta es
otra historia. Por cuestión de comodidad, hablaré provisionalmente de los
diversos efectos que se dejan sentir a través de un vacío como «fenómenos
etéreos».)



Existen, pues, los cinco fenómenos etéreos que he mencionado anteriormente,
pero, ¿no podría haber más que llegasen a descubrirse, como la electricidad y
el magnetismo habían sido descubiertos por Tales? O, a la inversa, ¿no podrían
ser menos? ¿Podrían existir fenómenos etéreos que, aun pareciendo realmente
distintos, demostrasen ser idénticos al contemplarlos de una forma más
fundamental?

Por ejemplo, en 1800 el astrónomo germanobritánico William Herschel (1738-1822)
descubrió la radiación infrarroja: la radiación más allá del extremo rojo del
espectro. Los infrarrojos afectaban tan fuertemente a un termómetro que, al
principio, Herschel pensó que esa región invisible del espectro consistía en
«rayos de calor».

Sin embargo, no pasó mucho antes de que la teoría de las ondas de la luz
quedase establecida, y se comprendió que existía una extensión de la longitud
de onda mucho más amplia que la que el ojo humano estaba equipado para percibir.

Asimismo comenzó a comprenderse mejor el calor. Podía transmitirse por
conducción a través de la materia sólida, o por convección en corrientes de
líquido o gas en movimiento. Esto es una acción por medio de átomos o moléculas
en contacto. Cuando el calor se deja sentir a través de un vacío, no obstante,
con lo cual constituye un fenómeno etéreo, lo hace por la radiación de ondas de
luz, particularmente en el infrarrojo. Estas radiaciones no son en sí mismas
calor pero son únicamente percibidas como tales cuando son absorbidas por la
materia, y la energía así absorbida hace que los átomos y moléculas de esa
materia se muevan o vibren con mayor rapidez.

Por lo tanto, podemos ampliar el concepto de luz para que signifique todo el
espectro de ondas parecidas a la luz, puedan o no ser percibidas por el ojo, y
de este modo cabe incluir también el calor en su aspecto de radiaciones. La
lista de los fenómenos etéreos se reduce, pues, a cuatro: luz, gravitación,
magnetismo y electricidad.

¿Existe alguna posibilidad de reducir aún más esta lista? Todos los fenómenos
etéreos son similares en que cada uno de ellos tiene su origen en alguna fuente
e irradia hacia delante en todas direcciones por igual. Además, la intensidad
del fenómeno disminuye, en cada caso, con el cuadrado de la distancia desde el
origen.

Si uno se encuentra a una distancia dada de una fuente de luz y mide su
intensidad (la cantidad de luz que alcanza una unidad de área), y luego se
separa hasta que la distancia es de 2,512 veces la distancia original, la nueva
intensidad es 1/ 2,522, o 1/ 6,31 de lo que era la distancia original. Esta
regla de «la inversa del cuadrado» puede también demostrar ser cierta en la
intensidad de la gravitación, la electricidad y el magnetismo.

Pero esto tal vez no sea tan significativo como parece. Podríamos visualizar
cada uno de estos fenómenos como una radiación moviéndose hacia delante con
cierta velocidad fija en todos las direcciones por igual. Después de cualquier
lapso de tiempo concreto, el borde delantero de la ola en expansión ocupa todos
los puntos en el espacio que están a una distancia concreta de la fuente. Si se
conectan todos esos puntos, se hallará que se ha señalado la superficie de una
esfera. La superficie de una esfera aumenta con el cuadrado de su radio, es
decir, con el cuadrado de su distancia desde el punto central. Si una cantidad
fija de luz (o cualquier fenómeno etéreo) se esparce por la superficie de una
esfera en expansión, entonces cada vez que la superficie duplique el área, la
cantidad de luz disponible por unidad de área en esa superficie se reducirá a
la mitad. Puesto que el área superficial aumenta con el cuadrado de la
distancia desde la fuente, la intensidad de luz (o cualquier fenómeno etéreo)
disminuye con el cuadrado de la distancia desde la fuente.

Esto significa que los diversos fenómenos pueden ser, básicamente, diferentes
en propiedades y, sin embargo, parecerse unos a otros al seguir la ley de la
inversa del cuadrado. Pero ¿son los diversos fenómenos etéreos básicamente
diferentes?

Ciertamente así lo parecen. Gravitación, electricidad y magnetismo, todos se
hacen evidentes como una atracción. Esto los diferencia a los tres de la luz,
que no parece estar relacionada con la atracción.

En el caso de la gravitación, la atracción es el único efecto que puede
observarse. Sin embargo, en la electricidad y el magnetismo existe una
repulsión al igual que una atracción. Las cargas eléctricas se repelen
mutuamente, y lo mismo sucede con los polos magnéticos. No obstante,
electricidad y magnetismo no son tampoco idénticos, dado que el primero parece
capaz de atraer toda clase de materia, mientras que la atracción magnética
parece, en gran medida, limitarse sólo al hierro.

Así, en los años 1780, el físico francés Charles Augustin de Coulomb
(1736-1806), que ya había mostrado que tanto electricidad como magnetismo
seguían la ley de la inversa del cuadrado, argumentó de forma convincente que
ambos podrían ser similares en esto, pero que eran fundamentalmente diferentes
en lo esencial. Esto se convirtió en la opinión ortodoxa.



Pero incluso mientras Coulomb estaba planteando su ortodoxia, se estaba
produciendo una revolución en el estudio de la electricidad.

Hasta entonces se había estado estudiando la «electrostática», la carga
eléctrica más o menos inmóvil en el cristal, el azufre, el ámbar y en otros
materiales que hoy se conocen como no conductores. Se observaron efectos
característicos cuando el contenido eléctrico de tales objetos se descargaba y
se hacía pasar toda la carga o a través de una brecha de aire, por ejemplo,
para producir una chispa y un crujido, o en un cuerpo humano para producir un
choque eléctrico mucho más desagradable.

En 1791, el físico italiano Luigi Galvani (1737-98) descubrió que los efectos
eléctricos podían producirse cuando dos metales diferentes entraban en
contacto. En 1800 este asunto fue llevado más allá por el físico italiano
Alessandro Volta (1745-1827), que utilizó una serie (o «batería») de contactos
de dos metales para producir un flujo continuo de electricidad. En un abrir y
cerrar de ojos, todos los físicos de Europa se pusieron a estudiar
«electrodinámica».

Sin embargo, este descubrimiento hizo que la electricidad y el magnetismo
parecieran más diferentes que nunca. Era fácil producir una corriente de cargas
eléctricas móviles, pero ningún fenómeno análogo se observaba con los polos
magnéticos.

Un físico danés, Hans Christian Oersted (1777-1851), vio las cosas de modo
diferente. Adoptado el punto de vista minoritario, mantuvo que existía una
conexión entre electricidad y magnetismo. Una corriente eléctrica a través de
un cable desarrollaba calor; si el cable era delgado, incluso desarrollaba luz.
¿No podía ser —argumentó Oersted en 1813, —que si el cable fuese aún más
delgado, la electricidad obligada a pasar a través de él produjese efectos
magnéticos?

Sin embargo, Oersted pasaba tanto tiempo enseñando en la Universidad de
Copenhague, que le quedaba muy poco para experimentar, y en todo caso tampoco
estaba particularmente dotado para la experimentación.

No obstante, en la primavera de 1820, se encontraba dando una conferencia sobre
electricidad y magnetismo ante un auditorio general, y había un experimento que
deseaba realizar pero que no había tenido tiempo de comprobar antes de la
conferencia. Siguiendo un impulso, lo intentó en el transcurso de ésta. Colocó
un cable delgado de platino encima de una brújula magnética, haciéndolo correr
paralelo a la dirección norte-sur de la aguja, y luego hizo fluir una corriente
a través del cable. Ante el asombro de Oersted (puesto que no se trataba
precisamente del efecto que esperaba), la aguja de la brújula se movió cuando
se conectó la corriente. No fue una gran sacudida, y el público, al parecer,
permaneció impasible, pero después de la conferencia, Oersted volvió a
experimentar.

Descubrió que, cuando se hacía pasar corriente por el cable en una dirección,
la aguja de la brújula giraba en el sentido de las manecillas del reloj; cuando
la corriente fluía en la otra dirección, lo hacía en sentido contrario a las
manecillas del reloj. El 21 de julio de 1820 publicó su descubrimiento, y luego
dejó correr el asunto. Pero ya había hecho lo suficiente. Había establecido
alguna clase de conexión entre electricidad y magnetismo, y los físicos se
precipitaron a investigar más el asunto, con una avidez que no se volvió a ver
hasta el descubrimiento de la fisión del uranio, más de un siglo después.

Al cabo de pocos días, el físico francés Dominique F. J. Arago (1786-1853)
mostró que un cable que llevase una corriente eléctrica atraía no sólo agujas
magnetizadas, sino también a las limaduras de hierro ordinarias no
magnetizadas, igual que lo haría un auténtico imán. Se trataba de un efecto
magnético, absolutamente indistinguible del de los imanes corrientes, originado
en la corriente eléctrica.

Antes de que acabase el año, otro físico francés, André Marie Ampere
(1775-1836), mostró que dos cables paralelos que estuviesen unidos a dos
baterías separadas, de tal modo que la corriente fluyese a través de cada una
en la misma dirección, se atraían mutuamente. Si la corriente fluía en
direcciones opuestas, se repelían uno a otro. En otras palabras, las corrientes
podían actuar como polos magnéticos.

Ampere enrolló un hilo en forma de solenoide, o hélice (como un muelle de
colchón) y descubrió que la corriente al fluir en la misma dirección en cada
vuelta, producía un refuerzo. El efecto magnético era más fuerte que si se
hubiese producido en un hilo recto, y el solenoide actuaba exactamente igual
que un imán de barra, con un polo norte y un polo sur.

En 1823, un experimentador inglés, William Sturgeon (1783-1850), colocó
dieciocho vueltas de cobre simple en torno de una barra de hierro en forma de
U, sin permitir que, en realidad, el hierro tocase la barra. Esto concentraba
el efecto magnético aún más, hasta el punto que consiguió un «electroimán». Con
la corriente dada, el electroimán de Sturgeon podía alzar veinte veces su
propio peso en hierro. Con la corriente desconectada, ya no era un imán y no
podía levantar nada.

En 1829, el físico estadounidense Joseph Henry (1797-1878) empleó cable aislado
y enrolló innumerables vueltas en torno de una barra de hierro para producir un
electroimán aún más potente. Hacia 1831, había conseguido un electroimán de no
gran tamaño que podía levantar más de una tonelada de hierro.

Entonces se planteó la pregunta: dado que la electricidad produce magnetismo,
¿puede el magnetismo producir también electricidad?

El científico inglés Michael Faraday (1791-1867) demostró que la respuesta era
afirmativa. En 1831 colocó un imán de barra dentro de un solenoide de cable en
el que no había conectada ninguna batería. Cuando metió el imán, se produjo una
descarga de corriente eléctrica en una dirección (esto se observó con facilidad
con un galvanómetro, que había sido inventado en 1820 empleando el
descubrimiento de Oersted de que una corriente eléctrica haría mover una aguja
magnetizada). Cuando retiró el imán, se produjo una descarga de electricidad en
la dirección opuesta.

Entonces Faraday siguió con la construcción de un mecanismo en el que se hacía
girar continuamente un disco de cobre entre los polos de un imán. Se estableció
así una corriente continua en el cobre, y ésta podía extraerse. Esto constituyó
el primer generador eléctrico. Henry invirtió las cosas haciendo que una
corriente eléctrica hiciese girar una rueda, y esto fue el primer motor
eléctrico.

Faraday y Henry, conjuntamente, iniciaron la era de la electricidad, y todo
ello derivó de la observación inicial de Oersted.

Era ahora cierto que la electricidad y el magnetismo constituían fenómenos
íntimamente relacionados, que la electricidad producía magnetismo y viceversa.
El interrogante era sí podían existir también por separado; si había
condiciones en las que la electricidad no produjese magnetismo, y viceversa.

En 1864, el matemático escocés James Clerk Maxwell imaginó una serie de cuatro
ecuaciones relativamente simples, que ya hemos mencionado en el capítulo 1.
Describían la naturaleza de las interrelaciones de la electricidad y el
magnetismo. Se hizo evidente pronto que las ecuaciones de Maxwell se cumplían
en todas las condiciones y que explicaban la conducta electromagnética. Incluso
la revolución de la relatividad introducida por Albert Einstein (1879-1955) en
las primeras décadas del siglo XX, una revolución que modificó las leyes de
Newton del movimiento y de la gravitación universal, dejó intactas las
ecuaciones de Maxwell.

Si las ecuaciones de Maxwell eran válidas ni los efectos eléctricos ni los
magnéticos podían existir aislados. Los dos estaban siempre presentes juntos, y
sólo existía electromagnetismo, en el que los componentes eléctricos y
magnéticos eran dirigidos en ángulos rectos uno a otro.

Además, al considerar las implicaciones de sus ecuaciones, Maxwell descubrió
que un campo eléctrico cambiante tenía que inducir un campo magnético
cambiante, que, a su vez, tenía que inducir un campo eléctrico cambiante, y así
sucesivamente. Por así decirlo, ambos saltaban por encima, por lo que el campo
progresaba hacia afuera en todas direcciones en forma de una onda transversal
que se movía a una velocidad de 300.000 kilómetros por segundo. Esto era la
«radiación electromagnética». Pero la luz es una onda transversal que se mueve
a una velocidad de 300.000 kilómetros por segundo, y la conclusión irresistible
fue que la luz en todas las longitudes de onda, desde los rayos gamma hasta las
ondas radio, era una radiación electromagnética. El conjunto formaba un
espectro electromagnético.

Luz, electricidad y magnetismo se mezclaban en un solo fenómeno descrito por
una sola serie de relaciones matemáticas: e pluribus unum. Ahora sólo quedaban
dos formas de acción a distancia: gravitación y electromagnetismo. Al
desaparecer el concepto del éter, hablamos de «campos»; de un «campo
gravitatorio» y de un «campo electromagnético», consistiendo cada uno de ellos
en una fuente y una radiación que se expande indefinidamente desde esta fuente,
moviéndose hacia afuera a la velocidad de la luz.



Habiendo reducido los cinco a dos, ¿no deberíamos buscar alguna serie de
relaciones matemáticas aún más general que se refiera a un solo «campo
electromagnetogravitatorio», con la gravitación y el electromagnetismo
meramente como dos aspectos del mismo fenómeno?

Einstein trató durante treinta años de elaborar semejante «teoría del campo
unificado», y fracasó. Mientras lo intentaba, se descubrieron dos nuevos
campos, disminuyendo cada uno en intensidad con la distancia con tanta rapidez,
que mostraban su efecto sólo a distancias comparables al diámetro de un núcleo
atómico o menos (de ahí que se descubrieran tan tarde). Se trata del «campo
nuclear fuerte» y del «campo nuclear débil»

En los años 1870 el físico estadounidense Steven Weinberg (n. 1933) y el físico
paquistanobritánico Abdus Salam (n. 1926), independientemente elaboraron un
tratamiento matemático que mostraba que los campos elecromagnético y nuclear
débil eran aspectos diferentes de un único campo, y probablemente puede
lograrse también que este nuevo tratamiento incluya el campo nuclear fuerte.
Sin embargo, hasta hoy la gravitación sigue estando tozudamente fuera de la
puerta, tan recalcitrante como siempre.

Así pues, lo que cuenta es que ahora existen dos grandes descripciones del
mundo: la teoría de la relatividad, que trata de la gravedad y el macrocosmos,
y la teoría cuántica, que trata del campo electromagnético débil fuerte y el
microcosmos.

Aún no se ha encontrado la manera de combinar los dos, es decir ninguna manera
de «cuantificar» la gravitación. No creo que exista ningún modo más seguro de
conseguir un premio Nobel dentro de un año que el de realizar esta tarea.





III. LAS DOS MASAS





Vi a Albert Einstein en una ocasión.

Fue el 10 de abril de 1935. Yo regresaba de una entrevista en el Columbia
College, una entrevista de la que dependía mi permiso para entrar en el mismo.
(Resultó desastrosa, puesto que yo era un muchacho de quince años totalmente
inexpresivo, y no entré.)

Me detuve en un museo para recuperarme, puesto que no me hacía ilusiones en
cuanto a mis posibilidades después de aquella entrevista, y me encontraba tan
confuso y alterado que nunca he sido capaz de recordar de qué museo se trataba.
Pero al pasear en un estado semiconsciente por sus salas, vi a Albert Einstein,
y no estaba tan sordo y ciego al mundo que me rodeaba para no reconocerle al
instante.

A partir de ese momento, durante media hora, le seguí con paciencia de una sala
a otra, sin mirar nada más, simplemente contemplándole. No estaba solo, puesto
que había otros que hacían lo mismo. Nadie pronunciaba una palabra, nadie se le
acercó para pedirle un autógrafo o con cualquier otro propósito; todos,
simplemente, se limitaban a mirarle. De todos modos Einstein tampoco prestaba
la menor atención; supongo que estaba acostumbrado a ello.

A fin de cuentas, ningún otro científico, excepto Isaac Newton, fue tan
reverenciado en vida, incluso por otros grandes científicos y también por los
profanos y por los adolescentes. Y no se trata sólo de que sus logros fuesen
enormes, sino que son, en ciertos aspectos, casi demasiado refinados para
describirlos, especialmente en relación con lo que se considera en general como
su descubrimiento más importante: la relatividad general.

Sin duda es también algo demasiado sutil para mí, puesto que sólo soy
bioquímico (en cierto modo) y no un físico teórico, pero en el papel que he
asumido de entrometido que lo sabe todo, supongo que, de todos modos, debo
intentarlo.



En 1905, Einstein había formulado su teoría especial de la relatividad (o
relatividad especial, para abreviar), que es la parte más familiar de su
trabajo. La relatividad especial comienza suponiendo que la velocidad de la luz
en un vacío se medirá siempre con el mismo valor constante, sin tener en cuenta
la velocidad de la fuente de luz respecto del observador.

A partir de aquí, una línea ineludible de deducciones nos dice que la velocidad
de la luz representa la velocidad límite de cualquier cosa de nuestro Universo;
es decir, que si observamos un objeto en movimiento, descubriremos que su
longitud en la dirección del movimiento y el índice de paso del tiempo por él
se ve disminuido y su masa aumentada, en comparación con lo que sería si el
objeto estuviese en reposo. Estas propiedades varían con la velocidad de una
manera fija tal, que a la velocidad de la luz, la longitud y el tiempo podrían
medirse como cero mientras la masa se haría infinita. Además, la relatividad
especial nos dice que energía y masa están relacionadas, según la actualmente
famosa ecuación e = mc2.

Sin embargo, supongamos que la velocidad de la luz en un vacío no es inmutable
en todas las condiciones. En ese caso, ninguna de las deducciones es válida.
¿Cómo, pues, podemos decidir acerca de este asunto de la constancia de la
velocidad de la luz?

En realidad, el experimento de Michelson-Morley (véase «The Light That Failed»,
en Adding a dimension, Doubleday, 1964) indicó que la velocidad de la luz no
cambiaba con el movimiento de la Tierra, es decir, que era la misma tanto si la
luz se movía en la dirección de las vueltas de la Tierra en tomo del Sol, o en
ángulos rectos respecto del mismo. Se podría extrapolar el principio general a
partir de esto, pero el experimento de Michelson-Morley es susceptible de otras
interpretaciones. (Llegando hasta un extremo, podría indicar que la Tierra no
se movía, y que Copérnico estaba equivocado.)

En cualquier caso, Einstein insistió más tarde en que no había tenido noticia
del experimento de Michelson-Morley en la época en que concibió la relatividad
especial, y que le parecía que la velocidad de la luz debía ser constante
porque se encontraba envuelto en contradicciones si no era así.

En realidad, la mejor manera de comprobar el supuesto de Einstein seria
comprobar si las deducciones de tal presunción se observan en el Universo real.
Si es así, entonces nos vemos obligados a llegar a la conclusión de que el
supuesto básico debe ser cierto, porque entonces no conoceríamos otra forma de
explicar la verdad de las deducciones. (Las deducciones no proceden del
anterior punto de vista newtoniano del Universo, ni de ningún otro punto de
vista no einsteiniano, o no relativista.)

Hubiera sido en extremo difícil comprobar la relatividad especial si el estado
de los conocimientos físicos hubiera sido el de 1895, diez años antes de que
Einstein formulase su teoría. Los desconcertantes cambios que predijo en el
caso de la longitud, la masa y el tiempo con la velocidad sólo son perceptibles
a grandes velocidades, mucho más que las que encontramos en la vida cotidiana.
No obstante, por un golpe de suerte, el mundo de las partículas subatómicas se
había abierto en la década previa a los enunciados de Einstein. Estas
partículas se mueven a velocidades de 15.000 kilómetros por segundo y más, y a
esas velocidades los efectos relativísticos son apreciables.

Se demostró que las deducciones de la relatividad especial estaban todas allí,
todas ellas; no sólo cualitativamente sino también cuantitativamente. No sólo
un electrón ganaba masa si se aceleraba a los nueve décimos de la velocidad de
la luz, sino que la masa se multiplicaba 3 1/6 veces, tal y como había predicho
la teoría.

La relatividad especial ha sido verificada un increíble número de veces en las
últimas ocho décadas, y ha pasado todas las pruebas. Los grandes aceleradores
de partículas construidos desde la Segunda Guerra Mundial no funcionarían si no
tuviesen en cuenta los efectos de la relatividad, exactamente del modo
requerido por las ecuaciones de Einstein. Sin la ecuación e= mc2, no existe
explicación para los efectos energéticos de las interacciones subatómicas, el
funcionamiento de las centrales de energía nuclear, el brillo del Sol. Por
consiguiente, ningún físico que se halle mínimamente cuerdo duda de la validez
de la relatividad especial.

Esto no quiere decir que la relatividad especial represente necesariamente la
verdad definitiva. Es muy posible que algún día pueda proponerse una teoría más
amplia para explicar todo lo que la relatividad especial hace, y más incluso.
Por otra parte, no ha surgido hasta ahora nada que parezca requerir tal
explicación excepto la llamada aparente separación de los componentes del
quasar a más de la velocidad de la luz, y la apuesta es que probablemente se
trata de una ilusión óptica que puede explicarse dentro de los límites de la
relatividad especial.

Pero aunque esta teoría más amplia se desarrollara, debería llegar hasta la
relatividad especial dentro de los limites de la experimentación actual, igual
que la relatividad especial llega hasta las leyes del movimiento ordinarias de
Newton, si uno se atiene a las bajas velocidades que empleamos en la vida
cotidiana.

¿Por qué es especial esa relatividad a la que tildamos de "especial"? Porque
trata del caso especial del movimiento constante. La relatividad especial nos
dice cuanto se necesita saber si se está tratando con un objeto que se mueve a
velocidad constante y en una dirección fija con respecto a uno mismo.

Pero ¿qué ocurre si la velocidad o la dirección de un objeto (o ambas cosas)
cambia con respecto a uno? En ese caso, la relatividad especial resulta
insuficiente.

Estrictamente hablando, el movimiento nunca es constante. Existen siempre
fuerzas que introducen cambios en la velocidad, la dirección, o ambas cosas, en
el caso de cualquier objeto que se mueva. Por consiguiente, podríamos
argumentar que la relatividad especial es siempre insuficiente.

Así es, pero esa insuficiencia puede ser lo bastante pequeña para no hacerle
caso. Las partículas subatómicas que se mueven a enormes velocidades en
distancias cortas no tienen tiempo de acelerarse demasiado, y se puede aplicar
la relatividad especial.

Sin embargo, por lo general, en el Universo, que implica estrellas y planetas,
la relatividad especial es totalmente insuficiente, puesto que allí hay que
tratar con grandes aceleraciones y éstas son invariablemente producidas por la
existencia de vastos y omnipresentes campos gravitatorios.

A nivel subatómico, la gravitación es tan excesivamente débil en comparación
con otras fuerzas, que puede pasarse por alto. A nivel macroscópico de los
objetos visibles, sin embargo, no puede pasarse por alto; en realidad, se puede
pasar por alto todo menos la gravitación.

Cerca de la superficie de la Tierra, un objeto que cae se acelera mientras un
cuerpo que asciende va más despacio, y ambos constituyen ejemplos de
aceleraciones causadas enteramente por el avance a través del campo
gravitatorio de la Tierra. La Luna viaja en una órbita alrededor de la Tierra,
la Tierra alrededor del Sol, el Sol en torno del centro galáctico, la galaxia
alrededor del centro del grupo local, y así sucesivamente, y en cada caso el
movimiento orbital incluye una aceleración, puesto que existe un cambio
continuo en la dirección del movimiento. Estas aceleraciones también son
producidas como respuesta a los campos gravitatorios.

Por lo tanto, Einstein se dedicó a aplicar sus nociones de relatividad al caso
del movimiento en general, tanto acelerado como constante; en otras palabras, a
todos los movimientos auténticos del Universo. Cuando estuvo elaborado, esto
constituyó la teoría general de la relatividad, o relatividad general. Para
hacerlo, ante todo y principalmente tuvo que considerar la gravitación.



Existe un misterio acerca de la gravitación que se remonta a Newton. Según la
formulación matemática de Newton de las leyes que gobiernan la forma en que los
objetos se mueven, la fuerza de la atracción gravitatoria depende de la masa.
La atracción de la Tierra sobre un objeto con una masa de 2 kilogramos es,
exactamente, el doble de intensa que sobre un objeto que tenga una masa de sólo
1 kilogramo. Además, si la Tierra doblase su propia masa, lo atraería todo con
una fuerza exactamente doble a como lo hace ahora. Por tanto, podemos medir la
masa de la Tierra midiendo la intensidad de su atracción gravitatoria sobre un
objeto dado; o bien podemos medir la masa de un objeto midiendo la fuerza
ejercida sobre él por la Tierra.

Una masa determinada así es una «masa gravitatoria».

No obstante, Newton también elaboró las leyes del movimiento y alegó que
cualquier fuerza ejercida sobre un objeto hace que dicho objeto sufra una
aceleración. La cantidad de aceleración es inversamente proporcional a la masa
del objeto. En otras palabras, si se ejerce la misma fuerza sobre dos objetos,
uno con una masa de 2 kilogramos y el otro con una de 1 kilogramo, el objeto de
2 kilogramos se acelerará exactamente la mitad que el objeto de 1 kilogramo.

La resistencia a la aceleración se denomina inercia, y podemos afirmar que
cuanto mayor sea la masa del objeto, mayor será su inercia; es decir, menos se
acelerará bajo el impulso de una fuerza dada. Por lo tanto, podemos medir la
masa de un objeto midiendo su inercia; es decir, midiendo la aceleración
producida sobre el mismo por una fuerza dada.

Una masa determinada así es una «masa inerte».

Todas las masas que se han determinado han sido medidas o bien a través de los
efectos gravitatorios, o bien por los efectos de la inercia. Cada una de estas
formas se toma como válida y se consideran intercambiables, aunque las dos
masas no tengan una relación aparente. A fin de cuentas, ¿no es posible que
existan algunos objetos, hechos con ciertos materiales o mantenidos en ciertas
condiciones, que presenten un intenso campo gravitatorio pero muy poca inercia,
o viceversa? ¿Por qué no?

Sin embargo, cuando se mide la masa de un cuerpo gravitatoriamente, y se mide
la masa del mismo cuerpo según la inercia, las dos medidas resultan ser
iguales. No obstante, esto puede ser sólo apariencia. Pueden existir pequeñas
diferencias, tan pequeñas que normalmente no se noten.

En 1909, un importante experimento en relación con esto fue realizado por un
físico húngaro, Roland, barón Von Eotvos (el nombre se pronuncia «ut vush»).

Lo que hizo fue suspender una barra horizontal en una fibra delicada. En un
extremo de la barra había una bola de un material, y en el otro extremo una
bola de otro material. El Sol atrae ambas bolas y fuerza una aceleración en
cada una de ellas. Si las bolas tienen una masa diferente por ejemplo 2
kilogramos y 1 kilogramo, entonces la masa de 2 kilogramos es atraída con el
doble de fuerza que la masa de 1 kilogramo y cabria esperar que se acelerase
con una fuerza dos veces superior. Sin embargo, la masa de 2 kilogramos posee
el doble de inercia que la masa de 1 kilogramo. Por esta razón, la masa de 2
kilogramos se acelera sólo la mitad por kilogramo y acaba por acelerarse sólo
con la fuerza de la masa de 1 kilogramo.

Si la masa inerte y la gravitatoria son exactamente iguales, en ese caso las
dos bolas son aceleradas de un modo exactamente igual, y la barra horizontal
puede ser atraída hacia el Sol en una cantidad inconmensurable, pero eso no la
hace rotar. Si la masa inerte y la masa gravitatoria no son del todo iguales,
una bola, se acelerará un poco más que la otra y la barra experimentará una
leve fuerza giratoria. Esto retorcerá la fibra, la cual resiste hasta cierto
punto la torsión y sólo se retorcerá en respuesta a una fuerza dada. Por la
extensión de la torsión, es posible calcular la cantidad de diferencia entre la
masa inerte y la masa gravitatoria.

La fibra empleada era muy delgada, por lo que su resistencia a la torsión era
muy baja, y sin embargo la barra horizontal no presentó ninguna vuelta medible.
Eótvós pudo calcular que una diferencia en las dos masas de 1 parte en
200.000.000 habría producido una torsión mensurable, de modo que ambas masas
eran idénticas en cantidad dentro de ese límite.

(Desde entonces se han llevado a cabo versiones aún más delicadas del
experimento de Eótvós, y ahora estamos seguros, a través de la observación
directa, de que la masa inerte y la masa gravitatoria son idénticas en cantidad
hasta 1 parte en 1.000.000.000.000.)

Einstein, al elaborar la relatividad general, comenzó por suponer que la masa
inerte y la masa gravitatoria eran exactamente iguales, porque son, en esencia,
la misma cosa. A esto se le denomina «el principio de equivalencia», y
desempeña el mismo papel en la relatividad general que la constancia de la
velocidad de la luz en la relatividad especial.

Incluso antes de Einstein era posible ver que la aceleración producida
inercialmente puede provocar los mismos efectos que la gravitación. Cualquiera
de nosotros puede experimentarlo.

Si, por ejemplo, se está en un ascensor que empieza a descender, ganando
velocidad al principio, durante ese período de aceleración el suelo del
ascensor se separa de los pies de uno, por así decirlo, de manera que se ejerce
sobre él menos fuerza. Uno siente disminuir su peso, como si se estuviera yendo
hacia arriba. La aceleración hacia abajo es equivalente a una disminución de la
atracción gravitatoria.

Naturalmente, una vez que el ascensor alcanza una determinada velocidad y la
mantiene, ya no hay más aceleración y uno siente su peso normal. Si el ascensor
se está moviendo a una velocidad constante dada, y en una dirección constante,
no se nota el efecto de la gravedad. En realidad, si se viaja por un vacío en
una caja cerrada por completo, de modo que no se vea moverse el escenario, ni
se sienta la vibración de la resistencia del aire, ni se oiga el silbido del
viento, no existe ninguna manera de distinguir este movimiento constante de
cualquier otro (a diferente velocidad o en una dirección diferente), o del
estado de reposo. Ésta es una de las bases de la relatividad especial.

Dado que la Tierra viaja por un vacío a una velocidad casi constante y en una
dirección casi constante (en distancias cortas), a la gente le resulta difícil
diferenciar esta situación de la de la Tierra estando en reposo.

Por otra parte, si el ascensor siguiera acelerando hacia abajo y se moviera
cada vez más aprisa, uno sentiría como si su peso hubiese disminuido de forma
permanente. Si el ascensor acelerara hacia abajo en una proporción
considerablemente importante, si cayera a la aceleración natural que la
atracción gravitatoria le impondría («caída libre»), en este caso desaparecería
toda sensación de peso. Uno se sentiría flotar.

Si el ascensor acelerase hacia abajo en una proporción más rápida que la
asociada con la caída libre, se sentiría el equivalente de una atracción
gravitatoria hacia arriba, y se encontraría que el techo desempeña para uno las
funciones del suelo.

Naturalmente, no se puede esperar que un ascensor se acelere hacia abajo
durante mucho tiempo. En primer lugar, se necesitaría un hueco de ascensor
extraordinariamente largo para que éste pudiera seguir desplazándose hacia
abajo, uno que tuviese años luz de longitud, sí queremos llevar las cosas al
extremo. En segundo lugar, aunque se tuviese ese imposiblemente largo hueco de
ascensor, un nivel de aceleración constante pronto haría que la velocidad se
convirtiese en una fracción respetable de la velocidad de la luz. Eso
introduciría efectos relativistas apreciables y complicaría las cosas.

Sin embargo, podemos imaginar otra situación. Si un objeto se encuentra en
órbita alrededor de la Tierra, está, en efecto, cayendo constantemente hacia la
Tierra con una aceleración impuesta por la atracción gravitatoria de la Tierra.
No obstante, se está también moviendo horizontalmente en relación con la
superficie de la Tierra y, puesto que la Tierra es esférica, esa superficie se
curva alejándose del objeto que está cayendo. De ahí que el objeto esté siempre
cayendo, pero nunca llegue a la superficie. Estará cayendo durante miles de
millones de años, tal vez. Estará en perpetua caída libre.

Así, una nave espacial que se halle en órbita bordeando la Tierra, se mantiene
en esa órbita gracias a la atracción gravitatoria de la Tierra, pero cualquier
cosa en la nave espacial cae con ésta y experimenta una gravedad cero, igual
que si se encontrase en un ascensor que estuviese cayendo perpetuamente. (En
realidad, los astronautas sentirían la atracción gravitatoria de la nave
espacial en sí y de cada uno, por no hablar de las atracciones de los otros
planetas y de las estrellas distantes, pero se trataría de unas fuerzas
pequeñas que serían por completo imperceptibles.) Ésa es la razón de que las
personas que se encuentran en naves espaciales en órbita floten libremente.

Una vez más, la Tierra se halla sujeta a la atracción gravitatoria del Sol y
que la mantiene en órbita alrededor del Sol. Igual que la Luna. La Tierra y la
Luna caen juntas, perpetuamente, hacia el Sol y, al encontrarse en caída libre,
no sienten la atracción del Sol en lo que se refiere a su relación mutua.

Sin embargo, la Tierra tiene una atracción gravitatoria por sí misma que,
aunque es mucho más débil que la del Sol, es bastante fuerte. Por tanto, la
Luna, en respuesta a la atracción gravitatoria de la Tierra, gira alrededor de
ésta, exactamente como si el Sol no existiese. (Realmente, dado que la Luna se
halla un poco apartada de la Tierra, y a veces está un poco más cerca del Sol
que la Tierra, y a veces un poco más lejos, la atracción solar es un poco
diferente en los dos mundos, y esto introduce ciertos «efectos de marea»
menores que ponen de manifiesto la realidad de la existencia del Sol.)

De nuevo, nos encontramos sobre la Tierra y sentimos sólo la atracción de ésta
y no la del Sol, puesto que nosotros y la Tierra compartimos la caída libre
respecto del Sol, y puesto que el efecto de marea que el Sol ejerce sobre
nosotros es demasiado pequeño para que lo percibamos o seamos conscientes del
mismo.

A continuación, supongamos que nos encontramos en un ascensor que está
acelerando hacia arriba. Esto sucede en un grado muy pequeño cada vez que nos
hallamos en un ascensor que se mueve hacia arriba desde el estado de reposo. Si
se trata de un ascensor rápido, cuando se pone en marcha hay un momento de
aceleración apreciable durante el cual el suelo se mueve hacia arriba, hacia
nosotros, y sentimos una presión hacia abajo. La aceleración hacia arriba
produce la sensación de una mayor atracción gravitatoria.

También en este caso la sensación es muy breve, puesto que el ascensor alcanza
su velocidad máxima y luego la mantiene durante el transcurso de su viaje hasta
que llega el momento de detenerse, cuando momentáneamente reduce su velocidad y
se tiene la sensación de que la atracción gravitatoria decrece. Mientras el
ascensor se encontraba a la velocidad máxima, sin acelerar ni ir más despacio,
uno se sentía por completo normal.

Bueno, supongamos que nos encontramos en el hueco de un ascensor de una
longitud de años luz y que hay allí un ascensor cerrado que podría acelerarse
con suavidad hacia arriba a través de un vacío durante un período indefinido,
yendo cada vez más deprisa. Se sentiría indefinidamente una mayor atracción
gravitatoria. (Los astronautas tienen esta sensación durante un período de
tiempo cuando un cohete acelera hacia arriba y sienten una incómoda presión
hacia abajo. Existe un límite respecto a lo intensa que puede permitirse que
sea una aceleración, o la sensación adicional de atracción gravitatoria puede
hacerse lo bastante fuerte para que la presión lleve los astronautas a la
muerte.)

Pero supongamos que no existe la Tierra, que se trata sólo de un ascensor que
acelera hacia arriba. Si el índice de aceleración estuviera en el nivel
apropiado, se sentiría el equivalente de una atracción gravitatoria igual que
en la superficie de la Tierra. Se podría andar allí con perfecta comodidad e
imaginarnos que el ascensor descansa inmóvil en la superficie de la Tierra.



Aquí es donde Einstein realizó el mayor salto en su imaginación. Al suponer que
la masa inerte y la masa gravitatoria eran idénticas, también supuso que no
existía ninguna manera ninguna manera de poder decir si uno se encontraba en un
cubículo cerrado moviéndose hacia arriba con una aceleración regular de 9,8 m
por segundo cada segundo, o si uno estaba en ese mismo cubículo cerrado en
reposo sobre la superficie de la Tierra.

Esto significa que cualquier cosa que sucediese en el cubículo en aceleración
también debe ocurrir en reposo sobre la superficie de la Tierra.

Esto resulta fácil de ver en lo que se refiere a los cuerpos ordinarios que
caen. Un objeto que se sostuviera con el brazo extendido en un cubículo
acelerado caería cuando se lo soltase, y parecería caer a un índice en
constante aceleración porque el suelo del cubículo se desplazaría hacía arriba,
para encontrarse con él a un índice en constante aceleración.

Por tanto, un objeto que se sostuviera en la Tierra caería de la misma forma.
Esto no significa que la Tierra se esté acelerando hacia arriba, hacia el
objeto. Significa simplemente que la atracción gravitatoria produce un efecto
que no se puede distinguir del de una aceleración hacia arriba.

Sin embargo, Einstein insistió en que esto lo incluye todo. Si un rayo de luz
fuera enviado horizontalmente a través de un ascensor que acelerase hacia
arriba, el ascensor estaría un poco más arriba cuando el rayo de luz acabase su
viaje, y por lo tanto éste parecería curvarse hacia abajo al cruzar el
cubículo. En realidad, la luz viaja con tanta rapidez, que en el tiempo que
tardase en cruzar el cubículo, éste se habría desplazado hacia abajo sólo de
modo imperceptible, pero se curvaría igualmente; no hay duda respecto a eso.

Por tanto, decía Einstein, un rayo de luz sujeto al campo gravitatorio de la
Tierra (o a cualquier campo gravitatorio) debe también viajar en una
trayectoria curva. Cuanto más intenso sea el campo gravitatorio y más larga la
trayectoria por la que ha viajado el rayo de luz, más perceptible será la
curva. Éste es un ejemplo de una deducción que puede extraerse del principio de
equivalencia que no podía extraerse de las teorías anteriores de la estructura
del Universo. Todas las deducciones reunidas constituyen la relatividad general.

Otras deducciones incluyen la sugerencia de que la luz debería tardar un poco
más de tiempo en viajar de A a B cuando se hallase sujeta a un campo
gravitatorio, porque sigue una trayectoria curva; que la luz pierde energía
cuando de desplaza contra la atracción de un campo gravitatorio y, por lo
tanto, muestra un desplazamiento hacía el rojo, etcétera.

Una vez más, examinando todas las deducciones, parece acertado considerar
curvado el espacio-tiempo. Todo sigue la curva, de modo que los efectos
gravitatorios se deben a la geometría del espacio-tiempo más que a una
«atracción».

Es posible elaborar una simple analogía de los efectos gravitatorios imaginando
una lámina indefinidamente grande de una goma infinitamente ampliable que se
extendiese muy por encima de la superficie de la Tierra. El peso de cualquier
masa que descanse sobre la lámina empuja la goma hacia abajo hasta el punto de
crear un «pozo de gravedad». Cuanto mayor sea la masa y más comprimida se
encuentre, más profundo será el pozo y más empinados los lados. Un objeto que
ruede a través de la lámina puede rozar un borde del pozo de gravedad,
hundiéndose en el somero reborde del pozo y salir de nuevo. De este modo se
verá forzado a seguir una trayectoria curvada como si hubiese sufrido una
atracción gravitatoria.

Si el objeto rodante siguiese una trayectoria que lo llevase a más profundidad
en el pozo, podría quedar atrapado allí y tendría que seguir una trayectoria
oblicua elíptica por las paredes del pozo. Si existe fricción entre el objeto
en movimiento y las paredes, la órbita decaerá y el objeto, finalmente, caerá
en el objeto mayor del fondo del pozo.

En resumen: utilizando la relatividad general, Einstein pudo establecer ciertas
«ecuaciones de campo», que son aplicables al Universo en conjunto. Esas
ecuaciones de campo fundaron la ciencia de la cosmología (el estudio de las
propiedades del Universo como un todo).

Einstein anunció la relatividad general en 1916, y la siguiente cuestión fue si
podría verificarse por la observación como la relatividad especial lo había
sido poco después de su formulación once años antes.

Aquí existe una trampa. Mientras la relatividad especial y la general predecían
efectos que diferían del viejo punto de vista newtoniano en tan poco como para
no poder observarse, el descubrimiento fortuito de los fenómenos subatómicos
hizo posible estudiar versiones muy pronunciadas de los efectos de la
relatividad especial.

La relatividad general no tuvo tanta suerte. Durante medio siglo después de
haberlo sugerido Einstein, sólo se podía contar con efectos muy pequeños para
distinguir la relatividad general del anterior tratamiento newtoniano.

Las observaciones que pudieron realizarse tendían a ser favorables a la
relatividad general, pero no abrumadoramente favorables. Por lo tanto, la
teoría de la relatividad general siguió siendo objeto discusión durante mucho
tiempo (pero no la relatividad especial, que es una cuestión ya establecida).

Y lo que es más, dado que la versión de Einstein no fue firmemente confirmada,
otros científicos trataron de elaborar formulaciones matemáticas alternativas,
basadas en el principio de equivalencia, por lo que existe cierto número de
diferentes relatividades generales.

De todas las distintas relatividades generales, la de Einstein resultó ser la
más simple y la que podía ser expresada de forma más nítida en ecuaciones
matemáticas. Era la más «elegante».

La elegancia resulta poderosamente atractiva para los matemáticos y los
científicos, pero no es una garantía absoluta de la verdad. Por lo tanto, era
necesario encontrar pruebas (si era posible) que distinguieran la relatividad
general de Einstein no sólo del punto de vista newtoniano del Universo, sino
también de todas las relatividades generales que competían con ella.

Trataremos de esto en el capítulo siguiente.





IV. EL GENERAL VICTORIOSO





Carol Brener, la ingeniosa propietaria de «Murder Ink», una librería
especializada en novelas de misterio, me telefoneó el otro día para preguntar
si podría enviar a alguien con un ejemplar de mi libro The Robots of Dawn, para
que se lo firmase para un cliente especial. Naturalmente, accedí enseguida.

Ese «alguien» llegó, y, más bien ante mi asombro, resultó ser una joven dama de
considerable belleza. Al instante me convertí en todo suavidad (como suele ser
mi costumbre). La invité a entrar y le firmé el libro.

—No me diga —le dije, exudando encanto— que Carol la ha enviado a mi casa sin
prevenirla acerca de mí.

—Oh, me previno —respondió la joven dama con calma—. Me dijo que me relajase,
porque en el fondo usted es inofensivo.

...Y ésa es, confío, la actitud apropiada que debe tomarse respecto de este
segundo ensayo que estoy escribiendo acerca de la relatividad general. El tema
puede parecer formidable pero (con los dedos cruzados) espero que demuestre
ser, en el fondo algo inofensivo.



En el capítulo precedente he explicado que la relatividad general se basaba en
el supuesto de que la masa gravitatoria era idéntica a la masa inerte, y que,
por tanto, se podían considerar los efectos gravitatorios como idénticos a los
efectos que se observarían en un sistema en aceleración infinita.

La pregunta es: ¿Cómo puede demostrarse que este punto de vista de la
gravitación es más correcto que el de Newton?

Para empezar, existe lo que se ha denominado «las tres pruebas clásicas».



La primera de ellas surgió del hecho que, en la época en que Einstein formuló
la teoría de la relatividad general, en 1916, seguía existiendo un enigma con
respecto al Sistema Solar. Cada vez que Mercurio giraba alrededor del Sol en su
órbita elíptica, pasaba por ese punto en que estaba más cerca del Sol
(«perihelio»). La posición de este perihelio no era fija en relación con el
fondo de estrellas, sino que avanzaba un poco en cada vuelta. Se suponía que lo
hacía así a causa de los efectos menores («perturbaciones») de las atracciones
gravitatorias de otros planetas. Sin embargo, cuando se tuvieron en cuenta
todas esas perturbaciones, se vio que había un ligero avance del perihelio
anterior, que ascendía a cuarenta y tres segundos de arco por siglo.

Se trataba de un movimiento muy pequeño (asciende sólo a la anchura aparente de
nuestra Luna después de 4.337 años), pero se podía descubrir y era preocupante.
La mejor explicación que podía darse era que existía un planeta aún no
descubierto en la órbita de Mercurio, y esta fuerza gravitatoria que no se
tenía en cuenta era la razón de ese avance, de otro modo inexplicable, del
perihelio. El único problema era que semejante planeta no podía hallarse.
(Véase «The Planet That Wasn’t» en The Planet That Wasn’t, Doubleday, 1976.)

Sin embargo, para Einstein el campo gravitatorio era una forma de energía, y
esa energía era equivalente a una masa pequeña, la cual, a su vez, producía un
poco más de campo gravitatorio. Por lo tanto, el Sol poseía un poco más de
gravitación de la que le habían atribuido las matemáticas newtonianas, y eso, y
no otro planeta, era lo que explicaba el avance del perihelio de Mercurio.

Esto constituyó una instantánea e impresionante victoria para la relatividad
general, aunque esa victoria demostró tener limitaciones. Todos los cálculos
que trataban de la posición del perihelio de Mercurio incluían el supuesto de
que el Sol era una esfera perfecta. Dado que el Sol es una bola de gas con un
campo gravitatorio muy intenso, esto parecía una suposición razonable.

Sin embargo, el Sol giraba y, como resultado, debería ser un esferoide
achatado. Una protuberancia ecuatorial, incluso pequeña, podría producir un
efecto que explicaría parte o todo el avance, y esto plantearía dudas acerca de
la relatividad general.

En 1967, el físico estadounidense Robert Henry Dicke realizó unas cuidadosas
mediciones del tamaño del disco solar e informó de un leve achatamiento que era
suficiente para ser el responsable de tres de los cuarenta y tres segundos de
arco de avance por siglo. Esto supuso grandes titulares científicos como un
posible golpe a la relatividad general de Einstein.

No obstante, desde entonces se han dado a conocer valores más pequeños del
achatamiento solar y el asunto sigue aún sometido a discusión. Mi opinión es
que, al final, se demostrará que el Sol es sólo insignificantemente achatado,
pero por el momento el avance del perihelio de Mercurio no se considera una
buena prueba para la relatividad general de Einstein.

Pero ¿qué hay de las otras dos pruebas clásicas?

Una de ellas implicaba el asunto de la curvatura de un campo gravitatorio, algo
que ya he mencionado en el capítulo 3. Si esto realmente tenía lugar en la
cantidad predicha por la relatividad general, sería algo mucho más
impresionante que el asunto del perihelio de Mercurio. A fin de cuentas, el
movimiento del perihelio de Mercurio se conocía, y se puede imaginar que las
matemáticas einsteinianas podían haber sido realizadas para adecuarse a ello.
Por otra parte, nadie había pensado jamás en poner a prueba la curva
gravitatoria de la luz porque, ante todo, nadie había soñado que pudiese
existir un fenómeno así. Si se predijera un fenómeno tan improbable y luego
resultara existir, eso constituiría un triunfo increíble para la teoría.

¿Cómo probarlo? Sí una estrella estuviese situada muy cerca de la posición del
Sol en el firmamento, su luz, al pasar rozando el Sol, se curvaría de tal forma
que la estrella parecería estar situada un poco más lejos de la posición del
Sol de lo que realmente estuviese. La relatividad general mostró que una
estrella cuya luz simplemente rozase el borde solar estaría desplazada en 1,75
segundos de arco, es decir, una milésima de la anchura aparente del Sol. Esto
no es mucho, pero es medible, salvo porque esas estrellas que se encuentran tan
cercanas a la posición aparente del Sol en el firmamento normalmente no son
visibles.

Durante un eclipse total de Sol, no obstante, si lo serían, y estaba previsto
un eclipse así para el 29 de mayo de 1919. Cuando se produjese, el oscurecido
Sol estaría situado en medio de un grupo de brillantes estrellas. El astrónomo
británico Arthur Stanley Eddington, que había conseguido una copia del ensayo
de Einstein acerca de la relatividad general, por medio de los neutrales Países
Bajos durante los oscuros días de la Primera Guerra Mundial, quedó impresionado
por la misma y organizó una expedición para realizar las mediciones necesarias
de las posiciones de aquellas estrellas unas respecto a otras. Estas mediciones
podrían compararse luego con las posiciones conocidas de las mismas estrellas
en los momentos en que el Sol estaba muy alejado en el firmamento.

Se realizaron las mediciones y, ante la creciente excitación de los astrónomos,
estrella tras estrella mostraron el desplazamiento pronosticado. La relatividad
general quedó demostrada de una manera que fue increíblemente dramática, y el
resultado llenó las primeras páginas de los periódicos. De una sola tacada,
Einstein se convirtió en lo que ya sería durante el resto de su vida: el
científico más famoso del mundo.

Y, sin embargo, aunque se supone (en la mitología popular de la ciencia) que el
eclipse de 1919 dejó zanjado el asunto, y aunque yo también lo he considerado
siempre de este modo, en realidad no estableció la relatividad general.

Las mediciones resultaron necesariamente poco claras, las comparaciones entre
estas mediciones y las posiciones en otros momentos del año fueron difíciles de
fijar con precisión, y apareció una incertidumbre adicional debida al hecho de
que, en las diferentes épocas del año, se emplearon distintos telescopios en
diferentes condiciones climáticas, y, en conjunto, como apoyo de la relatividad
general, los datos eran poco consistentes. Ciertamente no servían para
distinguir la variedad de Einstein de las otras variedades en competencia que
al final se ofrecieron.

Y lo que es más, mediciones posteriores en sucesivos eclipses no parecieron
mejorar la situación.

¿Y la tercera de las pruebas clásicas?

Ya mencioné en el capitulo 3 que la luz que sube contra la atracción de la
gravedad debería perder energía, según la relatividad general, dado que la luz
sin duda lo haría si se elevase contra una aceleración hacia arriba de la
fuente. La pérdida de energía significaba que cualquier línea espectral que se
hallase en una longitud de onda dada en ausencia de un campo gravitatorio
importante se desviaría hacia el rojo si la luz que lo contuviese se moviese
contra la atracción gravitatoria. Esto era el «desplazamiento hacia el rojo
gravitacional» o «el desplazamiento hacia el rojo de Einstein».

Sin embargo, un desplazamiento hacia el rojo de este tipo era asimismo muy
pequeño y haría falta un campo gravitatorio enormemente intenso para producir
uno que pudiera medirse de manera inconfundible.

En la época en que Einstein presentó su teoría de la relatividad general, el
campo gravitatorio más intenso que podía estudiarse fácilmente parecía ser el
del Sol, y éste, por intenso que fuese, era demasiado débil para resultar útil
como prueba del desplazamiento hacia el rojo de Einstein.

Pese a todo, sólo unos meses antes del ensayo de Einstein, el astrónomo
estadounidense Walter Sydney Adams había presentado pruebas de que el oscuro
compañero de Sirio («Sirio B») era en realidad una estrella con la masa del
Sol, pero con el volumen de un pequeño planeta. (Véase El sol brilla luminoso,
publicado en esta misma colección.) Esto resultó un poco difícil de creer al
principio, y durante algún tiempo no se hizo caso de la «enana blanca».

Sin embargo, fue Eddington quien vio, con toda claridad, que si Sirio B era muy
pequeño tenía que ser asimismo muy denso, y que poseería un campo gravitatorio
enormemente intenso. Su luz, por lo tanto, mostraría un desplazamiento hacia el
rojo de Einstein claramente perceptible si la relatividad general fuera
correcta.

Adams continuó estudiando el espectro de Sirio B con detalle, y en 1925 informó
que el desplazamiento hacia el rojo de Einstein se encontraba allí, y bastante
cerca de lo pronosticado por la relatividad general.

Una vez más aquello fue considerado como un triunfo, pero, de nuevo, pasado el
período de euforia, pareció que el resultado no era del todo claro. La medida
del desplazamiento no era muy exacta por cierto número de razones (por ejemplo,
el movimiento de Sirio B a través del espacio introducía un desplazamiento de
la línea espectral que no estaba relacionado con la relatividad general, y que
introducía una enojosa incertidumbre). Como resultado de todo ello, la prueba
ciertamente no podía emplearse para distinguir la relatividad general de
Einstein de otras teorías que competían con ella, y el estudio de la luz
procedente de otras enanas blancas tampoco mejoró las cosas.

Todavía en 1960, es decir, cuarenta y cuatro años después de que se introdujera
la relatividad general y cinco años después de la muerte de Einstein, la teoría
aún descansaba sobre las tres pruebas clásicas que eran, simplemente,
inadecuadas para esta tarea. Y lo que es más, parecía como si no existiese
ninguna otra comprobación que pudiera siquiera empezar a dejar zanjado el
asunto.

Daba la impresión de que los astrónomos tendrían, simplemente, que vivir sin
tener una descripción adecuada del Universo en conjunto, y discutir eternamente
acerca de las diferentes posibilidades de la relatividad general, como los
escolásticos al debatir el número de ángeles que podrían bailar encima de la
cabeza de un alfiler.

La única cosa que se podía afirmar, de un modo constructivo, era que la versión
de Einstein era la más sencilla de explicar matemáticamente y, por tanto,
también la más elegante. Pero eso tampoco era una prueba segura de la verdad.



Luego, a partir de 1960, todo cambió.

El físico alemán Rudolf Ludwig Móssbauer recibió su doctorado en 1958, a la
edad de veintinueve años, y el mismo año anunció lo que habría de llamarse «el
efecto Móssbauer», por el que recibió el premio Nobel de Física en 1961.

El efecto Móssbauer implica la emisión de rayos gamma por ciertos átomos
radiactivos. Los rayos gamma consisten en fotones de energía, y su misión
induce un retroceso en el átomo que realiza la emisión. El retroceso hace
disminuir un poco la energía del fotón del rayo gamma. Normalmente, la cantidad
de retroceso varia de un átomo a otro por varias razones, y el resultado es que
cuando los fotones se emiten en cantidad por una colección de átomos, son aptos
para tener una amplia extensión de contenido energético.

Sin embargo, hay condiciones en las que los átomos, cuando existen en un
cristal algo grande y ordenado, emitirán fotones de rayos gamma experimentando
el retroceso todo el cristal como una unidad. Dado que el cristal tiene una
masa enorme en comparación con un solo átomo, el retroceso que sufre es
insignificantemente pequeño. Todos los fotones se emiten con toda la energía,
por lo que el rayo posee una extensión de energía de prácticamente cero. Esto
es el efecto Móssbauer.

Los fotones de rayos gamma de exactamente el contenido de energía emitido por
un cristal en estas condiciones serán absorbidos con fuerza por otro cristal
del mismo tipo. Si el contenido energético es incluso muy ligeramente distinto
en una u otra dirección, la absorción por un cristal similar quedará en extremo
reducida.

Pues bien, supongamos entonces que un cristal está emitiendo fotones de rayos
gamma en el sótano de un edificio, y una corriente de fotones se dispara hacia
arriba, hacia un cristal absorbente que está en el tejado, 20 metros más
arriba. Según la relatividad general, los fotones que suben contra la atracción
de la gravedad de la Tierra perderían energía. La cantidad de energía que
perderían sería en extremo pequeña, pero suficiente para impedir que el cristal
del tejado la absorbiera.

El 6 de marzo de 1960, dos físicos estadounidenses, Robert Vivian Pound y Glen
Rebka, Jr., informaron de que habían llevado a cabo este experimento y
descubierto que los fotones no eran absorbidos. Y lo que es más, luego movieron
hacia abajo el cristal receptor muy despacio, para que su movimiento
incrementase muy levemente la energía de colisión con los fotones que entraban.
Midieron la proporción de movimiento descendente que originaría el suficiente
incremento de energía para producirse la pérdida de relatividad general y para
permitir que los fotones fuesen absorbidos con fuerza. De esta manera
determinaron exactamente cuanta energía perdían los rayos gamma al ascender
contra la atracción gravitatoria de la Tierra, y descubrieron que el resultado
coincidía con la predicción de Einstein hasta el 1 por 100. Ésta fue la primera
demostración real e indiscutible de que la relatividad general era correcta, y
fue la primera demostración llevada a cabo por completo en un laboratorio.
Hasta entonces, las tres pruebas clásicas habían sido siempre de tipo
astronómico y habían requerido mediciones con algunas inexactitudes que habían
sido casi imposibles de reducir. En el laboratorio, todo podía ser
perfectamente controlado, y la precisión era mucho más elevada. De forma
también asombrosa, el efecto Móssbauer no requería una enana blanca, ni
siquiera el Sol. El comparativamente débil campo gravitatorio de la Tierra era
suficiente, y en una diferencia de altura no mayor que la distancia entre el
sótano y el tejado de un edificio de seis pisos.

Sin embargo, aunque podría considerarse que el efecto Móssbauer había asentado
por fin la relatividad general, y dejado atrás definitivamente la gravedad
newtoniana, las demás variedades de relatividad general (que, en realidad,
habían sido introducidas a partir de 1960), no quedaban eliminadas por este
experimento.



El 14 de setiembre de 1959, se recibió un eco de radar, por primera vez, desde
un objeto externo al sistema Tierra-Luna: desde el planeta Venus.

Los ecos de radar se producen por un rayo de microondas (ondas de radio de muy
alta frecuencia), que viajan a la velocidad de la luz, una cifra que conocemos
con considerable precisión. Un rayo de microondas puede viajar rápidamente
hasta Venus, chocar contra su superficie y reflejarse, y a continuación
regresar a la Tierra en de 2 1/4 a 25 minutos, según donde se encuentren la
Tierra y Venus en sus respectivas órbitas. A partir del tiempo realmente
consumido por el eco al regresar, puede determinarse la distancia de Venus en
un momento dado con una precisión mayor que la que cualquier otro método
anterior había hecho posible. La órbita de Venus, por lo tanto, puede
calcularse con gran exactitud.

Esto invirtió la situación. Se hizo posible predecir cuánto tiempo tardaría
exactamente un rayo de microondas en chocar con Venus y regresar cuando el
planeta se encontrase en cualquier posición concreta de su órbita en relación
con nosotros mismos. Hasta las menores diferencias de la predicha extensión de
tiempo podían determinarse sin ninguna seria incertidumbre.

La importancia de esto radica en que Venus, con intervalos de 584 días, estará
casi exactamente en el lado opuesto al Sol desde nuestra posición, de manera
que la luz que se dirija de Venus a la Tierra debe rozar el borde del Sol
durante su camino.

Según la relatividad general, esa luz seguiría una trayectoria curvada y la
posición aparente de Venus se desplazaría alejándose ligeramente del Sol. Pero
Venus no puede observarse cuando se encuentra tan cerca del Sol, y aunque
pudiese hacerse, el ligero desplazamiento de su posición seria casi imposible
de medir con seguridad.

Sin embargo, debido a que la luz sigue una trayectoria levemente curvada al
rozar la superficie del Sol, tarda más en llegar a nosotros que si hubiese
seguido la habitual línea recta. No podemos medir el tiempo que tarda la luz de
Venus en llegar hasta nosotros, pero podemos enviar un rayo de microondas a
Venus y aguardar el eco. El rayo pasará cerca del Sol cuando se desplace en
cada dirección, y podemos medir el tiempo que se tarda en recibir el eco.

Si sabemos cuán cerca el rayo de microondas se aproxima al Sol, conoceremos,
por la matemática de la relatividad genera, exactamente cuánto debería tardar.
La tardanza real y la teórica pueden compararse con mayor exactitud de lo que
podemos medir el desplazamiento de las estrellas en un eclipse total.

Luego, también nuestras sondas planetarias emiten pulsaciones de microondas y
éstas pueden descubrirse. Cuando se sabe con exactitud la distancia de la sonda
en cualquier momento, el tiempo que tardan las pulsaciones en viajar hasta la
Tierra puede medirse y compararse con el teórico, cuando las pulsaciones no se
mueven en absoluto cerca del Sol, y luego de nuevo cuando deben pasar rozando
el Sol. Estas mediciones, realizadas a partir de 1968 han demostrado coincidir
con las formulaciones de Einstein de la relatividad general en un porcentaje de
0,1.

Por lo tanto, parece que ahora no hay duda de que no sólo la relatividad
general es correcta, sino de que la formulación de Einstein es el general
victorioso. Las teorías que competían con ella están desapareciendo.



Existen también en la actualidad demostraciones astronómicas de la validez de
la relatividad general, demostraciones que implican objetos cuya existencia no
se conocía en el momento en que Einstein presento por primera vez su teoría.

En 1963, el astrónomo holandés-estadounidense Maarten Schmidt consiguió
demostrar que ciertas «estrellas» que eran fuertes emisores de ondas de radio
no eran estrellas de nuestra propia galaxia, sino objetos situados a mil
millones o más de años luz de distancia. Esto pudo demostrarse por el enorme
desplazamiento hacia el rojo de sus líneas espectrales, que mostraron que
retrocedían respecto de nosotros a unas velocidades elevadas sin precedente.
Esto (presumiblemente) sólo podía ser debido a que se encontraban sumamente
alejadas de nosotros.

El asunto provocó una considerable controversia acerca de qué podrían ser esos
objetos («quasares»), pero esa controversia carece de toda importancia en
relación con lo que nos interesa ahora. Lo que sí importa es que los quasares
emiten fuertes rayos de ondas de radio. Gracias a los elaborados
radiotelescopios construidos desde que se reconocieron por primera vez los
quasares como lo que son, las fuentes de radio dentro de los quasares pueden
localizarse con una exactitud mucho mayor de la que es posible para localizar
un objeto simplemente emisor de luz.

Ocasionalmente, las ondas de luz (y de radio) que salen de un quasar
determinado rozan la superficie del Sol en su camino hacia nosotros. Las ondas
de luz se pierden en el fuerte brillo del Sol, pero las ondas de radio pueden
descubrirse con facilidad, con Sol o sin él, por lo que no hay necesidad de
aguardar a que se produzca un eclipse que sólo tiene lugar cuando el Sol se
encuentra en la Posición correcta para nuestros propósitos. Y aún más: la
fuente de ondas de radio se ha registrado con tanta exactitud, que el leve
desplazamiento inducido por la relatividad general puede determinarse con mucha
mayor exactitud que el famoso desplazamiento en la posición de la estrella
durante el eclipse de 1919.

El desplazamiento de la posición en las ondas de radio del quasar, medido una
gran cantidad de veces durante los últimos quince años, ha demostrado
encontrarse menos de un 1 por 100 dentro de lo que dan las previsiones de la
relatividad general de Einstein, y las mediciones llevadas a cabo durante el
eclipse de 1919, por poco fiables e inseguras que fuesen, han quedado
vindicadas.

Los quasares se hallan implicados en otro fenómeno que apoya la relatividad
general, un fenómeno particularmente impresionante.

Supongamos que existe un objeto emisor de luz que está lejos, y entre éste y
nosotros se halla un pequeño objeto con un poderoso campo gravitatorio. El
objeto emisor de luz que está lejos enviaría ondas de luz que pasarían rozando
los invisibles objetos cercanos por todos lados. En todos los lados la luz se
desplazaría hacia afuera por el efecto de la relatividad general, y el
resultado sería exactamente como si la luz pasase a través de una lente de
cristal ordinaria. El objeto distante quedaría ampliado y parecería mayor de lo
que realmente fuese. Esto constituiría una «lente gravitatoria» y su existencia
fue ya predicha por el propio Einstein.

El problema con el concepto era que no se conocía que existiese ningún caso de
ello en el firmamento. Por ejemplo, no había ninguna gran estrella luminosa que
tuviese una pequeña enana blanca exactamente entre sí misma y nosotros. Pero
aunque existiese, ¿cómo podríamos decir que la estrella estaba un poco más
agrandada de lo que normalmente estaría si la enana blanca no se encontrase
allí? No podríamos apartar la enana blanca y observar la estrella encogerse
para recuperar su tamaño normal.

Pero consideremos los quasares. Los quasares están mucho más alejados que las
galaxias ordinarias, y las galaxias ordinarias existen en un número de miles de
millones. Hay una razonable posibilidad de que pudiera existir una pequeña
galaxia entre nosotros y uno de los centenares de quasares ahora conocidos. Y
lo que es más, la fuente de radio dentro de un quasar (que es lo que observamos
con mayor exactitud), y la galaxia intermedia serían objetos irregulares, de
modo que el efecto sería similar al de la luz que atravesase una lente bastante
defectuosa. En vez de simplemente agrandarse el quasar se descompondría en dos
o más imágenes separadas.

En 1979, un equipo de astrónomos estadounidenses, D. Walsh, R. F. Carswell y R.
J. Weymann, estaban observando el quasar (›957 + 561), que presentaba dos
fuentes de radio separadas unos 6 segundos de arco. Parecían dos quasares
igualmente brillantes e igualmente distantes de nosotros. Y lo que es más, sus
espectros parecían idénticos. Los astrónomos sugirieron que lo que observaban
era en realidad un solo quasar que estaba dividido en dos por un efecto de
lente gravitatoria.

La proximidad del quasar se examinó muy de cerca en busca de cualquier señal de
galaxias entre nosotros y aquél, y, en 1980, se demostró que había un cúmulo de
débiles galaxias a más o menos una tercera parte de la distancia de los
quasares y exactamente delante de ellos. Las condiciones parecían ser las
adecuadas para la producción de una lente gravitatoria, y desde entonces se han
descubierto otros casos posibles..., un tanto más para la relatividad general.



Pero aún queda por contar la más impresionante e importante demostración de la
relatividad general.

Einstein predijo la existencia de ondas gravitatorias análogas a las ondas de
luz. Masas en aceleración emitirían ondas de gravedad, lo mismo que los campos
electromagnéticos oscilantes emiten ondas de luz y radiación similar. De este
modo, cualquier planeta que gire alrededor de nuestro Sol está continuamente
cambiando de dirección mientras gira, y por lo tanto acelerándose de forma
continua. Estaría emitiendo ondas gravitatorias, perdiendo energía en
consecuencia, aproximándose al Sol y, finalmente, precipitándose en el mismo.
Esto, por ejemplo, le está sucediendo a la Tierra, pero la pérdida de energía
es tan pequeña que no hay esperanzas de poder descubrir el efecto.

Lo que se necesita son campos gravitatorios más intensos y aceleraciones más
extremas. Pero hasta 1974 no se conoció nada que se aproximase a lo necesario.

En aquel año, los astrónomos estadounidenses Russell A. Hulse y Joseph H.
Taylor, Jr. descubrieron un púlsar que ahora se llama PSR 1913 + 16. Emitía
pulsaciones de ondas radio con intervalos de 0,05902999527 segundos, o
simplemente unas 17 pulsaciones por minutos. Esos intervalos se hacen levemente
más grandes y levemente más pequeños de una forma regular en un Período de
7,752 horas.

La deducción es que se acerca y se aleja de nosotros de forma alternativa, y el
mejor modo de explicarlo consiste en suponer que gira en torno de algo. Por el
tamaño de su órbita y por el hecho de que el objeto en torno al que gira no
puede verse, los astrónomos concluyeron que habían captado un doble púlsar.

Esto en sí mismo no carece de precedentes. Otros pulsares dobles han sido
localizados. Sin embargo, lo que es insólito es que los dos pulsares de este
sistema se encuentren tan juntos. Zumban uno en torno del otro a velocidades de
unos 320 kilómetros por segundo. Esto, combinado con la pequeñez de la órbita y
la intensidad de sus campos gravitatorios, significaba que los efectos de
relatividad general debían ser enormes.

Por ejemplo, el punto de la mayor aproximación mutua de los pulsares
(«periastro») se movería hacia adelante, exactamente como lo hace el perihelio
de Mercurio, pero en una proporción superior a un millón y medio de veces. Y
con bastante seguridad el avance se ha observado en un apropiado índice de
4,226 grados por año.

Y lo que es más importante, el púlsar binario emitiría raudales de ondas
gravitatorias en cantidad suficiente para acortar el período de revolución de
modo perceptible.

El acortamiento seria sólo de una diezmillonésima de segundo por período
orbital. Sin embargo, esto se acumula a medida que aumenta el número de órbitas
en las que es observado, y en la actualidad ya no hay duda de que los pulsares
del sistema están acortando sus órbitas y aproximándose uno a otro, y de que en
menos de diez mil años deberían estrellarse uno contra otro.

Y esto también es una clara evidencia en favor de las ondas gravitatorias
predichas por la teoría de la relatividad general de Einstein.

Y ésa es la historia. Todas las mediciones apropiadas que se han llevado a cabo
en los dos tercios de siglo han apoyado a Einstein. Ninguna medición ha
conseguido arrojar ninguna duda seria sobre él.

Lamento que Einstein no viviera lo suficiente para ver por lo menos algunas de
las victorias que han tenido lugar desde 1950, pero eso, realmente, no importa.
Siempre estuvo absolutamente seguro de que su teoría era correcta. Existe la
anécdota de que, después del eclipse de 1919, se le preguntó qué hubiera
pensando si las mediciones del desplazamiento de la estrella no le hubieran
apoyado. Se dice que respondió que lo hubiera sentido por Dios, por haber
cometido el error de construir un Universo sobre unos principios equivocados.





Segunda parte





ASTRONOMÍA





V. ACTUALIZACIÓN DE LOS SATÉLITES





A medida que se envejece, se tiende a reunir una amplia variedad de
reputaciones. Una de las mejores que he conseguido es la de ser “una persona
agradable.”

Esta reputación me gusta, puesto que significa que la gente me sonríe, me da
fuertes apretones de mano y me soba los hombros, y dejan que sus ojos brillen
de placer cuando me ven. Las damas de una belleza por encima de lo corriente
incluso es probable que pidan permiso para besarme





[2].

Sin embargo, a veces resulta un poco cansado tener editores que protegen su
propiedad no permitiéndome gruñir, jurar y rechinar los dientes cuando tengo
una urgente necesidad de hacerlo.

Consideremos mi libro Saturn and beyond (Lothrop, Lee and Shepard, 1979). En la
época en que lo escribí, no se conocía que Plutón poseyese un satélite. Para
cuando me dieron a leer las galeradas, se descubrió el satélite y me apresuré a
añadir un par de párrafos para que, cuando apareciese el libro, el satélite
plutoniano se encontrase situado en sus páginas de modo adecuado.

Algún tiempo después de su publicación, se hizo una crítica del libro en la que
se me castigaba sin misericordia por no haber incluido el satélite. El tono de
la crítica era en extremo insultante.

Mi editora realizó una pequeña labor detectivesca y descubrió que el crítico
había leído, en realidad, unas pruebas de galeradas en las que figuraba con
claridad la indicación de que estaban sin corregir, y era demasiado estúpido
para comprender que uno de los propósitos de las pruebas de galeradas es dar al
autor una oportunidad para poner al día el material.

La editora no quiso, por alguna razón, que escribiese directamente al crítico.
(Tal vez sabía algo acerca de la naturaleza de mi elocuencia.) Sugirió que en
vez de ello le permitiera interceptar la carta y entregarla luego al crítico.

Estuve de acuerdo, y pronto me volqué en una carta en la que explicaba con
detalle la situación. Comencé con un breve ensayo ciceroniano sobre el tema de
la «estupidez», y luego examinaba los síntomas y consecuencias de la
«senilidad», y concluía con algunas placenteras sugerencias respecto a lo que
el crítico podría hacer con varias partes de su cuerpo.

Desgraciadamente (sé que apenas se creerán esto), mi editora se negó a hacer
llegar la carta, y en lugar de ésta envió una misiva insulsa de su propia
cosecha, en la que dejaba al crítico indemne por completo.

Me dio la excusa de que mi carta no proyectaba correctamente mi imagen «de
persona agradable». Mi acalorada explicación de que no me sentía en absoluto
como una persona agradable, sino que deseaba sacarle las tripas a aquel hijo de
un padre incierto, cayó en oídos sordos.

Pero esto no importa: mis libros quedan anticuados con el tiempo, y uno de los
aspectos en que Saturn and Beyond quedó anticuado (al igual que un anterior
volumen gemelo, Jupiter, the Largest Planet, Lothrop, 1973) fue en relación con
los satélites del Sistema Solar. Pero ahora tengo la oportunidad de poner al
día todo este asunto.



Si comenzamos por el Sol y vamos hacia afuera, resulta que Mercurio y Venus
carecen en absoluto de satélites, por lo menos que sepamos, y parece bastante
seguro que no se descubrirá ninguno de tamaño importante.

La Tierra posee un satélite, la Luna, y parece del todo seguro que no existe un
segundo satélite (de origen natural) de ningún tamaño importante. Sin embargo,
la Luna es un satélite grande: uno de un total de siete en el Sistema Solar que
poseen diámetros que exceden de los 3.000 kilómetros. Es muy improbable
(dejando aparte el descubrimiento de un gigante gaseoso más allá de la órbita
de Plutón) que siga sin descubrir ningún satélite grande. En el último siglo y
un tercio, sólo se ha localizado (que yo sepa) uno que tiene más de 200
kilómetros de diámetro.

Marte tiene dos pequeños satélites que se conocen desde hace un siglo, y
recientemente han sido fotografiados con detalle.

Esto nos lleva a Júpiter. Posee cuatro grandes satélites, en ocasiones llamados
los «satélites galileanos», porque Galileo los descubrió en 1610. Uno de ellos,
Ganimedes, es el satélite más grande del Sistema Solar, con un volumen 3,5
mayor que el de la Luna.

Además de los satélites galileanos, Júpiter tiene algunos pequeños satélites y
aquí es donde comienza la actualización.

En 1973, cuando se publicó mi libro Júpiter..., se conocían ocho pequeños
satélites de Júpiter. (Siento el impulso de llamarles «satelitos», pero me
estoy resistiendo a ello.) A los satélites de Júpiter a menudo se les numera en
el orden de su descubrimiento, con los galileanos J-I a J-IV, y los pequeños
desde el J-V al J-XII (como en 1973). La «J», como ya habrán adivinado, es por
Júpiter.

En Júpiter..., daba los nombres de los ocho pequeños satélites extraídos de la
mitología. En aquella época dichos nombres no eran oficiales, pero di por
supuesto que llegarían a serlo. Me equivoqué. Sólo se conservó uno de esos ocho
nombres, por lo que debo comenzar mi actualización dando los actuales nombres
oficiales de los ocho pequeños satélites, junto con el año de su descubrimiento:

J-V Amaltea1892

J-VI Himalia 1904

J-VII Elara 1905

J-VIII Pasifae 1908

J-IX Sinope 1914

J-X Lisitea 1938

J-XI Carme 1938

J-XII Ananke 1951



Es costumbre que los nombres de los cuerpos del Sistema Solar se tomen de la
mitología griega, y éstos no son ninguna excepción.

Amaltea (el único nombre que usé que se ha conservado y, finalmente, se ha
convertido en oficial) fue una de las ninfas que alimentaron al infante Zeus
(Júpiter, para los romanos) con leche de cabra, cuando se hallaba oculto en
Creta para ponerle a salvo de las canibalísticas tendencias de su padre, Cronos
(Satumo). A veces el nombre se da a la cabra que proporcionó la leche. En
cualquier caso resulta apropiado para el satélite que estaba más cerca que
cualquiera de los otros satélites de Júpiter ya conocidos en la época de su
descubrimiento.

Cuando Zeus creció, digamos de paso, regaló un cuerno de la cabra a la ninfa
como recompensa, diciéndole que si deseaba algo, no tenía más que meter la mano
en el cuerno para conseguirlo. (Esto fue la cornucopia original, de una frase
latina que significa «cuerno de la abundancia»). Elara fue una mujer mortal que
cayó bajo la mirada del omnímodo Zeus. La escondió bajo tierra para impedir que
fuese descubierta por la celosa Hera (Juno), que nunca llegó a acostumbrarse a
las propensiones amorosas de su todopoderoso marido, y que practicaba su
venganza persiguiendo a cualquiera que pareciese gustarle.

Según algunos relatos, Elara fue la madre de Titius, un enorme monstruo nacido
en la Tierra (recuerden que Elara se encontraba bajo tierra), que fue muerto
por las flechas de Apolo y que, cuando fue tendido en el Tártaro, ocupó cuatro
hectáreas de terreno.

Pasifae fue una nuera de Zeus, por estar casada con su hijo, el rey Minos de
Creta. Pasifae es sobre todo conocida por haberse enamorado apasionadamente de
un toro de gran belleza. (Sobre gustos no hay nada escrito.) Construyó un
armazón, y lo cubrió con un pellejo de vaca. Pasifae se metió dentro y muy
pronto el toro se montó obedientemente encima de la estructura. A su debido
tiempo, Pasifae dio a luz un niño con cabeza de toro, que se convirtió en el
famoso Minotauro.

Sinope era otra joven dama que fue abordada por el insaciable Zeus. Él le
ofreció cualquier cosa que desease a cambio de su sumisión, y la mujer solicitó
una virginidad perpetua. (Ya he dicho que sobre gustos no hay nada escrito.)

Carme fue también otra beneficiaria de Zeus, y la madre de Britomarte, una
diosa cretense de la pesca y de la caza.

Ananke difiere del resto. Es la personificación divina del Hado o Necesidad: el
desarrollo ordenado de los acontecimientos que ni siquiera los dioses pueden
alterar, por lo que Ananke es la única divinidad superior a Zeus.

Himalia y Lisitea son unas figuras por completo oscuras, que he logrado
descubrir sólo gracias a la amabilidad de algunos de mis lectores. (Los
astrónomos o bien son muy versados en mitología, o están lo suficientemente
desesperados para rebuscar en grandes compendios de la misma.)

En cualquier caso, Himalia era una ninfa de Rodas, que gobernaba las buenas
cosechas, y que proporcionó al bueno de Zeus otra buena cosecha: tres hijos.

Lisitea es una ninfa que, en algunos mitos, se identifica como la madre de
Dionisos, el dios del vino. Por lo general, la madre que se le atribuye es
Semele.

Los ocho pequeños satélites de Júpiter fueron descubiertos por orden de brillo
decreciente, como parece razonable. Dado que todos ellos se encuentran a la
misma distancia de la Tierra y tienen, probablemente, similar albedo (la
capacidad de reflejar la luz), fueron también descubiertos por orden de tamaño
decreciente. Así, Amaltea e Himalia tienen un diámetro de unos 170 kilómetros,
mientras que Ananke posee un diámetro de tal vez 20 kilómetros.

Pero incluso el más grande es comparativamente pequeño. Los ocho satélites
constituyen sólo 1/3.000 del volumen de Europa, el más pequeño de los
galileanos, o 1/32.000 del volumen de los cuatro satélites galileanos puestos
juntos.

Cuatro de los pequeños satélites están agrupados a una distancia
particularmente grande de Júpiter. Se trata de Pasifae, Sinope, Carme y Ananke,
con distancias medias de Júpiter que van de 20.700.000 kilómetros, en el caso
de Ananke, el más próximo, a los 23.370.000 kilómetros en el caso de Sinope, el
más alejado.

Es muy probable que esos satélites sean asteroides capturados y constituyen
unas relativamente recientes adiciones a la familia de Júpiter. No han tenido
aún tiempo de regularizar sus órbitas circularmente y moverse en torno del
plano ecuatorial de Júpiter, en especial teniendo en cuenta que, a las
distancias que están, el influjo gravitatorio de Júpiter es comparativamente
débil. Por lo tanto, las órbitas de los satélites son muy inclinadas y
elípticas, y el agrupamiento no es tan rígido como lo sería si todas poseyesen
órbitas circulares y girasen en torno del plano ecuatorial de Júpiter.

La órbita más excéntrica es la de Pasifae, lo cual es bastante adecuado si se
tienen en cuenta los excéntricos gustos del prototipo mitológico. Pasifae
retrocede hasta una distancia de 33.200.000 kilómetros de Júpiter en un extremo
de su órbita. Ésta es la mayor distancia conocida de cualquier satélite
respecto del planeta alrededor del que gira. Es, por ejemplo, más o menos 85
veces la distancia de la Luna a la Tierra.

Los períodos de revolución de esos satélites son largos, más de 600 días en
cada caso. El período de revolución más largo es el de Sinope, como cabía
esperar, puesto que posee la mayor distancia media desde Júpiter. Su período es
de 758 días, o 2,08 años. Esto es casi 28 veces más el tiempo que tarda la Luna
en girar alrededor de la Tierra, y 1, 1 veces lo que tarda Marte en dar la
vuelta en torno del Sol.

De los restantes pequeños satélites, tres se agrupan un poco más cerca de
Júpiter. Himalia, Lisitea y Elara poseen distancias medias de Júpiter de entre
11.000.000 y 12.000.000 de kilómetros.

No obstante, hay una superposición. Elara tiene una órbita que es
suficientemente excéntrica para poder alejarse hasta 14.300.000 kilómetros de
Júpiter, mientras Pasifae, en el punto más próximo de su órbita, se encuentra a
sólo 13.800.000 kilómetros de Júpiter.

Los siete satélites están mucho más lejos de Júpiter que los galileanos. La
aproximación más cercana de cualquiera de los siete es la de Elara que, en el
punto más próximo de su órbita, se halla a sólo 9.300.000 kilómetros de
Júpiter. Sin embargo, esto equivale a cinco veces más lejos de Júpiter que
Calisto, el más alejado de los satélites galileanos.

El octavo pequeño satélite, Amaltea, difiere de los demás en que se encuentra
más cerca de Júpiter que cualquiera de los galileanos. Se halla a una distancia
de sólo 180.000 kilómetros del centro de Júpiter. Esto es menos de la mitad de
la distancia de lo, el más cercano de los galileanos, y menos de la mitad de la
distancia a la que se encuentra la Luna en relación con la Tierra.

Impulsado por el enorme campo gravitatorio del cercano Júpiter, Amaltea es
lanzado en torno del planeta en 11.95 horas, lo que es menos de 1/50 veces el
tiempo que tarda la Luna en girar alrededor de la Tierra.

En la época en que escribí Júpiter, Amaltea poseía el segundo periodo más corto
de todos los satélites conocidos. Amaltea sólo era vencida por Fobos, el más
interior de los dos satélites de Marte. Éste gira en torno de Marte en 7,65
horas, sólo 5 1 8 del período de Amaltea. Fobos gira, en realidad, alrededor de
Marte bastante más deprisa que Marte en torno de su eje, por lo que Fobos
constantemente se adelanta a la superficie marciana, saliendo por el Oeste y
poniéndose por el Este. Dado que Júpiter gira a una sorprendente velocidad de
9,92 horas, Amaltea no se adelanta a la superficie de Júpiter, sino que sale
por el Este y se arrastra más bien lentamente hacia el Oeste.

No obstante, Fobos, mientras gira en torno del pequeño Marte, tiene una órbita
mucho más corta que la de Amaltea, que tiene que girar alrededor del dilatado
globo del poderoso Júpiter. La órbita de Amaltea es casi veinte veces más larga
que la de Fobos. Por lo tanto, Fobos, en su órbita en torno de Marte, se
desplaza a una velocidad de 2,14 kilómetros por segundo, mientras que Amaltea,
en su rápida carrera alrededor de Júpiter, va a una velocidad de

26,3 kilómetros por segundo. (Como comparación, la Luna gira alrededor de la
Tierra a una velocidad media de sólo 1 kilómetro por segundo.)



Pero Júpiter se publicó en 1973, y en 1974 se descubrió un decimocuarto
satélite de Júpiter, por observaciones realizadas en la Tierra. Formaba parte
del grupo Himalia, como se denominan los pequeños satélites exteriores a los
galileanos, pero no totalmente exterior. Esto aumentó el número de este grupo,
pasando de tres a cuatro.

La razón de que este nuevo satélite no se descubriese antes es que era el más
pequeño. En realidad, tenía sólo 10 kilómetros de diámetro, y hasta hoy sigue
siendo el satélite más pequeño que se ha descubierto.

Se le llamó Leda, que, en la mitología griega, era una reina de Esparta que fue
pretendida por Zeus. El dios adoptó la forma de un cisne para este propósito,
dando así ocasión a cierto número de representaciones artísticas de
bestialidad. El resultado fue que Leda puso dos huevos y, de cada uno de ellos,
salieron dos bebés. El más famoso de los bebés fue el que, con el tiempo llegan
a ser conocida como Helena de Troya.

Luego llegó la época de la sondas y, en 1979, se descubrieron tres nuevos
satélites de Júpiter, todos ellos más cercanos a Júpiter que los satélites
galileanos. Esto representaba una simetría más bien desconcertante. En la
actualidad existen 16 satélites de Júpiter: 4 pequeños más cerca de Júpiter que
los galileanos; 4 galileanos grandes; 4 pequeños más alejados que los
galileanos, y 4 más pequeños y más alejados aún. Indudablemente, se producirá
un nuevo descubrimiento que romperá la simetría, lo cual me parecerá una
vergüenza, por que me gusta la simetría.

Los satélites más recientemente descubiertos, Adrastea,





[3] Tebes y Metis, poseen unos diámetros estimados de unos 25, 80 y 40
kilómetros respectivamente, y uno se pregunta por qué costó tanto descubrirlos
cuando Lisitea, con un diámetro de sólo 20 kilómetros, fue descubierto ya en
1938.

La respuesta es que esos satélites que están tan cerca quedan inundados por la
luz del gigante Júpiter, y sólo pueden verse con la visión más cercana
facilitada por las sondas. Amaltea, el único satélite de los que están cerca
que puede descubrirse desde la Tierra, tiene 170 kilómetros de diámetro, mucho
más grande que los otros, y fue descubierto ya en 1892 por un astrónomo de una
casi legendaria agudeza de visión.

El más cercano a Júpiter de todos los satélites (por lo menos según sabemos
hoy) es Metis, que se encuentra a sólo 128.000 kilómetros del centro del
planeta, aunque Adrastea se encuentra muy cerca de esto, a sólo 1 29.000
kilómetros. El período de revolución de Metis es de 7,07 horas, mientras que el
de Adrastea es de 7,13 horas. Ambos han arrebatado el récord a Fobos, puesto
que realizan su viaje en torno del planeta en media hora menos que Fobos.

La velocidad orbital de esos dos satélites interiores de Júpiter es tan rápida
como de 31,6 kilómetros por segundo, y los dos son más veloces que Júpiter en
su rotación. Si alguien pudiese mirar esos satélites desde la nubosa superficie
de Júpiter, parecerían como Fobos, salir por el Oeste y ponerse por el Este.

Avancemos ahora hasta Saturno. Durante las siete primeras décadas del siglo XX
se creyó que tenía nueve satélites. Uno de ellos, el sexto contando desde
Saturno, es un gran satélite llamado Titán. (En volumen es sólo el segundo,
detrás de Ganimedes, y aún resulta más notable al ser el único satélite
conocido que posee una atmósfera, y, además, una que es más densa que la de la
Tierra.) Titán tiene un volumen diez veces mayor que el de todos los demás
satélites saturnianos juntos.

Los otros satélites saturnianos, aunque considerablemente más pequeños que
Titán, son todos mayores que cualquiera de los satélites de Júpiter, dejando
aparte los galileanos. Rea posee un diámetro de 1.530 kilómetros, por ejemplo,
y el de Japeto es de 1.460 kilómetros. El más pequeño de los nueve satélites
saturnianos es Febe, que es el más distante y, cosa no sorprendente
considerando su tamaño, fue el último en ser descubierto. Posee un diámetro de
220 kilómetros, y se localizó por primera vez en 1898





[4].

¿Por qué carece Saturno de los realmente pequeños satélites que Júpiter posee
en abundancia? La explicación obvia es que Saturno está dos veces más lejos de
nosotros que Júpiter, y que, por tanto, los satélites más pequeños son mucho
más difíciles de ver. Probablemente existen, pero no se han descubierto.

En 1967 se informó de un pequeño satélite saturniano y se le llamó Jano, algo
que ya he descrito en «Little Found Satellite», en The Solar System and Back
(Doubleday, 1970). Por desgracia, se probó que se trataba de un error, y en
este ensayo actualizo este asunto: ¡borren a Jano!

Sin embargo, en 1980, las sondas que fotografiaron Saturno desde cerca
localizaron no menos de ocho nuevos satélites saturnianos, cada uno de ellos
más pequeño que Febe. El mayor de los ocho tiene un diámetro ligeramente
superior a los 200 kilómetros, mientras que los más pequeños tienen sólo unos
15 kilómetros de diámetro como promedio. A ninguno de los ocho se les ha puesto
aún nombre.

Cinco de los ocho satélites saturnianos recientemente descubiertos están más
cerca de Saturno que Mimas. (Mimas es el más cercano de los satélites ya
establecidos desde hace mucho tiempo; se descubrió por vez primera en 1789 y
posee un diámetro de unos 390 kilómetros).

El más cercano de los satélites saturnianos que se conocen actualmente se halla
a sólo 137.000 kilómetros del centro de Saturno (no tan cerca como el más
cercano de los satélites jovianos respecto de su planeta). Gira alrededor de
Saturno en 14,43 horas. Esto es el doble del período de los satélites de
Júpiter más próximos, pero Saturno, al ser menor que Júpiter tiene un campo
gravitatorio menos intenso.

De los cinco satélites más cercanos a Saturno, los dos menos cercanos ofrecen
algo verdaderamente asombroso y, en realidad, hasta ahora sin precedentes. Son
coorbitales, es decir, que comparten la misma órbita, persiguiéndose sin cesar
uno a otro alrededor de Saturno. Se encuentran a una distancia de 151.000
kilómetros de Saturno, y giran en un período de 16,68 horas. Fueron esos dos
satélites, que se tomaron por un solo cuerpo, los que se dieron a conocer en
1967 como tratándose de Jano.

Los tres restantes satélites saturnianos, recientemente descubiertos, que se
encuentran dentro del sistema de los nueve satélites conocidos desde hace
tiempo, representan otras situaciones sin precedentes.

Se descubrió que el satélite Dione, conocido desde hace mucho tiempo,
localizado por primera vez en 1684, poseía un insospechado pequeño compañero
coorbital. Mientras que Dione tiene un diámetro de 1.120 kilómetros, el
compañero (al que debería llamársele Dione-B), posee un diámetro de sólo unos
30 kilómetros. Dione-B gira en torno de Saturno en un punto 60 grados por
delante de Dione, de modo que Saturno, Dione y Dione-B se encuentran en los
vértices de un triángulo equilátero. Ésta es la «situación troyana» (véase «The
Trojan Hearse», en View from a Height. Doubleday, 1963).

Hasta 1980, los únicos ejemplos conocidos de situación troyana incluían el Sol,
Júpiter y algunos asteroides coorbitales con Júpiter. Algunos de estos
asteroides giraban alrededor del Sol 60 grados por delante de Júpiter, en la
posición «L-4», y algunos a 60 grados por detrás de Júpiter, en la posición
«L-5».

Dione-B se halla en la posición L-4 respecto a Dione.

Pero aún más asombroso resulta el caso de Tetis, que se descubrió el mismo año
que Dione y tiene un diámetro de 1.060 kilómetros. Los dos restantes satélites
saturnianos recientemente descubiertos, cada uno de ellos con un diámetro de 25
kilómetros, son ambos coorbitales con Tetis.

Uno, Tetis B, se encuentra en la posición L-4 respecto del mismo, y el otro,
Tetis-C, se halla en la posición L-5.

De una forma clara, la familia de satélites de Saturno es la más rica y más
compleja en el Sistema Solar, por lo que conocemos hasta ahora. Esto
probablemente es parte del mismo fenómeno que proporciona a Saturno los anillos
más espectaculares del Sistema Solar.



No se han producido nuevos descubrimientos de satélites de Urano y Neptuno en
el último tercio de siglo (ya que aún no se ha enviado sondas hasta ellos),
aunque los anillos de Urano han sido recientemente descubiertos (véase «Rings
and Things», en The Road to Infinity, Doubleday, 1979).

Urano tiene cinco satélites. Cuatro de ellos se conocen desde hace más de un
siglo, y poseen diámetros que van de 1.000 a 2.000 kilómetros. El quinto es
Miranda, más cercano y más pequeño que los otros. Fue hallado en 1948, posee un
diámetro de unos 300 kilómetros y gira alrededor de Urano a una distancia de
unos 130.000 kilómetros.

Neptuno tiene dos satélites. Uno de ellos es un satélite grande, Tritón, con un
diámetro de unos 4.400 kilómetros de modo que es más grande que nuestra Luna.
Fue hallado sólo unas semanas después de que se descubriera el mismo Neptuno.

El segundo satélite de Neptuno, Nereida, se descubrió en 1949 y posee asimismo
un diámetro de unos 300 kilómetros. Nereida es notable por poseer la órbita más
excéntrica de todos los satélites. En un extremo de su órbita llega a sólo
1.390.000 kilómetros de Neptuno, mientras que en el otro extremo se aleja hasta
una distancia de 9.734.000 kilómetros.

Y lo que es más, los últimos datos que he podido encontrar respecto del período
orbital de Nereida han sido los de 365,21 días, 0,9999 de año.

Imagínense qué hubiera sucedido si Neptuno y Nereida fuesen visibles sin ayuda
de instrumentos y los seres humanos pudiesen ver este último girando en torno
del primero. No hubiera llevado mucho tiempo, incluso a los hombres
prehistóricos, comprobar que Nereida marcaba con gran precisión el ciclo de las
estaciones.

Hubiéramos acabado con un bonito calendario neptuniano completo, hasta con años
bisiestos, mucho antes del neolítico. Sólo el cielo sabe lo que esto hubiera
impulsado las matemáticas, la ciencia y la tecnología, y dónde estaríamos ahora
como resultado de todo ello.

Si eso hubiese sucedido, la existencia de Nereida habría sido un claro ejemplo
de la benigna providencia de Dios, y los científicos hubieran encontrado muy
duro decir «Oh, se trata sólo de una coincidencia». Sin embargo, dado que la
benigna providencia dispuso que esta asombrosa coincidencia siguiese invisible
hasta nuestra actual generación, el asunto no se planteó.



Extrañamente, el descubrimiento de satélite más asombroso de los últimos años
no tiene nada que ver con las sondas. Se realizó desde la superficie de la
Tierra. El 22 de junio de 1978 se descubrió que Plutón, el más distante de los
planetas, poseía un satélite. Se le llamó Caronte, por el barquero que
transportaba las sombras de los muertos al otro lado de la laguna Estigia,
hacia el reino de Plutón, en el Hades.

El satélite resultó ser sorprendentemente grande: tiene, al parecer, un
diámetro de 1.300 kilómetros.

El diámetro del mismo Plutón ha sido materia de controversia desde que se
descubriera en 1930. Antes de su descubrimiento, se suponía que otro planeta
exterior seria un gigante gaseoso, como los demás. Una vez descubierto, se vio
que Plutón era sorprendentemente apagado, por lo que tenía que ser más pequeño
de lo que se creía. Con cada nueva evaluación, su tamaño disminuía. Llegó a
parecer no más grande que la Tierra, y luego no más grande que Marte.

Una vez descubierto Caronte, la masa total de Plutón y Caronte pudo ser
calculada a partir del período de revolución y de la distancia entre ambos. Por
el brillo comparativo de los dos, pudieron determinarse las masas separadas y,
suponiendo que la densidad seria la del hielo, se pudo estimar el diámetro. Se
descubrió entonces que Plutón tenía un diámetro de unos 3.000 kilómetros y que,
por 10 tanto, era un poco más pequeño que Europa, el más pequeño de los grandes
satélites.

Hagamos ahora una aclaración.

Cada planeta es más voluminoso que todo el material de sus satélites. Mercurio
y Venus son infinitamente más voluminosos que sus satélites, puesto que no
tienen ninguno, mientras que Marte es 15.500.000 veces más voluminoso que sus
dos satélites juntos. Júpiter es unas 8.500 veces más voluminoso que todos sus
satélites reunidos, y Saturno es unas 8.800 veces más voluminoso que su sistema
de satélites.

Urano lo hace algo mejor, al no tener grandes satélites, y es cerca de 10.000
veces más voluminoso que su sistema de satélites. Neptuno, con un gran
satélite, y al ser él mismo el más pequeño de los cuatro grandes gigantes
gaseosos, lo hace un poco peor y es sólo 1.350 veces más grande que sus dos
satélites juntos.

Podemos sacar como conclusión, a partir de este registro de siete de los nueve
planetas, que existe una ley cósmica según la cual cualquier planeta debe ser,
por lo menos, 1.000 veces más voluminoso que todos sus satélites juntos.

Pero luego llegamos a la Tierra, y ¡atención! La Tierra es sólo 50 veces más
voluminosa que la Luna.

Los terrícolas están, con razón, orgullosos de esto, y el poseer un satélite
tan grande ha resultado muy útil, considerando lo que ha ayudado al avance
intelectual de la especie humana (véase «The Triumph of the Moon», en The
Tragedy of the Moon, Doubleday, 1973). Creemos ser lo más cercano a un planeta
doble en el Sistema Solar, e incluso publiqué una vez un libro acerca del
sistema Tierra-Luna, al que llamé The Double Planet (AbelardSchuman, 1960).

Pues bien, he aquí un caso en el que tengo que actualizar incluso el titulo de
un libro, puesto que Plutón es sólo doce veces más voluminoso que su satélite,
y Plutón-Caronte está más cerca de un planeta doble que la Tierra-Luna.

Es una lástima.





VI. EL BRAZO DEL GIGANTE





Además de ser un escritor prolífico, soy un orador prolífico, y en los últimos
tiempos he dado casi una charla por semana. Sin embargo, hay una diferencia en
mis dos carreras: mientras existen críticos profesionales de la literatura, no
hay críticos profesionales de la oratoria.

Créanme, no me quejo de esta carencia. Comparto con todos los demás escritores
que conozco (vivos y muertos) una pobre opinión respecto de los críticos de
profesión, y no pido nuevas variedades de la especie. Y en lo que se refiere a
mis discursos, me encanta aceptar los aplausos y ovaciones por lo que son; me
complace que haya gente que se me acerque para decirme cosas agradables, y (la
mejor indicación de todas) me gratifica que la persona que me persuadió para
dar la charla me entregue el cheque con una amplia sonrisa en el rostro

No necesito que además alguien se gane la vida explicando lo que hice mal. Y,
sin embargo, de vez en cuando aparece algo de esto de forma inesperada. (O,
como dijo una vez algún olvidado filósofo: «No puedes vencerles a todos».).

Hace algunas semanas me pidieron que diese una charla nocturna en una
convención de la Asociación Americana de Psiquiatras. Cuando les pregunté qué
diantres les podía contar a un par de millares de psiquiatras, considerando que
no sé nada de psiquiatría, se me respondió de una forma vaga:

—De cualquier cosa que usted desee.

Así que hablé de robots y de su efecto sobre la sociedad, y lo que podría
reservarnos el futuro de la robótica. Presenté el tema contándoles con detalles
humorísticos cómo llegué a escribir mis historias de robots y recité las Tres
Leyes de la Robótica, y, como suelo hacer, me mostré muy seguro de mí mismo y
muy poco humilde.

La conferencia pareció ser un gran éxito, y yo quedé complacido. Sin embargo,
mi querida esposa Janet (que es también psiquiatra), se había sentado en la
última fila para no ser tan visible, y me dio la impresión de que estaba un
poco deprimida. Me di cuenta de ello, de modo que se lo pregunté y ella me lo
explicó.

Después de haber estado yo perorando durante un rato (me contó Janet), una
mujer que se sentaba cerca de ella comenzó a hablar en voz alta a su vecina.
Janet le llamó la atención y le pidió con mucha educación que bajase la voz.

A lo cual la mujer respondió con desprecio:

—¿Por qué? No me diga que lo encuentra interesante. No son más que disparates
narcisistas.

Naturalmente me reí, y le dije a Janet que se olvidase del asunto. Nunca he
esperado complacer a todo el mundo.

Asimismo, no sabía si la mujer era también psiquiatra o simplemente había
entrado porque sí, pero, sin duda, no empleaba la palabra «narcisista» en un
sentido psiquiátrico. Lo había usado en su sentido informal y cotidiano de
«anormalmente interesado en sí mismo, con desprecio de los demás», y captar el
hecho de que yo soy un narcisista en este sentido no constituye ningún gran
descubrimiento.

En realidad, casi todo el mundo es narcisista en este sentido, por lo general
con menos excusas de las que yo puedo fabricar. Por ejemplo, su crítica fue más
bien desagradablemente narcisista, ya que expresaba de modo deliberado su
desagrado hacia mí de una forma que molestaba a los que pudieran estar
interesados por mi conferencia.

Ni siquiera tenemos que limitamos a los individuos. La especie humana es, en
conjunto, increíblemente narcisista y, de una manera general, se considera a sí
misma la única razón para la existencia del Universo. Su interés por algo más
se limita casi por completo a objetos que les impresionan y en proporción
directa al alcance de esa mencionada impresión.

Por ejemplo, se estima que existen 1022 estrellas en el Universo conocido y, no
obstante, la Humanidad fija por lo común su atención en sólo una de ellas (el
Sol), con una casi total exclusión de las otras, sólo porque resulta que es la
que se encuentra más cerca de nosotros.

Para ilustrar lo que quiero decir, estaremos todos de acuerdo al instante en
que el Sol es con mucho, la estrella de mayor importancia por su tamaño
aparente. A fin de cuentas, es la única estrella que aparece en forma de disco
y no como un simple punto de luz. Muy bien, pero ¿cuál es la segunda estrella
más grande en tamaño aparente? ¿Cuántas personas lo saben? ¿O les interesa?

Por lo tanto, para desalentar el narcisismo, abordaré ahora la cuestión de la
segunda estrella más grande en tamaño aparente.



La constelación de Orión se considera en general, la más bella de nuestro
firmamento septentrional porque es tan grande, de forma tan interesante y tan
rica en brillantes estrellas. El nombre de la constelación se remonta a los
griegos, que poseían multitud de mitos acerca de un cazador gigante llamado
Orión. Fue amado por Artemisa, la diosa de la caza, pero el hermano de ésta,
Apolo, la obligó a matarle. Entristecida y arrepentida, lo trasladó al
firmamento como constelación.

Normalmente, se representa al cazador gigante sujetando un escudo con el brazo
izquierdo para detener el ataque de Tauro (el Toro), mientras con el brazo
derecho sostiene en el aire su clava, dispuesto a matar con ella al furioso
animal. Una brillante estrella señala cada uno de esos brazos. Más abajo, una
brillante estrella marca cada una de sus piernas. Entre ambos hay una línea
horizontal de tres estrellas luminosas que señalan su cintura (cinturón de
Orión).

La más brillante de las estrellas de Orión es una de un característico color
rojo y que brilla en su brazo derecho. Su nombre astronómico es Alfa de Orión
(Alpha Orionis).

En la Alta Edad Media, los victoriosos árabes se apropiaron de la ciencia
griega, incluyendo la descripción del firmamento que los griegos habían hecho,
y vieron también la constelación de Orión en la forma de un cazador gigante.
Los árabes tenían la sensata costumbre de denominar a las estrellas según su
posición en una constelación, por lo que llamaron a Alfa de Orión Yad al-yawza,
que significa «brazo del gigante». Por alguna razón, algún traductor europeo de
un texto árabe transliteró los símbolos árabes como bayt al-yawza («casa del
gigante», lo cual carece de sentido), y lo deletreó con caracteres como
Betelgeuse, que sigue siendo su nombre hasta hoy.

En mi juventud, tenía la impresión de que se trataba de una palabra francesa, y
trataba de pronunciarla de esa forma. No sentía más que desprecio hacia
cualquiera que fuese tan analfabeto como para pronunciarla de otra manera.
Imaginen mi vergüenza cuando salí de mi error.

Pues bien, en realidad, Betelgeuse es más conocida en detalle que cualquier
otra estrella, excepto nuestro Sol.

¿Por qué?

Consideremos que (siendo iguales todas las demás cosas) una estrella cercana es
más probable que sea conocida con detalle que una que esté lejos, del mismo
modo que la Luna fue conocida en sus detalles superficiales mucho antes de que
lo fuese Marte.

Una vez más (siendo iguales las demás cosas), una estrella grande es más
probable que sea conocida con cierto detalle que una pequeña; igual que la
superficie de Júpiter se conocía con más detalle, hasta hace poco, que la del
mucho más pequeño, pero más cercano, Fobos.

Si queremos, pues, saber detalles de alguna estrella que no sea nuestro Sol,
debemos elegir una que sea grande y esté cerca.

Betelgeuse no es una estrella realmente cercana; es probable que existan
2.500.000 estrellas más próximas a nosotros. De todos modos, considerando que
puede haber 300.000.000.000 de estrellas en la galaxia, existen 120.000 veces
más estrellas en nuestra galaxia que están más lejos que Betelgeuse que
estrellas que están más cerca. Por lo tanto, podemos decir que Betelgeuse se
encuentra en nuestra vecindad estelar.

Por otra parte, también podemos llegar a la conclusión de que Betelgeuse es
inusualmente grande, sólo mirándola sin ayuda de instrumentos. Esto puede
parecer extraño, dado que todas las estrellas parecen simples puntos de luz, no
sólo al ojo sin ayuda de instrumentos, sino también con el mayor de los
telescopios. ¿Cómo, pues, podemos decir con tanta facilidad que un punto de luz
es mayor que otro punto, sólo mirándolo sin la ayuda de instrumentos?

La respuesta es que las estrellas rojas son rojas porque sus superficies están
relativamente frías. Debido a que esas superficies están frías, tienen que ser
confusas por unidad de área. Si no obstante las estrellas rojas son muy
brillantes, ello debe ser porque están excepcionalmente cerca de nosotros, o,
si no es así, porque la superficie total es excepcionalmente grande.

Así, la estrella Alfa del Centauro C (Próxima Centauro) está más cerca de
nosotros que cualquier otra estrella en el firmamento, pero incluso así es
insuficientemente próxima para ser visible al ojo sin ayuda de instrumentos. Es
roja y fría, y además pequeña.

Betelgeuse es tan roja como Alfa del Centauro C, y está 150 veces más lejos que
Alfa del Centauro C, pero Betelgeuse no es sólo visible sin ayuda de
instrumentos, sino que se halla entre la docena de estrellas más brillantes en
el cielo. Por lo tanto, debe deducirse por este solo hecho que tiene una
superficie enorme.

De este modo debió de razonar el físico estadounidense, nacido en Alemania,
Albert Abraham Michelson (1852-1931). En 1881, Michelson había inventado el
interferómetro, con el que se puede medir con gran exactitud, la forma en que
dos rayos de luz se interfieren mutuamente, eliminando las ondas de luz de uno
las del otro en algunos lugares y reforzándolas en otros (dependiendo de si una
onda sube mientras la otra baja, o ambas suben y bajan juntas). El resultado
fue una especie de alternancia de franjas de luz y oscuridad, y se pudieron
deducir muchas cosas por la anchura de las franjas.

Si una estrella tal como la vemos nosotros en el firmamento fuese un verdadero
punto, con un diámetro cero, toda la luz llegaría en un solo rayo y por lo
tanto no habría ninguna interferencia. Sin embargo, si una estrella tuviese un
diámetro finito (aunque pequeño), la luz procedente de un lado de la estrella y
la luz procedente del otro lado serían dos rayos separados que convergerían
hacia el punto de observación, formando un ángulo muy pequeño. Los dos rayos
separados interferirían uno con otro, pero lo harían muy ligeramente y la
interferencia sería muy difícil de descubrir. Naturalmente, cuanto más grande
fuera la estrella, más grande seria el ángulo (aunque seguiría siendo muy
pequeño) y mejor la posibilidad de descubrir la interferencia.

Michelson usó un interferómetro especial, de 6 metros de longitud, que podía
detectar efectos particularmente pequeños. También empleó el entonces nuevo
telescopio de 2,5 metros, el mayor del mundo. En 1920 se midió el diámetro
aparente de Betelgeuse. Fue la primera estrella que demostró, mediante una
medición real, que era más que un punto de luz, y la noticia apareció en
primera plana en el Times de Nueva York.

El diámetro aparente de Betelgeuse resultó ser de unos 0,02 segundos de arco.

¿Qué anchura representa esto? Si imaginamos 100.000 puntos brillantes igual que
Betelgeuse uno al lado de otro y tocándose, tendríam05 una línea delgada y
brillante con una longitud igual a la anchura de la Luna llena cuando se halla
más cerca de la Tierra. Si imaginamos 65.000.000 de puntos como Betelgeuse uno
al lado del otro y tocándose, tendríamos una delgada línea brillante rodeando
el cielo como un fulgurante ecuador.

Y lo que es más, si imaginamos un número mayor de puntos brillantes, cada uno
de ellos del tamaño aparente de Betelgeuse, y los imaginamos formando una masa
compacta en la esfera del cielo, harían falta 1 1/3 trillones de ellos
(1.330.000.000.000.000) para convertir el firmamento en un compacto resplandor
rojo en torno de la Tierra.

Cuando se piensa en esto y se tiene en cuenta que, en la realidad, el cielo
está sólo salpicado de 6.000 estrellas visibles, uno se percata de cuán vacío
se halla realmente el firmamento, aun tenido en cuenta el Sol, la Luna y los
seis planetas visibles.

Betelgeuse es una estrella variable, es decir, que su brillo varía con el
tiempo. Y más aún, no existe una periodicidad simple en la variación, por lo
que se trata de una «variable irregular». Su brillo medio es de magnitud 0,85,
pero en ocasiones brilla hasta 0,4 y en otras ocasiones desciende hasta 1,3.

La razón de esta variabilidad no es misteriosa. El simple hecho de que una
estrella sea una gigante roja significa que se encuentra en su fase final como
estrella extendida. Dentro de poco ya no será capaz de soportar la masa de sus
capas externas por la energía de las reacciones de fusión en sus profundidades
y la estrella se desmoronará (con o sin explosión). El hecho de que, Betelgeuse
parpadee por así decirlo, constituye otra indicación de que el final está
cerca. El parpadeo se debe a la turbulencia y diversas inestabilidades que cabe
esperar en una estrella que tiene problemas para autoabastecerse con suficiente
calor para mantenerse en expansión.

Si esto es así, debería haber cambios perceptibles en el diámetro de Betelgeuse
al ser medido con el interferómetro, y los hay. El diámetro aparente varía de
0,016 a 0,023 segundos de arco.



A fin de decir lo grande que es realmente Betelgeuse, en unidades absolutas, a
partir de su tamaño aparente, se debe conocer su distancia, y eso no es fácil.
Las distancias estelares superiores a los 30 pársecs (100 años luz), más o
menos, resultan difíciles de determinar.

La última (y presumiblemente más de fiar) cifra que he podido encontrar para la
distancia de Betelgeuse es de 200 pársecs (650 años luz).

Para que la esfera de una estrella aparezca como de un diámetro de 0,02
segundos de arco, aun cuando se encuentre a una distancia de 200 pársecs,
debería tener un diámetro real de unos 600.000.000 de kilómetros, si mis
cálculos son correctos. Así pues, Betelgeuse tiene un diámetro, como promedio,
430 veces mayor que el diámetro del Sol. Su volumen sería entonces 80.000.000
de veces el de nuestro Sol, lo que significa que si imagináramos a Betelgeuse
como una esfera hueca, podríamos echar en ella 80.000.000 de esferas del tamaño
del Sol para que esta gran esfera se llenase (suponiendo que las pequeñas
esferas formasen un conglomerado de modo que no quedase espacio entre ellas).

Si imaginásemos a Betelgeuse en el lugar de nuestro Sol, su superficie se
localizaría cerca de la órbita de Marte. La posición de la Tierra se
encontraría a siete décimos de la distancia desde el centro de Betelgeuse a su
superficie.

Podemos conseguir ahora una representación más impresionante de su pulsación.
Cuando Betelgeuse se expande a su máximo, su diámetro aumentaría hasta unos
725.000.000 de kilómetros, o casi unas 500 veces el del Sol. En su mínimo,
seria aún de 500.000.000 de kilómetros, o 360 veces el del Sol.

En plena expansión, la superficie de Betelgeuse, si la imaginásemos en el lugar
de nuestro Sol, se hallaría en el cinturón de asteroides. Es tres veces más
voluminosa en su máximo que en su mínimo. Si nos la imaginamos respirando con
fuerza porque está cerca del fin de su carrera como estrella expandida, su
respiración es muy fuerte.

Dando por supuesto que, en realidad, Betelgeuse es una estrella gigante
(pertenece, de hecho, a una clase de estrellas a las que llamamos «gigantes
rojas»), ¿cómo puede compararse en tamaño aparente con otras estrellas que son
más pequeñas, pero que están más cerca?

Por ejemplo, ya he dicho que Alfa del Centauro C es la estrella más próxima a
nosotros. Forma parte de un grupo de tres estrellas, la mayor de las cuales es
Alfa del Centauro A. Alfa del Centauro A es casi exactamente del tamaño de
nuestro Sol, y a su distancia de 1,35 pársecs (1/150 la de Betelgeuse) su
diámetro aparente sería sólo de 0,0035 segundos de arco, menos de un quinto del
de Betelgeuse. Aunque Alfa del Centauro A esté tan cerca, su diminuto tamaño no
le permite mostrarse tan grande como la distante y gigante Betelgeuse.

Sirio es más grande que Alfa del Centauro A, pero se halla aún más lejos y su
tamaño aparente es de sólo unos 0,0032 segundos de arco. Arturo tiene un
diámetro de 32.000.000 de kilómetros (23 veces el del Sol), pero se encuentra a
11 pársecs de distancia y su diámetro aparente es de 0,0095 segundos de arco,
mientras que Aldebarán posee un diámetro de 50.000.000 de kilómetros (36 veces
el del Sol), pero está a una distancia de 16 pársecs, por lo que su diámetro
aparente es de 0,011, exactamente la mitad que el de Betelgeuse.

Por lo tanto, no existe ninguna estrella lo suficientemente grande o lo
suficientemente cercana (o ambas cosas) para rivalizar con Betelgeuse. La que
se acerca más es otra gigante roja, Antares, en la constelación del Escorpión.
Se encuentra a una distancia de 130 pársecs, es decir, más cercana que
Betelgeuse, pero aun así es levemente más apagada que Betelgeuse, a pesar de la
ventaja de estar más cerca, y por lo tanto debe ser apreciablemente más pequeña.

En realidad, Antares, a la distancia que está, tendría un diámetro aparente de
0,002 segundos de arco, lo que es igual al valor medio de Betelgeuse, pero
Antares no late de manera apreciable. Por tanto, es más pequeña en tamaño
aparente que Betelgeuse en su máximo.

En resumen, de todas las estrellas, Betelgeuse es la segunda, después del Sol,
en tamaño aparente.

Betelgeuse tiene una temperatura superficial de 3.200º K, en comparación con la
temperatura superficial de nuestro Sol de 5.700º K. Betelgeuse se encuentra al
rojo vivo, mientras que nuestro Sol está al rojo blanco.

Si la temperatura superficial del Sol descendiese de repente a 3.200º K, aparte
del hecho de que su luz enrojecería, ofrecería una iluminación total de una
intensidad de sólo 1/43 de la actual.

Sin embargo Betelgeuse tiene una superficie 185.000 veces mayor que la del Sol,
y aunque cada porción del tamaño del Sol da sólo 1/43 de la iluminación de
nuestro Sol, la estrella entera resplandece con una luz 4.300 veces mayor que
la del Sol.

Los astrónomos emplean el término «magnitud absoluta» para representar el
brillo que una estrella mostraría si se encontrase a 10 pársecs de la Tierra.
Si pudiésemos ver nuestro Sol desde una distancia de 10 pársecs, tendría una
magnitud absoluta de 4,7, con lo que sería más bien apagada y una estrella nada
espectacular.

Por otra parte si, Betelgeuse avanzase hacia nosotros hasta una distancia de 10
pársecs, resplandecería con una magnitud absoluta de —5,9. Brillaría, rojiza,
con un brillo 4 1/3 veces el de Venus en su máxima brillantez.

Tendría entonces un diámetro aparente de 0,4 segundos de arco, lo que sería
enorme para una estrella (aparte de nuestro Sol), pero seguiría pareciendo
meramente un punto de luz. A fin de cuentas, el planeta Júpiter tiene un
diámetro aparente de 50 segundos de arco, y aún así parece un simple punto
luminoso si se mira sin ayuda de instrumentos.



A pesar del enorme tamaño y brillo de Betelgeuse, en cierto modo no es por
completo el gigante que parece. ¿Qué pasa, por ejemplo, con su masa, la
cantidad de materia que contiene?

Sin duda tiene más masa que el Sol, pero no enormemente más. En realidad, se
estima que tiene 16 veces más masa que el Sol. Sólo 16 veces.

Esta masa de 16 Soles se extiende en un volumen que es, como promedio,
80.000.000 de veces el del Sol. La densidad media de Betelgeuse, por tanto,
debe ser 16/80.000.000 o 1/5.000.000 la del Sol.

Esto es mucho menos de lo que cabía esperar, puesto que representa más o menos
1/4.500 de la densidad del aire que estamos respirando. Cuando Betelgeuse se
encuentra en su máxima expansión, la cantidad de materia que contiene se
extiende en un volumen aún más grande, y su densidad media es entonces de
1/7.000 la del aire.

Si pudiésemos absorber en un contenedor todo el aire menos el 1/4.500, estaría
justificado que hablásemos del resultado como un vacío. No sería un vacío
absoluto, ni siquiera uno muy fuerte, pero sería suficiente vacío en el sentido
práctico cotidiano de esa palabra. Sería bastante natural, pues considerar a
Betelgeuse (o a cualquier gigante rojo) como una especie de vacío al rojo vivo.

De todos modos, Betelgeuse (o cualquier estrella) no es densa de modo regular
en toda su masa. Una estrella es menos densa en su superficie, y esa densidad
aumenta, con mayor o menor regularidad, a medida que se penetra debajo de esa
superficie, y posee, naturalmente, la mayor densidad en el centro. La
temperatura también llega al máximo en el centro.

Una estrella comienza como una bola de hidrógeno, principalmente, y es en el
centro donde la temperatura y la densidad son mayores, donde los núcleos se
aplastan mutuamente con suficiente fuerza para fundirse. Así pues, es en el
Centro donde el hidrógeno se fusiona en helio y se produce energía. El helio se
acumula formando un núcleo de helio que crece de modo regular a medida que
prosigue la fusión.

La fusión del hidrógeno sigue teniendo lugar fuera del núcleo de helio, donde
el hidrógeno se encuentra a su mayor temperatura y densidad; y el núcleo de
helio, a medida que crece, se hace más caliente y más denso. Finalmente,
después de millones o incluso miles de millones de años, la temperatura y
densidad en el núcleo de helio se hacen lo suficientemente grandes para forzar
incluso a los núcleos de helio estables a fusionarse en núcleos de carbono y de
oxígeno. (Los núcleos de carbono se componen de tres núcleos de helio, y los
núcleos de oxígeno de cuatro.)

La nueva oleada de calor desarrollada por el inicio de la fusión del helio hace
que la estrella (que, durante toda la fusión del hidrógeno, ha permanecido
relativamente inalterada en apariencia) se expanda, por lo que su superficie se
enfría. En otras palabras, la estrella, que hasta entonces ha sido un objeto
relativamente pequeño al rojo blanco, de repente se expande hasta ser un
gigante rojo al formarse y crecer en el centro, un nuevo núcleo de carbono y
oxígeno.

Esta es pues la situación con Betelgeuse. En su centro se halla un núcleo de
carbono-oxígeno que está a una temperatura de 100.000 ºK (en comparación con
los 15.000.000 ºK en el centro del Sol). Esto no representa calor suficiente
para hacer que el carbono y oxígeno se fusionen en núcleos más complicados.

Este núcleo (como los mejores astrónomos pueden decir por cálculos efectuados
con ordenador basados en lo que se conoce de la teoría de la reacción nuclear)
tiene tal vez dos veces el diámetro de la Tierra y una densidad de unos 50.000
gramos por centímetro cúbico, o más de 2.000 veces la del platino terrestre.
Ciertamente, Betelgeuse no es en todo su interior un vacío al rojo vivo.

Tal vez 1/50 de la masa total de Betelgeuse está comprimida en ese pequeño
núcleo. Alrededor del núcleo hay una capa de helio, tal vez de diez veces el
volumen del núcleo, que alberga otro 1/50 de la masa total. Y en el exterior de
la capa de helio se hallan las rarificadas regiones externas que son aún, en
gran medida, hidrógeno. El helio continúa fusionándose en la superficie del
núcleo de carbono-oxígeno, y el hidrógeno sigue fusionándose en los límites de
la capa de helio.

El hidrógeno que se halla en el fondo de las más bien raras regiones exteriores
hidrogenosas de Betelgeuse no puede fusionarse a la enorme velocidad con que se
hubiese fusionado en el centro. El helio, al fusionarse en condiciones más
densas y cálidas, produce mucha menos energía por núcleo. Las dos fusiones
juntas apenas producen suficiente calor, por tanto, para mantener a Betelgeuse
en su estado de enorme distensión. De vez en cuando existe, aparentemente, un
déficit, y la estrella comienza a contraerse. La contracción comprime el
hidrógeno y el helio y acelera la fusión, por lo que la estrella se expande de
nuevo.

A medida que pasa el tiempo, en el núcleo tienen lugar ulteriores reacciones,
produciendo cada una menos energía por núcleo que la anterior, de modo que la
situación se hace cada vez peor. Con el tiempo, cuando se forman núcleos de
hierro en el centro, ya no hay forma de que tenga lugar aquí, una ulterior
fusión productora de energía, y las contracciones periódicas se hacen cada vez
más extremas. Finalmente, hay un último fallo y la estrella se derrumba total y
permanentemente.

El súbito derrumbamiento comprimirá todo el material fusionable que aún queda,
y la mayor parte del mismo desaparecerá al instante para producir una
explosión. Cuanto más masa tenga la estrella, más repentino será el
derrumbamiento y más catastrófica la explosión.

Una estrella del tamaño del Sol se derrumbará y siseará, lanzando una pequeña
porción de su capa más externa al espacio. Esto formará una capa esférica de
gas en torno de la estrella derrumbada. Vista desde lejos, la capa parecerá un
anillo de humo y el resultado constituye una nebulosa planetaria. La estrella
derrumbada en el centro será muy pequeña y densa: una enana blanca.

Una estrella considerablemente más grande que el Sol como Betelgeuse explotará
con la suficiente violencia para ser una supernova. Los restos comprimidos se
derrumbarán sobrepasando el estadio de enana blanca y se convertirán en una
estrella neutrónica o incluso, tal vez, en un agujero negro.

Sin duda, éste es el destino que hay que esperar de Betelgeuse en un futuro
comparativamente próximo, pero para los astrónomos, el «futuro próximo» podría
significar 100.000 años, así que no pasen las noches en vela para verlo. Existe
por lo menos otra estrella que parece que puede ganar en esto a Betelgeuse
(véase «X» representa lo desconocido), e incluso en ese caso pueden pasar unos
cuantos miles de años antes de que explote.

Sin embargo, aun excluyendo una supernova, hay más cosas interesantes que decir
de Betelgeuse, lo cual haré en el siguiente capítulo.





VII. EL MUNDO DEL SOL ROJO





Cuando era un poco más joven que ahora, y estaba en la escuela superior júnior,
solía leer revistas de ciencia-ficción que podía encontrar en el mostrador de
las revistas de la confitería de mi padre.

Las historias que me llamaban particularmente la atención, las volvía a contar
a un grupo de absortos compañeros de clase durante la hora del almuerzo, y el
ejemplo con más éxito de esas narraciones de segunda mano fue una historia que
me gustaba mucho llamada «El mundo del Sol Rojo», que apareció en el número de
diciembre de 1931 de Wonder Stories.

En aquel tiempo no tomé nota del nombre del autor, porque en realidad tampoco
era muy conocido. De hecho, era la primera historia que publicaba.

Fue sólo muchos años después, tiempo durante el cual me convertí en
corresponsal y buen amigo del famoso escritor de ciencia-ficción Clifford D.
Simak, cuando, al conseguir el valiosísimo índice de Donald Day de historias de
ciencia-ficción, de 1926 a 1950, vi «El mundo del Sol Rojo» y descubrí que se
trataba nada menos que del esfuerzo inaugural de Cliff. (Y ahora, más de medio
siglo después, todavía se encuentra en activo, produciendo aún material de
primera, y ha sido elegido como Gran Maestro por los Escritores de
ciencia-ficción de Estados Unidos.)

Siempre ha sido motivo de infinita satisfacción para mí el que, cuando era sólo
un chiquillo aún no adolescente, ya reconociese la grandeza en la primera
historia de un autor.

Así pues, pueden imaginarse el gran placer con que llegué a percatarme, cuando
planeaba este ensayo, de que el título más lógico para el mismo sería el que
Cliff dio a su primer relato. Por lo tanto, empleo este título en homenaje a un
viejo amigo.

La historia de Cliff era el relato de un viaje a través del tiempo, y el Sol
Rojo del que hablaba era nuestro propio Sol en un futuro lejano. No obstante,
mi Sol Rojo es la estrella de la que he tratado con considerable detalle en el
capítulo precedente: Betelgeuse, el gigante rojo.

La cuestión es la siguiente: Si consideramos a Betelgeuse como el Sol Rojo,
¿podría haber un mundo que girase en tomo de él? Con esto no me refiero a un
planeta, llano y sencillo, sino a uno que tuviera un carácter como el de la
Tierra y con vida inteligente en él. La vida no tiene por qué ser de tipo
humanoide, naturalmente, pero debería ser vida tal y como la conocemos: ácido
nucleico y proteínas, formado en un fondo acuoso.

Veamos, pues... Supongamos que tenemos un planeta parecido a la Tierra para
empezar (y tengo la fuerte tentación de emplear la voz «terroide» como sinónimo
de parecido a la Tierra, aunque no creo que esto se haya hecho nunca).

Un planeta terroide no puede encontrarse demasiado cerca de una estrella, o su
océano herviría; tampoco puede hallarse demasiado lejos de una estrella, puesto
que su océano se helaría y, en uno u otro caso, la vida terroide resultaría
imposible.

Dado que, como promedio, Betelgeuse es una estrella con 430 veces el diámetro
de nuestro Sol, sabemos que nuestro planeta terroide debería hallarse mucho más
lejos de ella de lo que lo está la Tierra del Sol. Como primera aproximación,
situemos el planeta a una distancia a la que Betelgeuse tenga el tamaño
aparente en su firmamento igual que nuestro Sol en el cielo de la Tierra.

En ese caso, el planeta debería encontrarse a una distancia media de
63.500.000.000 kilómetros de Betelgeuse (1/15 de un año luz), o más de diez
veces la distancia media de Plutón respecto de nuestro Sol.

Si existiese un planeta a esa distancia de nuestro Sol, haría una revolución
completa alrededor del Sol en unos 8.742 años terrestres.

Sin embargo, Betelgeuse tiene 16 veces más masa que nuestro Sol, por lo que
haría girar a este planeta distante mucho más deprisa en tomo de su órbita de
lo que nuestro Sol podría. El planeta que estamos imaginando para Betelgeuse
efectuaría una revolución completa alrededor de su estrella distante pero con
mucha masa en no menos de una cuarta parte del tiempo que hubiera tardado en
girar alrededor de nuestro Sol. Su período de revolución en tomo de Betelgeuse
sería, pues, de 2.185 años terrestres.

¿Tiene importancia que el período de revolución del planeta fuese de más de dos
milenios de duración?

Supongamos que es igual que nuestra Tierra. Imaginemos que su órbita es
circular, que gira en tomo de su eje en 24 horas, que su eje está inclinado
como el nuestro, etcétera. En ese caso tendría estaciones como las nuestras,
pero cada estación duraría más de cinco siglos. Demasiado tiempo, naturalmente.
Las regiones polares tendrían siglos de luz continua y luego siglos de una
continua oscuridad.

Bueno, pues imaginemos que su eje está recto: 12 horas de luz solar y 12 horas
de noche en todas partes. Las regiones polares, indudablemente, tendrían unas
capas permanentes de hielo que se podrían extender hasta las zonas templadas,
sin un cálido verano que pudiese derretirlo, pero las regiones tropicales
serían agradables. Todo parecería bien montado, pero...

¡No es así!

Betelgeuse es rojo, y no blanco. Su temperatura superficial es de 3.200 K, y no
de 5.800 K como nuestro Sol. Tamaño por tamaño, la superficie de Betelgeuse
daría sólo 1/43 de la luz y del calor de nuestro Sol. Tendría un aspecto tan
grande como el del Sol en el firmamento del planeta, pero sería un Sol frío
según nuestros niveles, por lo que el océano del planeta se helaría y la vida
terroide resultaría imposible.



En ese caso, avancemos hacia el interior el planeta terroide. (La imaginación
constituye una poderosa herramienta.) Olvidemos lo de que Betelgeuse tenga el
tamaño de nuestro Sol, dejémosle agrandarse a medida que el planeta se acerca,
hasta que la incrementada área de su superficie compense su frialdad.

Debemos avanzar hasta que el área aparente de Betelgeuse en el firmamento
terroide sea 43 veces la de nuestro Sol en el cielo terrestre, y el diámetro
aparente de Betelgeuse, por lo tanto, unas 6,5 veces el de nuestro Sol. Esto
significa que debemos imaginar el planeta terroide a una distancia media de
9.680.000.000 kilómetros de Betelgeuse, o sólo 1,6 veces la distancia de Plutón
respecto de nuestro Sol.

A esa distancia, Betelgeuse parecería tener unos 3,5 grados de diámetro y
parecería hinchado a nuestros ojos acostumbrados al Sol, pero daría sólo la
cantidad apropiada de luz y de calor.

Sin duda, la luz sería de una calidad diferente. Tendría un color rojizo y,
para nuestros ojos, sería menos satisfactoria. Sin embargo, los organismos
vivos del planeta de Betelgeuse estarían adaptados, presumiblemente, a la gama
de radiación de la estrella. Sus ojos serían más sensibles al rojo que los
nuestros y responderían hasta cierto punto dentro del infrarrojo (y,
probablemente, no les afectaría la luz de onda corta que en realidad estaría
presente en sólo pequeñas cantidades en la luz de Betelgeuse). A los ojos
terroides, la luz de Betelgeuse aparecería blanca, y los organismos que
poseyesen esos ojos estarían perfectamente satisfechos.

Y lo que es más, el período de revolución sería más corto en esas condiciones,
y equivaldría sólo a 130 años terrestres. Sería soportable una leve inclinación
del eje y ello reduciría apreciablemente la cubierta de hielo polar.

Parece magnífico, ¿verdad? ¡Pues no lo es!

Nuestro Sol es una estrella estable, que no cambia de tamaño ni la cantidad de
radiación que emite. Sin duda en unas épocas es más irregular que en otras, y
en años recientes se han realizado algunas observaciones que han llevado a los
astrónomos a pensar que su tamaño cambia muy levemente con el tiempo, pero esos
cambios son triviales en comparación con el caso de Betelgeuse, que, como ya he
señalado en el anterior capitulo, pulsa marcadamente..., y de forma irregular.

He dicho que Betelgeuse posee un diámetro 430 veces mayor que el del Sol, pero
esto como promedio. Puede dilatarse hasta un diámetro 500 veces el del Sol (a
veces incluso más), o encogerse hasta tener sólo un diámetro 360 veces mayor
que el del Sol (a veces incluso menos).

El planeta que estamos imaginando que gira en torno de Betelgeuse, por tanto,
vería la estrella con un tamaño aparente de 3,5 grados sólo de promedio. Este
diámetro variaría desde 4,2 grados hasta 2,9 grados. En su diámetro máximo, el
área aparente de Betelgeuse en el firmamento sería el doble que en el diámetro
mínimo, y emitiría el doble de radiación en el máximo que en el mínimo.

Esto significa que nuestro planeta imaginario sufrirá unos períodos de tiempo
enormemente cálidos y otros enormemente fríos, aunque su órbita en torno de
Betelgeuse fuese circular y su eje recto. En realidad, sospecho que las
variaciones de temperatura en el planeta serían demasiado grandes para la vida
como sabemos que se desarrolla.

Pero ¿su órbita debe ser circular? ¿No nos podríamos imaginar una órbita más
bien elíptica, dispuesta de tal modo que el planeta se aproxime a Betelgeuse
exactamente cuando la estrella se contraiga y emita menos luz y calor, y se
aleje de Betelgeuse cuando se expanda y emita más?

Sería pedir mucho a la coincidencia el suponer que se acerca y se aleja
exactamente con la sincronización apropiada para mantener su temperatura
bastante estable, pero yo no vacilaría en imaginarlo, sólo porque es improbable.

El problema es que no es improbable, sino que es imposible.

He dicho que el planeta giraría en torno de Betelgeuse en 130 años. Por muy
elíptica que pudiese ser la órbita, el período de revolución seguiría siendo de
130 años si la distancia media desde Betelgeuse continuase siendo de
9.680.000.000 kilómetros. Esto significa que estaría relativamente cerca de
Betelgeuse durante algo menos de 65 años, y relativamente lejos del mismo
durante un poco más de 65 años. La razón de esto es que el planeta se movería a
una velocidad mayor que la orbital media cuando estuviese más cerca de
Betelgeuse, y a una velocidad menor a la media cuando se hallase más lejos.
Cuanto más altamente elíptica fuese la órbita, más desequilibrados serían los
tiempos en que estaría cerca y luego lejos.

No hay modo de poder conjugar esta situación con la expansión y contracción de
Betelgeuse, a menos que la estrella se expandiese y contrajera con un período
de 130 años, y la parte expandida del ciclo fuera un poco más prolongada que la
parte de contracción.

El período de pulsación de Betelgeuse tampoco es muy cercano. Betelgeuse tarda
unos 50 días en expandirse desde el tamaño mínimo al máximo, y unos 100 a 150
días en contraerse desde el máximo al mínimo de nuevo. En un período orbital
del planeta en torno de Betelgeuse, por tanto, la estrella se dilataría y
contraería unas 270 veces. Para equilibrar esto, se tendría que hacer ondear el
planeta hacia dentro y hacia afuera, en períodos variables y en grado variable,
a fin de conjugar con exactitud las imprevisibles variaciones en el índice y
alcance de la expansión y contracción de Betelgeuse.

Aparentemente, la irregularidad de Betelgeuse tiene que ver Con el hecho de que
es turbulenta y está «hirviendo». Burbujas calientes de helio del interior
salen periódicamente a la superficie Y producen enormes manchas calientes que
hacen que la estrella se expanda. Las variables implicadas son demasiadas para
permitir una regularidad.

Naturalmente se puede argumentar que la Tierra tiene muchísimas variaciones
climáticas también, y que, sin embargo, hay vida en ella.

Pero, de todos modos, las variaciones de temperatura de la Tierra, en conjunto,
son muy inferiores a las que el planeta de Betelgeuse se vería obligado a
soportar y, además, existen grandes regiones en la Tierra en las que la
temperatura es muy estable durante largos períodos de tiempo. Es difícil saber
hasta qué punto sería así también en el planeta de Betelgeuse.

Betelgeuse es enormemente inestable también de otras maneras. Muestra signos de
poseer prominencias colosales y de ser la fuente de un enorme viento estelar.
Todo esto lleva a razonar que Betelgeuse no permanecerá en su forma presente
durante mucho tiempo, en comparación con las estrellas ordinarias como nuestro
Sol, que pueden continuar relativamente sin cambios durante miles de millones
de años.

Comparemos el viento de Betelgeuse con el del Sol. El Sol está perdiendo masa
constantemente, mientras oleadas de partículas (principalmente protones, los
núcleos de los átomos de hidrógeno, que forman el grueso de la sustancia del
Sol) se mueven hacia afuera en todas direcciones. Cerca de un millón de
toneladas métricas de materia se pierden en el Sol cada segundo por este viento
solar, pero Betelgeuse pierde materia en un índice miles de millones mayor.

Si Betelgeuse continuara perdiendo materia por su viento estelar según el
índice actual, habría desaparecido por completo en el plazo de 16.000.000 de
años. No obstante, hay probabilidades de que, mucho antes, Betelgeuse haya
expulsado suficiente materia para convertirse en una estrella condensada
rodeada por una nebulosa planetaria, o haya estallado formando una supernova.
Sospecho que una gran gigante roja sólo puede permanecer en este estado unos
2.000.000 de años.

Esto puede parecernos mucho tiempo, considerando que la civilización humana ha
durado menos de 10.000 años. Un período de 2.000.000 de años es doscientas
veces más esa duración.

¡Pero no! No estamos hablando del desarrollo de la civilización, sino del
desarrollo de la vida. La vida apareció en la Tierra tal vez hace 3.500.000.000
de años, y la vida multicelular quizás hace 800.000.000 de años y la vida
terrestre hace sólo 400.000.000 de años. Se tardó más de dos mil quinientos
millones de años en pasar del estadio unicelular, y esto es más de mil veces la
vida de una gigante roja.

Se podría decir que esa evolución resultó ser en extremo lenta en la Tierra, y
que podría ser más rápida en el planeta de Betelgeuse.

En realidad, no podemos decir si el índice de evolución en la Tierra es, o no,
típico de la vida en el Universo en general, porque la vida en la Tierra es el
único ejemplo del fenómeno que conocemos. Sin embargo, por lo que sabemos de la
evolución parece difícil suponer que pueda ser otra cosa que un proceso muy
lento. Resulta difícil creer que la vida inteligente pueda desarrollarse
durante la breve existencia de una gigante roja.

En ese caso, recordemos que Betelgeuse no fue siempre una gigante roja. Antes
de ser una gigante roja, se encontraba en la secuencia principal. Es decir, era
una estrella estable como el Sol, que subsistía por la fusión del hidrógeno en
el núcleo. Entonces era una estrella relativamente pequeña, con más masa que el
Sol, y por lo tanto algo más grande, más brillante y más caliente, pero no una
gigante.

¿Por qué, pues, hemos de suponer que la vida tuvo que empezar mientras
Betelgeuse era una gigante roja? ¿No tendría sentido suponer que la vida
comenzó cuando se encontraba en la secuencia principal, y que la vida
evolucionó hasta la inteligencia, y la alta tecnología, durante ese período?

Así pues, cuando Betelgeuse llegó al final de su vida en la secuencia principal
y comenzó a evolucionar hacia una gigante roja, los habitantes inteligentes del
planeta terroide original (que, naturalmente, giraría en torno de Betelgeuse a
una distancia mucho mayor que la Tierra respecto del Sol, puesto que Betelgeuse
era la estrella más caliente, pero no a una distancia muchísimo mayor) habrían
podido realizar viajes espaciales para alejarse más hacia afuera. El movimiento
se efectuaría por etapas porque, aunque la evolución hacia la fase de gigante
roja es rápida en comparación con los cambios producidos durante la secuencia
principal, sigue siendo de todos modos bastante lenta a escala de la vida
humana.

Así, cuando nuestro Sol comience a evolucionar hacia la fase de gigante roja,
los seres humanos (o nuestros evolucionados descendientes), si aún existen,
podrían desplazarse poco a poco hacia Marte; luego, centenares de miles de años
después, hacia Europa; a continuación, un millón de años mas tarde hacia Titán,
y así sucesivamente. Al tener más masa, Betelgeuse evolucionaría con mayor
rapidez que el Sol, pero, de todos modos, no habría ninguna prisa.

Por lo tanto, el distante planeta de la fase de gigante roja de Betelgeuse no
contendría la vida inteligente que se hubiese desarrollado allí, sino la vida
que hubiese emigrado desde algún planeta interior y que hubiese sido vaporizado
físicamente y absorbido por Betelgeuse cuando esa estrella se hubiese expandido.

¡Pero esto no funciona!

En nuestro Sistema Solar, los mundos relativamente cercanos al Sol son
esencialmente rocosos, con o sin núcleo metálico, y se puede pensar que podrían
albergar vida humana a largo plazo, de una forma natural (como la Tierra), o
después de considerables modificaciones tecnológicas, como podrían hacer la
Luna o Marte.

Los mundos fuera del cinturón de asteroides, que sobrevivirán al gigante solar
rojo, son, sin embargo, de una composición fundamentalmente diferente. Los
grandes mundos son principalmente gaseosos, mientras que los mundos pequeños
están en su mayor parte helados. Estos mundos no ofrecen demasiadas esperanzas
como refugios a largo plazo. Los gaseosos son del todo inconvenientes. Los
helados carecen de los elementos rocosos y metálicos que necesitamos.

Naturalmente, se puede pensar que el gigante rojo solar puede calentar Júpiter
hasta el punto de que gran parte del mismo se disperse, y podríamos soñar con
que se expusiese un núcleo rocoso que fuese una nueva Tierra. Desgraciadamente,
no estamos seguros de que exista un núcleo rocoso, ni de lo grande que podría
ser, ni de si incluso un Júpiter calentado no seguiría unido o más o menos
intacto, gracias a su gran campo gravitatorio.

De los grandes satélites de Júpiter, Ganímedes y Calisto están helados, y en la
época de la gigante roja pueden fundirse y dispersarse. lo, con seguridad, es
rocoso, pero carece de agua. Calisto es rocoso y posee un océano superficial
que rodea todo el mundo (en la actualidad, está helado, por lo menos en la
parte superior). La gigante roja podría fundir y vaporizar el océano, que de
este modo se perdería en el espacio exterior.

Más allá de Júpiter, todo quedaría intacto, pero los mundos no son realmente
atractivos.

Existen muchas razones para pensar que esta pauta general —mundos rocosos cerca
de una estrella, y mundos gaseosos o helados lejos de una estrella— es general
en los sistemas planetarios. Así pues, se podría suponer que existe la regla de
que la vida comienza relativamente cerca de una estrella, y que en la época de
la gigante roja, la retirada a las regiones exteriores implicaría una
terraformación tan extensa que sería algo prohibitivo.



¿Pero no estamos limitando demasiado el posible avance de la tecnología? La
terraformación podría ser muy sencilla para unas especies avanzadas
tecnológicamente. Considerando el índice de avance tecnológico en los últimos
cien años (desde los planeadores sin motor hasta las sondas de cohetes que han
tomado fotografías en primer plano de los anillos de Saturno), ¿qué no
podríamos esperar de nosotros mismos en otro centenar de años, por no decir más
de un millar?

¿Y quién dice que debemos estar satisfechos, como refugiados, con cualquier
mundo que pueda existir en los confines de un sistema planetario? Son sólo
acumulaciones de recursos.

Podemos representar a la Humanidad, cuando se acerque la ¿poca de la gigante
roja solar, viviendo en colonias espaciales artificiales, tan cómodas y
agradables como la superficie de la Tierra, y mucho más seguros. Podría no
existir jamás el pensamiento de regresar a cualquier mundo. Simplemente, habría
que desplazar las colonias, alejándolas del Sol, poco a poco, año a año,
siguiendo el ritmo del aumento de intensidad de la radiación solar.

Incluso podríamos imaginarnos a la Humanidad salvando mundos de la destrucción
solar, impulsándolos más lejos del Sol de vez en cuando, a fin de mantenerlos
como recursos.

Por lo tanto, podríamos imaginar la vida que al principio se desarrolló
relativamente cerca de Betelgeuse en sus días de la secuencia principal,
viviendo ahora en grandes colonias a cerca de diez mil millones de kilómetros
de la estrella, con satélites y asteroides rescatados también en órbita.
Incluso podríamos suponer que los habitantes poseyeran métodos para amortiguar
las diferencias de radiación recibidas cuando Betelgeuse se expande y contrae.
Podrían resguardar las colonias y desviar la mayor parte de la radiación cuando
se calentase Betelgeuse, y reunir y concentrar la radiación cuando se enfriase.

¡Tampoco funcionaría!

Todo esto depende de sí realmente hubiese podido iniciarse y desarrollarse vida
en el sistema planetario de Betelgeuse mientras esa estrella se encontraba
todavía en la secuencia principal.

Consideremos, por ejemplo, nuestro Sol, y al hacerlo no hablemos de miles de
millones de años. Resulta difícil captar tan enormes períodos de tiempo. En vez
de ello, definamos «6 años largos» como iguales a mil millones de años
ordinarios (1.000.000.000). A esta escala, «1 segundo largo» equivale a 31 años.

Empleando esta «medida larga», el Sistema Solar se condensaría a partir de un
remolino de polvo y gas primordial en, más o menos, 7 meses largos e iniciaría
su existencia en la secuencia principal. Permanecería en la secuencia principal
durante unos 72 años largos (aproximadamente la vida media de un ser humano,
que es el motivo por el que he elegido esta escala particular), luego pasaría
por la fase de gigante roja en no más de 4 días largos y se derrumbaría y
convertiría en enana blanca, en cuyo estado permanecería indefinidamente,
enfriándose poco a poco.

Si miramos más de cerca la porción de secuencia principal de la vida del Sol, y
lo hacemos en años largos, éstos son los resultados.

Los planetas y otros cuerpos fríos del Sistema Solar llegaron a su forma actual
sólo de un modo lento, a medida que fueron recogiendo los restos en sus
órbitas. El bombardeo de estos restos ha dejado su marca en forma de cráteres
meteóricos que cicatrizan todos los mundos donde no están erosionados ni
oscurecidos por factores tales como aire, agua, lava volcánica, actividad viva,
etcétera. No fue hasta que el Sol tuvo tres años largos de edad cuando este
bombardeo acabó esencialmente, y la Tierra y los otros mundos se mostraron ya
más o menos en su forma actual.

Cuando el Sol tenía una edad de 6 años largos, las primeras trazas de
moléculas, lo suficientemente complicadas para considerarse vivas, aparecieron
en la Tierra.

Cuando el Sol tenía 21 años largos de edad, se formó la primera vida
multicelular, y los registros de fósiles empiezan a los 24 años largos. El Sol
tenía una edad de poco más de 25 años largos cuando la vida pasó a tierra, y
ahora tiene un poco más de 27,5 años largos de edad. Para cuando tenga 60 años
largos, puede que haga demasiado calor en la Tierra para estar cómodos, y los
seres humanos o sus evolucionados descendientes (si aún existen) quizá
comiencen a retirarse. Para cuando tenga 72 años largos, nuestro Sol será una
gigante roja, aunque no tan grande como es ahora Betelgeuse.

En realidad, no todas las estrellas permanecen en la secuencia principal
durante igual espacio de tiempo. En general, cuanta más masa tiene una
estrella, mayor es su suministro de combustible nuclear. Sin embargo, cuanta
más masa tiene, más rápidamente debe consumir ese suministro de combustible si
ha de generar suficiente calor y presión de radiación para impedir derrumbarse
bajo la atracción de su mayor masa.

La proporción de gasto de combustible aumenta con mayor rapidez que el
abastecimiento del mismo, a medida que la masa aumenta. De ahí se deduce que
cuanta más masa tiene una estrella, más corto es el tiempo en la secuencia
principal y más rápidamente alcanza la fase de gigante roja.

Consideremos ahora las enanas rojas, que constituyen las tres cuartas partes de
todas las estrellas. Se trata de estrellas relativamente pequeñas con masas de
1/5 a 1/2 la del Sol, masa suficiente para producir presiones internas capaces
de poner en marcha reacciones nucleares. Consumen gota a gota su relativamente
pequeño suministro de combustible, por lo que permanecen en la secuencia
principal durante un espacio de tiempo que va desde 450 años largos hasta 1.200
años largos.

Eso es una enorme cantidad de tiempo, si se piensa que se cree que el Universo
en sí no tiene más que unos 90 años largos de vida en la actualidad. Eso
significa que todas las enanas rojas existentes se hallan aún en la secuencia
principal. Ninguna ha tenido tiempo todavía de llegar al estado de gigante roja.

Por otra parte, las estrellas que tienen más masa que el Sol permanecen menos
tiempo en la secuencia principal. Proción, por ejemplo, que tiene 1,5 veces más
masa que el Sol, permanecerá en la secuencia principal durante un total de 24
años largos. Sirio, con una masa 2,5 veces superior a la del Sol, permanecerá
en la secuencia principal durante sólo 3 años largos. (Examinaré de nuevo este
tipo de cosas, de un modo diferente, en el capítulo final de este libro.)

¿Y qué cabe decir de Betelgeuse, que tiene una masa 16 veces superior a la del
Sol? Pues permanece en la secuencia principal durante unas 3 semanas largas.
Comparemos esto con los 6 años largos (un período de tiempo centenares de veces
mayor) que transcurrieron antes de que aparecieran en la Tierra los primeros
indicios de vida.

Incluso dando por sentado que nuestro Sistema Solar fuese fenomenalmente lento
en desarrollar la vida, resulta difícil imaginar que ésta pudiese desarrollarse
en menos de una centésima de ese tiempo.

Y no son sólo los primeros indicios de vida lo que nos interesa. Esperamos que
la vida evolucione lentamente hacia formas cada vez más complicadas, hasta que
pueda surgir alguna especie con la suficiente inteligencia para desarrollar una
tecnología avanzada. La Tierra tardó 27 años largos en conseguir esto. ¿Podría
haberlo hecho el planeta de Betelgeuse en 3 semanas largas, no mucho más que
1/500 de ese periodo?

Simplemente, parece no haber ninguna posibilidad de que se hubiese podido
desarrollar vida en cualquier planeta que girase en torno de Betelgeuse, o de
que pudiera haber ahora allí vida propia. (Digo «vida propia» porque no quiero
excluir la posibilidad de que algunos seres con tecnología avanzada, que
podrían haberse originado en cualquier otro sistema estelar, hubiesen fundado
un observatorio científico en los ámbitos exteriores del sistema de Betelgeuse,
a fin de estudiar de cerca a una gigante roja. Si semejante estación tuviese
formas de vida en ella, sería mejor que se marchasen y estuviesen a un año luz
de distancia el día en que explote Betelgeuse.)

Por lo tanto, no hay un Mundo del Sol Rojo en el sentido de Betelgeuse, y no
podemos esperar que se origine vida terroide cerca de ninguna estrella
apreciablemente con más masa que nuestro Sol. Las estrellas que tienen
apreciablemente menos masa que nuestro Sol quedan excluidas por otras razones.

Esto nos deja sólo las estrellas razonablemente cercanas a la masa de nuestro
Sol como adecuadas para el desarrollo de una vida terroide. Por fortuna, dichas
estrellas constituyen el 10% del total, y eso nos deja un margen considerable.





VIII. EL AMOR HACE GIRAR EL MUNDO





Una idea lleva a otra y estoy acostumbrado a dejar vagar mi mente. Por ejemplo,
algo en lo que pensé recientemente me ha hecho preguntarme acerca de la frase:
«¡Es el amor lo que hace girar el mundo!»

Lo que esto significa para la mayoría de las personas es que el amor es una
emoción tan excitante que el experimentarlo le hace sentir a uno que el mundo
entero es nuevo y maravilloso, mientras que su pérdida hace que el mismo Sol
parezca perder su brillo y que el mundo cese de girar. Esta clase de tonterías.

¿Y quién dijo esto primero?

Me dirigí a mi biblioteca de referencias y descubrí, ante mi gran asombro, que
su primer uso, en la literatura inglesa, fue en 1865, cuando la Duquesa
Maladice, en Alicia en el País de las maravillas, de Lewis Carroll: «Y la moral
de eso es "Oh, el amor, el amor, es lo que hace girar el mundo".»

En el mismo año, apareció (con un «el amor» más) en la obra de Charles Dickens
Nuestro común amigo. La invención independiente parece improbable, por lo que
ese sentimiento debió de haber tenido una existencia anterior, como los
refranes, y, en realidad, existe un verso de una canción popular francesa de
hacia 1700, que dice Cest lamour, lamour, qui fait le monde á la ronde, que se
traduce por la expresión de la Duquesa.

Si retrocedemos aún más en el tiempo, llegamos al último verso de La divina
comedia de Dante, que contiene la frase Lamor che move u sole e l'altre stelIe
(El amor hace girar el sol y las Otras estrellas). Esto se refiere al
movimiento general más que a la mera rotación sobre un eje, pero sirve. Y verán
que por «amor» no queremos decir ese sentido del afecto romántico humano en que
la mayoría de nosotros pensamos cuando se emplea la palabra. Más bien, Dante se
está refiriendo a ese atributo de Dios que muestra su preocupación por la
Humanidad y mantiene el Universo en funcionamiento para nuestro bien y nuestra
comodidad.

Esto, a su vez, debió, al menos en parte, de inspirarse en un antiguo proverbio
latino que data, supongo, de la época romana:

Amor mundum fecit (El amor hizo el mundo).

Y de aquí retrocedemos a las cosmogonías místicas de los griegos. Según lo que
sabemos de las doctrinas incluidas en los misterios orificios, el Universo
comenzó cuando la noche (es decir, el caos primitivo) formó un huevo, del que
salió Eros (el amor divino), y fue ese amor divino el que creó la Tierra, el
cielo, el Sol y la Luna, y lo puso todo en movimiento.

Metafísicamente, este «amor divino», desde un punto de vista pagano o
judeocristiano, puede manifestarse en el Universo material como una inexorable
atracción que todos los objetos experimentarían los unos hacia los otros.
Existe realmente una inexorable atracción, que es la que mantiene unido el
Universo, y los científicos llaman ahora a eso «la interacción gravitatoria».

Así pues, lo que realmente decimos es: «Oh, la gravedad, la gravedad, es lo que
hace girar el mundo», y tal vez eso no sea tan mala idea.

¿Y qué fue lo que inició esta línea de pensamiento? Pues...



En mayo de 1977, se publicó un ensayo mío titulado Twinkle Twinkle Microwaves
en el que contaba la historia del descubrimiento de los púlsares (unas pequeñas
estrellas neutrónicas que giran rápidamente). No tienen un diámetro mayor que
la longitud de la isla de Manhattan y, sin embargo, pueden contener tanta masa
como una estrella de tamaño normal. El primer púlsar que fue descubierto
efectuaba una rotación sobre su eje en 1,3370209 segundos. Y esto es una
rotación muy rápida incluso para un objeto tan pequeño como un púlsar.

¿Por qué, pues, debería un púlsar girar tan rápidamente?

Un púlsar es el resto de una supernova: una estrella gigante que ha estallado.
Semejante explosión mandaría parte de la masa estelar al espacio en todas
direcciones como una vasta masa de gas y de polvo en expansión, mientras las
porciones centrales quedarían reducidas a una estrella neutrónica
extremadamente densa y pequeña (o, en ocasiones, formarían un agujero negro).

La estrella original tendría cierta cantidad de momento angular: la cantidad
dependería de su índice de rotación y de la distancia media de la materia
contenida desde el eje de rotación.

Una de las leyes fundamentales de la Naturaleza es que la cantidad de momento
angular constituye un sistema cerrado que no puede cambiarse. Cuando una
estrella explota, parte del momento angular sería arrastrado por el gas y el
polvo que saldría en torbellino, pero buena parte del mismo quedaría atrapado
en las partes centrales derrumbadas.

Cuando el núcleo de la estrella, con su momento angular, se derrumba, la
materia de la que está compuesta se acerca al eje de rotación, queda mucho más
cerca. De una distancia media de millones de kilómetros, se encoge hasta un
promedio de sólo cinco kilómetros. Esto, en sí mismo reduciría el momento
angular a casi nada, a no ser por la existencia del otro factor: el índice de
rotación. A fin de que se conserve el momento angular, ese enorme decrecimiento
de la distancia desde el eje debe equilibrarse con un enorme incremento en el
índice de rotación.

Así pues, ya ven por qué el púlsar gira con tanta rapidez como lo hace. Por el
derrumbamiento de la estrella, provocado por la inexorable atracción de su
propia gravitación. Y si igualamos la gravitación, de un modo místico, con el
amor, descubrimos que, realmente, «Es el amor lo que hace girar el mundo».
(Ahora pueden comprender mi línea de pensamiento.)



En realidad, los púlsares no giran con la suficiente rapidez. La enorme
contracción debería dar como resultado un giro considerablemente más rápido.
Sin embargo, poco después de que se descubriesen los púlsares, se señaló que
existían efectos retardadores. Los púlsares arrojaban radiación energética y
partículas, y la energía así gastada iba en detrimento de su energía rotatoria.
Como resultado de ello, la velocidad de rotación disminuiría. Otra forma de
expresarlo fue que las emisiones se llevaban momento angular.

Las mediciones reales mostraron que los púlsares estaban reduciendo su
velocidad de forma regular. La rotación del primer púlsar descubierto lo está
haciendo en una proporción que doblará su períod0 en 16.000.000 de años.

De esto se deduce que cuanto más viejo sea un púlsar cuanto más largo sea el
período desde la explosión de la supernova que lo formó, más largo debería ser
su período de rotación.

En octubre de 1968, los astrónomos descubrieron un púlsar en la Nebulosa del
Cangrejo, una nube de gas que se formó al estallar una supernova hace 930 años.
Éste es un período de tiempo en extremo breve, hablando en términos
astronómicos, por lo que no causó la menor sorpresa el descubrir que el púlsar
de la Nebulosa del Cangrejo rotaba considerablemente más deprisa que los otros
púlsares que se habían hallado. La Nebulosa del Cangrejo gira sobre su eje en
0,033099 segundos, o 40,4 veces más deprisa que el primer púlsar descubierto.
Otra forma de expresarlo es que el púlsar de la Nebulosa del Cangrejo gira
sobre su eje 30,2 veces por segundo.

Hacia 1982 se habían descubierto más de 300 púlsares, y el púlsar de la
Nebulosa del Cangrejo siguió manteniendo el récord.

Esto tampoco fue ninguna sorpresa. Los púlsares son objetos muy pequeños y no
pueden descubrirse a grandes distancias, por lo que los que se han descubierto
hasta ahora están situados en nuestra propia galaxia de la Vía Láctea. Eso
significa que las supernovas que los formaron «estallaron dentro de nuestra
propia nebulosa de la Vía Láctea, y es muy probable que hubiesen podido verse
sin ayuda de instrumentos.

Sólo dos supernovas conocidas han explotado en nuestra galaxia desde que se
formo la Nebulosa del Cangrejo, y aparecieron en 1572 y 1604 respectivamente.
Los lugares de esas dos supernovas no han revelado ningún púlsar, pero no todas
las supernovas forman un púlsar, y no todos los púlsares que se forman giran en
una dirección que haría que sus corrientes de partículas y radiación pasaran
por la Tierra y pudieran ser descubiertas.

Eliminadas esas dos recientes supernovas, podemos estar casi seguros de que no
descubriremos ningún púlsar que sea más joven y, por lo tanto, de rotación más
rápida, que el púlsar de la Nebulosa del Cangrejo. Los astrónomos estaban tan
seguros de ello que ninguno quiso perder su tiempo haciendo frente al problema
de tratar de encontrar un púlsar ultrarrápido que seguramente no existía.



En realidad, los astrónomos habían preparado listas de todas las fuentes de
radio detectables en el cielo. Tales fuentes no tienen forzosamente que ser
púlsares. Pueden ser nubes de gas turbulento en nuestra propia galaxia; pueden
ser galaxias distantes en cuyos centros tienen lugar sucesos catastróficos;
pueden ser quasares aún más distantes.

En el Cuarto Catálogo de Cambridge de Emisores Radio había una de tales fuentes
llamada 4C21.53. Había estado muy tranquila en su lista hasta los primeros años
de la década de los sesenta, y nadie había pensado nada acerca de ella. La
forma más probable de explicar su existencia era suponer que se trataba de una
galaxia distante, demasiado alejada para percibirse visualmente, pero
suficientemente activa para que pudiesen descubrirse sus emisiones radio.

Y luego, en 1972, se observó que su imagen de radio centelleaba al pasar a
través del viento solar que emite nuestro Sol. Es decir, la imagen cambiaba de
posición muy levemente de una manera rápida y errática.

El parpadeo, en un sentido más ordinario, nos es familiar. La luz que pasa a
través de nuestra atmósfera se refracta en un grado muy pequeño, en direcciones
imprevisibles, mientras se mueve a través de las regiones atmosféricas a
diferentes temperaturas. Si el rayo de luz es bastante grueso, pequeños
fragmentos del mismo pueden desviarse en una dirección, y otras pequeñas
cantidades en otra. Éstas pueden neutralizarse de modo que todo el rayo parece
firme.

Así, un planeta como Marte puede verse como un simple punto de luz, incluso en
su aproximación máxima, pero se trata de un punto lo suficientemente grande
para que porciones diferentes del mismo centelleen de una forma distinta y el
efecto se neutralice. En conjunto, pues, Marte no parpadea.

Si observamos a Marte a través de un telescopio, no obstante, no sólo ampliamos
la imagen entera del mismo, sino que también ampliamos los parpadeos. Si
tratamos de ver detalles de la superficie, descubriremos que el centelleo
difumina esos detalles. (Por esta razón, observar a Marte desde fuera de la
atmósfera constituiría un gran progreso.)

Sin embargo, las estrellas son, en apariencia, unos objetos mucho más pequeños
que los planetas. Tan delgado es el rayo de luz procedente de una estrella,
particularmente una estrella apagada, que todo él puede desviarse de manera
errática al pasar a través de la atmósfera, y parpadea. El centelleo en si
atestigua la pequeñez de la imagen óptica de la estrella.

De la misma forma, cuando 4C21.53 parpadeó al pasar a través del viento solar,
se tuvo que deducir que se trataba verdaderamente de un rayo de radiación muy
delgado. Esto no sería sorprendente, en realidad, si se tratara de una galaxia
distante, pero se halla situada en la constelación Vulpecula («Pequeña Zorra»),
bastante cerca de la Vía Láctea. Esto significa que el rayo de ondas de radio,
si se originara en el exterior de la galaxia, tendría que viajar a través del
largo diámetro de la galaxia para llegar a nuestros instrumentos. Gran parte de
las ondas de radio serían esparcidas ligeramente por la materia enrarecida que
se encuentra dentro de nuestra galaxia (tal vez sea enrarecida, pero resulta
mucho más densa que la materia entre las galaxias), y por muy delgado que
hubiera podido ser el rayo en un principio, se habría agrandado hasta el punto
de que no parpadearía.

Por lo tanto, el mero hecho de parpadear mostró que 4C21.53 estaba situado
dentro de nuestra galaxia, y que su rayo de radio recorría una distancia
relativamente corta para alcanzarnos y así no tenía tiempo de agrandarse
indebidamente, sobrepasando la fase en que es capaz de parpadear. Y si estaba
tan cerca y aún poseía un rayo lo suficientemente delgado para parpadear,
4C21.53 debía ser un objeto muy pequeño.

Luego, en 1979, se informó que, si se estudiaba la mezcla de la longitud de
onda del rayo radio de 4C21.53, se descubría que era muy pobre en las altas
frecuencias, más pobre que la mayor parte de las fuentes radio. Pero los
púlsares eran característicamente pobres en las frecuencias más altas. ¿Podría
ser 4C21.53 un púlsar?

El asunto preocupó a un astrónomo estadounidense llamado Donald Backer, y
comenzó a considerar el problema a fondo. Si 4C21.53 era lo suficientemente
pequeño para ser un púlsar, y si tenía la distribución de longitud de onda de
un púlsar, y por lo tanto se concluía que se trataba de un púlsar, ¿por qué no
emitía pulsaciones?

Cuando un púlsar rota con rapidez, emite dos corrientes de ondas de radio, una
desde un lado de sí mismo y otra desde el otro lado. Al rotar, primero una
corriente y luego la otra, pasa a través de algún punto de observación dado. Si
nuestros instrumentos se encuentran en ese punto, las ondas de radio son
descubiertas en forma de pulsaciones dependiendo del período de rotación el
número de pulsaciones por segundo.

Si las ondas de radio no nos llegan, como probablemente ocurre en una gran
mayoría de casos, no detectamos nada en absoluto, pero si detectamos las ondas
de radio, también debemos detectar las pulsaciones. Si el púlsar se encuentra
muy alejado, la dispersión por la materia interestelar podría hacer confusas
las pulsaciones formando un rayo de radio más o menos firme y débil. Si el
púlsar es muy antiguo, las pulsaciones podrían haberse debilitado hasta el
punto de no poder ser descubiertas. Sin embargo, 4C21.53 estaba lo
suficientemente cerca (sólo a unos 2.000 parsecs) para que sus pulsaciones
fuesen claras, y el rayo de radio era lo suficientemente fuerte para que las
pulsaciones fuesen descubiertas con facilidad si se encontraban allí.

A Backer se le ocurrió que había una explicación razonable que aclaraba todo el
misterio. Supongamos que 4C21.53 girase muy rápidamente, por lo menos tres
veces mas rápidamente que el púlsar de la Nebulosa del Cangrejo. En ese caso,
sus pulsaciones pasarían inadvertidas, dado que las observaciones de radio que
se realizaban no estaban preparadas para unas pulsaciones tan rápidas. Trató de
publicar su conjetura, pero su artículo fue rechazado por demasiado
especulativo, con la sugerencia de que resultaba harto improbable.

Pero Backer no se rindió. Trató de conseguir astrónomos en diversas
instalaciones para que localizasen pulsaciones ultrarrápidas, pero durante un
período de tres años, aun cuando logró que algunos lo intentaran, no se
consiguió nada. Uno de los problemas (aunque Backer no lo sabía en aquel
tiempo) era que, en realidad, 4C21.53 se trataba de un conglomerado de tres
diferentes fuentes de radio, no muy espaciadas, una de las cuales era de hecho
una galaxia distante. Esto, naturalmente, confundía las cosas cuando los
astrónomos intentaban ver todo aquello con gran detalle.

En setiembre de 1982, Backer pidió a los del radiotelescopio de Arecibo, en
Puerto Rico, que comprobasen en el 4C21.53 la característica conocida como
polarización. Los púlsares muestran unos niveles de polarización muy altos,
mucho más que otras fuentes de radio. Le llegó el informe de que 4C21.53
mostraba un 30 % de polarización, lo que resultaba muy elevado incluso para un
púlsar.

Esto fue en realidad una buena noticia para Backer, pues estaba más convencido
que nunca de que tenía un púlsar por la cola. Los de Arecibo incluso habían
entrevisto ocasionalmente posibles pulsaciones.

El mismo Backer acudió a Arecibo, donde empleó sofisticados instrumentos
especiales durante siete noches. El 12 de noviembre de 1982 el asunto quedó
zanjado: se descubrió que 4C21.53 era un púlsar y, finalmente, recibió el
nombre de P5R1937 + 214.

El nuevo púlsar pronto fue conocido como Púlsar Milisegundo, porque giraba
sobre su eje en un poco más de una milésima de segundo. Para ser exactos, su
periodo de rotación es de 0,001557806449023 segundos. Esto significa que el
púlsar rota sobre su eje 642 veces por segundo. Esto no es 3 veces más rápido
que la Nebulosa del Cangrejo, como Backer había sospechado que podía ser, sino
21,25 veces más deprisa.

Supongamos que el Púlsar Milisegundo posee un diámetro de 20 kilómetros. En ese
caso, su circunferencia ecuatorial es de 62,8 kilómetros. Un punto en su
ecuador recorrería 642 veces esa distancia, o 40.335 kilómetros en un segundo.
Por lo tanto, viajaría a un 13,5 % de la velocidad de la luz.

Un púlsar posee una enorme gravedad superficial, pero incluso esto es apenas
suficiente para mantenerse unido contra la aceleración que implica tan inaudita
velocidad. Si el Púlsar Milisegundo rotase tres veces más deprisa —más o menos
2.000 veces por segundo— se haría añicos.



Y ahora viene la pregunta: ¿Qué es lo que hace que el Púlsar Milisegundo dé
vueltas tan deprisa?

La respuesta razonable es que gira con tanta rapidez porque es totalmente
nuevo. Cuando se descubrió el púlsar de la Nebulosa del Cangrejo y se vio que
rotaba sobre su eje 30,2 veces por segundo después de una vida de 930 años, los
astrónomos calcularon hacia atrás y estimaron que podía haber estado girando
1.000 veces por segundo en el momento de su formación.

Pues bien, si el Púlsar Milisegundo gira 642 veces por segundo ahora debió
formarse hace sólo un siglo o menos. Y si fue así, eso lo explicaría todo.

Pero ¿cómo puede ser tan joven? Si fuera tan joven, debería haber existido una
brillante supernova a sólo 2.000 parsecs de distancia, en la constelación de
Vulpecula, hace un siglo o menos, que marcara su nacimiento; y en ese caso, ¿no
se habría descubierto esa supernova?

No se descubrió ninguna supernova.

Tal vez podríamos dar alguna tortuosa razón para explicar por qué no se halló
tal supernova, pero, dejando esto aparte, no existe motivo que impida que los
astrónomos miren el púlsar ahora. Y, naturalmente, lo han mirado.

De haber existido una supernova en el lugar del Púlsar Milisegundo en un pasado
muy reciente, existirían ahora señales inconfundibles de esa explosión. La
supernova de la Nebulosa del Cangrejo que tuvo lugar en el año 1054 dejó tras
de sí una nube de polvo y gas en expansión que aun hoy es claramente visible.
En realidad, la Nebulosa del Cangrejo es esa nube en expansión.

Así pues, en el lugar del Púlsar Milisegundo debería haber semejante nube en
expansión de polvo y gas, mucho más pequeña que la Nebulosa del Cangrejo,
naturalmente, dado que sería tan nueva, pero que sería mucho más activa.

No hay señales de nada parecido, y eso debe de significar que la supernova
ocurrió hace tanto tiempo que la nube producida ya se ha dispersado y es
imposible hallarla. Esto haría muy viejo al Púlsar Milisegundo.

Pero estamos recibiendo señales contradictorias. El giro ultrarrápido dice «muy
joven», y la ausencia de nebulosa dice «bastante viejo». ¿Qué es lo correcto?
¿Cómo decidirlo?

Una forma consiste en determinar el índice de disminución de la velocidad de
rotación. En el caso de todos los púlsares descubiertos antes de noviembre de
1982, la regla decía que cuanto más rápido es el giro, más rápido es el índice
de disminución de la velocidad.

Por lo tanto, el Púlsar Milisegundo fue observado día a día y semana a semana,
y el índice de rotación se midió cuidadosamente una y otra vez.

Los astrónomos estaban profundamente asombrados. El Púlsar Milisegundo estaba
disminuyendo su velocidad en la proporción de 1,26 x 10-19 segundos por
segundo. Esto era un efecto de disminución de la velocidad mucho más pequeño
que el de cualquier otro púlsar conocido, aunque el índice de giro fuese mucho
más rápido que el de cualquiera de éstos. El índice de disminución de la
velocidad del púlsar de la Nebulosa del Cangrejo es 3.000.000 de veces mayor
que el del Púlsar Milisegundo, aunque el primero gira a menos del 5 por ciento
de la velocidad de este último.

¿Y esto por qué? La creencia general es que el efecto de disminución de la
velocidad surge a causa de la emisión energética de partículas y radiación por
un púlsar contra la resistencia de su propio campo magnético enormemente
intenso. Si el Púlsar Milisegundo disminuye su velocidad tan escasamente, debe
de tener un campo magnético muy débil, y esto debería ser señal de un púlsar
viejo. Y lo que es más, las mediciones parecen indicar que la temperatura
superficial del Púlsar Milisegundo es de menos de 1.500.000 ºK, la cual es muy
elevada según los niveles de una estrella ordinaria, pero bastante baja en
comparación con los demás púlsares: otra señal de mucha edad.

Así pues, todas las pruebas menos una —la falta de una nebulosa, la baja
temperatura, el débil campo magnético, el muy bajo índice de disminución de la
velocidad de giro— parecen indicar que se trata de un púlsar viejo. En
realidad, por su índice de disminución de la velocidad los astrónomos suponen
que el Púlsar Milisegundo puede tener una edad de 500 millones de años (o tal
vez más). Los púlsares ordinarios duran sólo de 10 a 100 millones de años antes
de ir más despacio y debilitarse hasta el punto de que las pulsaciones no se
puedan descubrir. El Púlsar Milisegundo es mucho más viejo de lo que se pensaba
que era la vida máxima de un púlsar y, considerando su lento índice de pérdida
energética, potencialmente puede vivir miles de millones de años más.

¿Pero esto por qué? En primer lugar, ¿por qué un púlsar viejo como éste giraría
como si se tratase de uno recién nacido?

Hasta ahora, la mejor suposición es que el Púlsar Milisegundo, habiéndose
formado hace mucho tiempo y habiendo reducido su velocidad y debilitado hasta
no ser posible su descubrimiento (muchos millones de años antes que hubiese en
la Tierra nadie para descubrirlo), de alguna forma se aceleró de nuevo en una
época relativamente reciente.

Supongamos, por ejemplo, que originariamente, el púlsar formase parte de un
sistema binario. Se conocen casos de sistemas binarios, en los que una o ambas
estrellas es un púlsar, como ya mencioné al final del capitulo 4.

Algún tiempo después de que el púlsar hubiese envejecido y se hubiese apagado,
la estrella normal que fue su compañera entró en el estado de gigante roja y se
expandió. Las regiones exteriores de la nueva gigante roja inundaron la
influencia gravitatoria del púlsar y formaron un «disco de acreción» de materia
que se hallaba en órbita en tomo del púlsar.

Cuanto más débil el campo magnético del púlsar, más cerca estaría el disco de
acreción del púlsar, y más rápido se movería el material en órbita bajo el
azote gravitatorio de la pequeña estrella.

En su borde interior, el material del disco de acreción giraría en torno del
púlsar más de prisa de lo que el lento y viejo púlsar estaría girando alrededor
de su propio eje. El resultado sería que el momento angular pasaría del disco
de acreción al púlsar. El púlsar aceleraría su giro y el disco de acreción
reduciría su velocidad.

A medida que la materia del disco de acreción redujera su velocidad, formaría
una espiral interior hacia el púlsar y se aceleraría de nuevo, transfiriendo
una vez más momento angular al púlsar. Con el tiempo, el material giraría hacia
abajo en espiral en el púlsar, mientras el nuevo material entraría en el borde
exterior del disco de acreción de la estrella compañera. Con el tiempo, buena
parte de la materia de la estrella compañera se habría derramado sobre el
púlsar y el viejo púlsar habría aumentado su índice de giro hasta la gama de
los milisegundos. Finalmente, la compañera habría desaparecido o tendría una
masa demasiado pequeña para no poder mantener sus fuegos nucleares, pasando a
ser una enana negra, es decir, en realidad, un planeta grande.

La lenta adición de la materia de la estrella compañera al púlsar no
restituiría su juventud. El púlsar seguiría careciendo de nebulosa; seguiría
estando frío y poseyendo un campo magnético débil; y puesto que tendría un
campo magnético débil, seguiría teniendo un índice de reducción de la velocidad
de giro muy lento. Pero tendría un giro muy rápido, como cuando era joven.

Si esta sugerencia es correcta, aunque algunos astrónomos la han combatido con
fuerza, tampoco se trataría de un caso muy raro. Los sistemas binarios son en
extremo comunes, más comunes que las estrellas sencillas como nuestro Sol. Esto
significa que la mayoría de las supernovas formarían parte de sistemas
binarios, y los púlsares resultantes, con frecuencia, tendrían una estrella
normal como compañera. Y si un sistema binario incluye un púlsar, de vez en
cuando la estrella normal evolucionaría de tal forma que se inmolaría y
aceleraría el púlsar. Por esta razón, una atenta búsqueda en el firmamento
podría descubrir otros púlsares viejos pero muy rápidos, tal vez incluso
docenas de ellos.



Aún queda un asunto interesante.

El Púlsar Milisegundo tiene un período de rotación que es el intervalo de
tiempo más delicadamente medido que conocemos. El período de rotación ha sido
medido hasta la trillonésima de segundo (quince decimales), y con el tiempo aún
seremos capaces de mejorarlo.

Otros púlsares son también buenos relojes, pero se hallan sujetos a periódicos
pequeños cambios repentinos en el índice de rotación, que pueden surgir por
cambios internos en la estructura del púlsar, o por la llegada de una cantidad
considerable de materia exterior. Esto introduce una imprevisible inexactitud
en el reloj púlsar ordinario. Por alguna razón, parece que no existen estos
cambios en el Púlsar Milisegundo.

Con toda seguridad, el índice del Púlsar Milisegundo no es constante. Reduce su
velocidad de modo perceptible. Cada 9 1/4 días su índice de giro se hace una
trillonésima de segundo más largo. Esto realmente no es mucho, puesto que se
necesitarían 2,5 millones de años para que su giro se hiciese una
milmillonésima de segundo más largo si esta reducción de velocidad permaneciese
constante.

¿Para qué sirve un reloj así?

Tomemos un ejemplo: el Púlsar Milisegundo puede emplearse para medir el paso de
la Tierra en torno del Sol. Las irregularidades en esa travesía —los pequeños
adelantos y los pequeños retrasos en relación con la posición teórica, si la
Tierra y el Sol estuviesen solos —en el Universo podrían medirse con más
exactitud que nunca.

Esos desplazamientos serían debidos, en gran parte, a las perturbaciones
producidas en la Tierra por otros planetas. A su vez, dichas perturbaciones
dependerían de la masa de esos planetas y de sus cambiantes posiciones con el
tiempo.

Conociendo las posiciones de los planetas por medio de la observación directa,
y con mayor precisión que nunca gracias al reloj del Púlsar Milisegundo,
seríamos capaces de calcular la masa de los distintos planetas con un elevado
grado de exactitud, mucho mayor de lo que hasta ahora ha sido posible,
especialmente la de los planetas más exteriores, como Urano y Neptuno.

Y es del todo concebible que puedan aparecer otras aplicaciones aún más
cercanas a nuestro hogar, también.





Tercera parte





QUÍMICA





IX. LAS PROPIEDADES DEL CAOS





Allá por el año 1967, escribí un libro acerca de la fotosíntesis, y es posible
que puedan interrumpirme en este momento para preguntarme qué demonios es la
fotosíntesis. Sí es así, tengan fe... Se lo explicaré antes de que se acabe
este capítulo.

En aquel tiempo, reconocí el hecho de que esta palabra de cinco sílabas no
inspiraba amor y confianza a primera vista, y fue mi intención darle al libro
un título dinámico para captar la atención del lector, y hacerle comprar el
libro antes de que se percatase de que estaba lleno de bioquímica moderadamente
difícil.

No tenía pensado el título exacto, y para tener un titulo de trabajo dejé que
mi imaginación se tomase un bien merecido descanso y empleé «Fotosíntesis».
Cuando hube terminado seguía sin tener un título exacto en mente, así que
decidí dejar que se ocupara de ello el editor, Arthur Rosenthal, de Basic Books.

En 1968 se publicó el libro y recibí un ejemplar previo, y descubrí, con gran
perplejidad, que el título de la cubierta del libro era Fotosíntesis. En
realidad, lo crean o no, ese título se repetía cuatro veces.

Dije con voz trémula:

—Arthur, ¿cómo esperas vender un libro con el título Fotosíntesis...
Fotosíntesis... Fotosíntesis... Fotosíntesis...?

A lo que me respondió:

—¿Pero no te has dado cuenta de que más hay en la cubierta del libro?

—¿El qué? —pregunté, intrigado.

Señaló la parte inferior izquierda de la cubierta donde se leía con claridad:
Isaac Asimov.

Como algunos de ustedes saben, el halago siempre funciona conmigo, así que me
sonreí y, en realidad, el libro fue razonablemente bien. El editor no perdió
dinero, pero les seré franco: no fue un auténtico bestseller

Por lo tanto, se me ocurrió volver a tratar algunos aspectos del tema, en el
encantador estilo informal que empleo en estos capítulos, y esta vez he
utilizado un título dramático, aunque supongo que eso solo tampoco convertirá
este libro en un auténtico bestseller.



Comencemos con el asunto del comer. Los animales, desde los más pequeños
gusanos a la ballena más grande, no pueden vivir sin alimentos, y los
alimentos; en esencia, son plantas. Todos nosotros, desde trillones de insectos
hasta miles de millones de seres humanos, nos tragamos de una forma
interminable y sin remordimientos todo el mundo de las plantas, o animales que
han comido plantas; o animales que han comido animales que han comido plantas,
o...

Investiguemos las cadenas alimenticias de los animales, y en sus extremos
siempre encontraremos plantas.

Sin embargo, el mundo vegetal no disminuye. Las plantas continúan creciendo
indefinidamente y sin remordimientos a medida que son comidas pero, por lo que
podemos ver por la simple observación no científica, ellas mismas no comen. Sin
duda requieren agua, y a veces tienen que ser ayudadas abonando cuidadosamente
el suelo con algo como excrementos de animales; pero no nos atrevemos a
considerar eso «comer».

En los tiempos precientíficos pareció tener sentido el suponer que las plantas
eran un orden de objetos, completamente diferente a los animales. Por supuesto,
las plantas crecían lo mismo que los animales, y provenían de semillas como
algunos animales provenían de huevos, pero esto no parecía otra cosa que
similitudes superficiales.

Los animales se movían independientemente, respiraban y comían... Las plantas
no hacían ninguna de estas cosas, como tampoco, por ejemplo, lo hacían las
rocas. El movimiento independiente, en particular parecía una propiedad
esencial de la vida, por lo que mientras todos los animales parecían vivos de
una forma evidente, las plantas (como las rocas), no.

Esto es al parecer el punto de vista de la Biblia. Cuando la tierra seca
apareció en el tercer día del relato que el Génesis hace de la creación, se
describe a Dios diciendo: «Haga brotar la tierra hierba verde, hierba con
semilla y árboles que den frutos según su especie y tengan su simiente sobre la
tierra.» (Génesis, 1, 11.)

No se hace la menor mención de que la vida sea una característica del mundo de
las plantas.

No es hasta el quinto día cuando se menciona la vida. Entonces Dios dice:
«Pululen las aguas con un pulular de seres vivientes... Y creó Dios los grandes
monstruos marinos y todos los animales vivos que se deslizan...» (Génesis, 1,
20-21.)

Los animales se caracterizan como móviles y vivos, implicando cada término,
aparentemente, el otro. Pero las plantas no son ninguna de las dos cosas.

Dios dijo: «...y a todas las bestias de la Tierra y a todas las aves del cielo,
a todo lo que se arrastra sobre la tierra y que tiene alma viviente, le doy
toda la hierba verde para comida...» (Génesis 1, 30.) En otras palabras, los
animales se mueven y están vivos, y las plantas, que no se mueven, son
meramente alimentos que proporciona para ellos la gracia de Dios.

El ser herbívoro es claramente considerado como lo ideal. El ser carnívoro no
se menciona en la Biblia hasta después del Diluvio, cuando Dios dice a Noé y a
sus hijos: «Todo cuanto vive y se mueve os servirá de alimento, al igual que la
hierba verde; os lo entrego todo.» (Génesis, 9, 3.)

En general, el pensamiento occidental ha seguido las palabras de la Biblia
(como no podía dejar de ser, dado que la Biblia era considerada la palabra
inspirada de Dios). El suelo viviente, no alimenticio, fue en cierta forma
convertido en plantas no vivientes pero alimenticias, que podían servir como
alimento para los animales vivientes. La semilla, al ser sembrada, servia como
agente desencadenante de la conversión del suelo en plantas.



La primera persona que comprobó esta teoría del crecimiento de las plantas fue
un médico flamenco, Jan Baptista van Helmont (1580-1644). Plantó un sauce joven
que pesaba cinco libras en una maceta que contenía 200 libras de tierra.
Durante cinco años dejó crecer el sauce, regándolo con regularidad y cubriendo
la tierra con cuidado entre los riegos para que no pudiese caer en ella ninguna
materia extraña que confundiese los resultados.

Al cabo de cinco años, retiró el ahora mucho más grande sauce de la maceta y,
con cuidado, le quitó toda la tierra que estaba adherida a las raíces. El sauce
pesaba 169 libras, habiendo ganado, pues, 164 libras. La tierra había perdido
como mucho la octava parte de una libra.

Éste fue el primer experimento bioquímico cuantitativo que conocemos, y fue de
crucial importancia por ello, por lo menos. Además, mostró de manera
concluyente que la tierra no se convertía, todo lo más en un grado muy pequeño,
en tejido de la planta.

Helmont razonó que, si el único material que había entrado en el sistema había
sido el agua, el sauce, y presumiblemente las plantas en general, se formaban a
partir del agua.

El razonamiento parecía a prueba de bombas, especialmente dado que se había
conocido bien desde los primeros tiempos el que las plantas no podían crecer si
se las privaba de agua.

Y, sin embargo, ese razonamiento era erróneo, porque el agua no era el único
material, aparte de la tierra, que había tocado el sauce. El árbol había sido
tocado también por el aire, y Helmont hubiera reconocido al instante ese hecho
si se le hubiese señalado. Al ser el aire invisible, impalpable y,
aparentemente, inmaterial, era fácil no hacerle caso. Helmont tenía también
otras razones para hacerlo así.

En la época de Helmont, el aire y las sustancias asociadas estaban empezando a
ser estudiadas científicamente por primera vez. En realidad, fue el propio
Helmont quien inició el proceso.

Así, los anteriores experimentadores químicos habían observado e informado que
se formaban vapores en sus mezclas y que subían en forma de burbujas, pero los
habían descartado considerándolos variedades del aire.

Helmont fue el primero en estudiar esos «aires» y en darse cuenta de que,
algunas veces, tenían propiedades por completo distintas de las del aire
ordinario. Por ejemplo, algunos de esos vapores eran inflamables, mientras que
el aire ordinario no lo era. Helmont observó que cuando esos vapores
inflamables ardían, se formaban a veces gotitas de agua.

Por supuesto, en la actualidad sabemos que cuando el hidrógeno arde se forma
agua, y podemos estar seguros de que fue eso lo que observó Helmont. Este, al
no tener la ventaja de nuestra brillante perspicacia llegó a la más bien simple
conclusión de que ese vapor inflamable (por tanto, todos los vapores, incluso
el mismo aire ordinario) era una forma de agua. Por lo tanto, naturalmente
descartó el aire como fuente de la sustancia del sauce. Era el agua lo que
constituía la fuente, ya fuese en forma líquida o de vapor.

Helmont observó que el agua líquida tenía un volumen definido, mientras que en
los vapores no era así. Los vapores se expandían para llenar los espacios,
interpenetrándolo todo. Parecían carecer de orden, ser sustancias que se
hallaban en completo desorden.

Los griegos creían que el Universo comenzó como una especie de sustancia que se
hallaba en total desorden. El término griego para esta sustancia original y
desordenada fue «caos». Helmont llamó a los vapores con dicho término,
empleando su pronunciación flamenca, que, al deletrearlo fonéticamente, produjo
la voz de «gas». Hasta hoy, llamamos al aire un gas, y aplicamos esa palabra a
cualquier vapor o sustancia parecida al aire.

Helmont estudió las propiedades del caos: es decir, las propiedades de los
gases. Produjo un gas quemando madera que no era inflamable, y que tendía a
disolverse en el agua (algo que Helmont interpretaría, naturalmente, como que
se convertía en agua). Lo llamó «gas silvestre» («gas de madera») y es el gas
que conocemos hoy como anhídrido carbónico. Es una lástima que Helmont no
tuviese manera de conocer la importancia de ese descubrimiento en relación con
su investigación del problema del crecimiento de las plantas.



El estudio de los gases dio otro paso adelante cuando un botánico inglés,
Stephen Hales (1677-1761), aprendió a reunirlos con razonable eficiencia.

En vez de, simplemente, dejarlos escapar en el aire, y verse obligado a
estudiarlos al vuelo, por así decirlo, produjo sus gases en una vasija de
reacción con un largo cuello que se curvaba hacia abajo y hacia arriba de
nuevo. Este largo cuello podía insertarse en una cubeta de agua, y la abertura
del cuello podía cubrirse con un vaso picudo invertido, también lleno de agua.

Cuando se formaba un gas particular como resultado de los cambios químicos que
tenían lugar en la vasija de reacción, burbujeaba hacia la superficie de los
materiales en reacción, llenaba el espacio de aire de encima, se expandía a
través del curvado y largo cuello hasta el vaso picudo invertido. El gas
recogido en el vaso picudo se quedaba allí, y las propiedades de un caos
particular podían estudiarse a placer.

Hales preparó y estudió de esta forma cierto número de gases, incluyendo
aquellos que ahora llamamos hidrógeno bióxido de azufre, metano, monóxido de
carbono y anhídrido carbónico. Sin embargo, no sacó suficiente jugo de todo
ello, puesto que siguió pensando que se trataba de variedades del aire
ordinario.

Asimismo, resultaba imposible trabajar con dichos gases, sin llegar finalmente,
a la conclusión de que el aire no era una sustancia simple, sino una mezcla de
diferentes gases.

Un químico escocés, Joseph Black (1728-1799), se interesó por el anhídrido
carbónico y descubrió, en 1756, que si se ponía en contacto con la sustancia
sólida común llamada cal (óxido cálcico) se convertía en piedra caliza
(carbonato cálcico).

Entonces observó un hecho crucial. No tenía que emplear anhídrido carbónico
laboriosamente preparado para este propósito. Tan sólo tenía que poner la cal
en contacto con el aire ordinario. La piedra caliza se formaría de modo
espontáneo, aunque mucho más despacio que si emplease anhídrido carbónico. La
conclusión de Black fue que el aire contenía anhídrido carbónico en pequeñas
cantidades, y en esto estuvo del todo en lo cierto.

En 1772, otro químico escocés, Daniel Rutherford (1749-1819), un estudiante de
Black, dejó arder unas velas en un contenedor de aire cerrado. Pasado un
tiempo, la vela ya no ardía, y lo que es más, ninguna otra sustancia se quemaba
en aquel aire. Tampoco podía vivir allí un ratón.

En aquella época ya se sabia que una vela que ardía producía anhídrido
carbónico, por lo que resultó fácil sacar la conclusión de que todo el aire
normal que permitía arder había sido reemplazado por el anhídrido carbónico,
que se sabía que no dejaba arder.

Por otra parte, se sabía también que el anhídrido carbónico era absorbido por
ciertos productos químicos (como la cal). El aíre en que la vela había ardido
se pasó a través de esos productos químicos y, realmente, sacó anhídrido
carbónico. Sin embargo, la mayor parte del aire permaneció intacto, y lo que
quedó, aunque no era anhídrido carbónico, tampoco permitía la combustión. Lo
que Rutherford había aislado era el gas que en la actualidad conocemos como
nitrógeno.

Un químico inglés, Joseph Priestley (1733-1804), también estudió los gases, en
particular, el gas que se formaba al fermentar cereales (vivía al lado de una
fábrica de cerveza), y descubrió que se trataba de anhídrido carbónico. Estudió
sus propiedades, sobre todo la manera en que se disolvía en el agua, y
descubrió que una solución de anhídrido carbónico producía lo que consideró
(pero yo no) una bebida agradable y ácida.

(Cuando yo era joven, esa agua carbonatada se llamaba seltz y se podía comprar
a un centavo el vaso. En la actualidad se la llama «Perrier» y se puede
comprar, según creo, a un dólar el vaso. En mi juventud me negué a invertir un
centavo en esa ácida bebida, y hoy me niego por partida doble a invertir un
dólar.)

Priestley fue el primero en hacer pasar gases a través de mercurio en vez de a
través de agua, y así pudo recoger algunos gases que se hubiesen disuelto al
instante en agua, empleando el método de Hales. De este modo, Priestley aisló y
estudió gases como el cloruro de hidrógeno y el amoníaco.

Su descubrimiento más importante tuvo lugar en 1774. Cuando el mercurio se
calienta mucho en el aire, se forma en su superficie un polvo rojizo. Esto es
el resultado de combinarse el mercurio (con cierta dificultad) con una porción
del aire. Si el polvo rojizo se recoge y se calienta de nuevo, la combinación
mercurio-aire se rompe y el componente del aire es liberado como gas.

Priestley descubrió que este componente del aire ayudaba con facilidad a la
combustión. Una astilla ardiendo en rescoldo entraba en fase de llama activa si
se colocaba en un vaso picudo que contuviera este gas. Los ratones encerrados
en un recipiente con este gas se comportaban de una forma desacostumbradamente
vivaracha y, cuando Priestley respiró un poco del gas, le hizo sentirse «alegre
y a gusto». Se trata del gas que en la actualidad llamamos «oxígeno».

Fue el químico francés Antoine Laurent Lavoisier (1743-1794), según la opinión
general el mayor químico de todos los tiempos, quien dio sentido a todo esto.
Sus cuidadosos experimentos le mostraron, hacia 1775, que el aire consistía en
una mezcla de dos gases, nitrógeno y oxígeno, en una proporción aproximada de 4
a 1 por volumen. (Sabemos ahora que hay un número de constituyentes menores en
el aire seco, que forman más o menos el 1% del total, con un porcentaje del
0,03 de anhídrido carbónico incluido.)

Lavoisier demostró que la combustión es el resultado de la combinación química
de sustancias con el oxígeno del aire. Por ejemplo, al quemar carbón, que es
casi carbón puro, es su combinación con el oxígeno lo que forma anhídrido
carbónico. Cuando el hidrógeno arde, se combina con el oxígeno para formar
agua, que consiste así en una combinación química de esos dos gases.

Lavoisier sugirió correctamente que los alimentos que comemos y el aire que
respirarnos se combinan uno con otro de modo que la respiración es una forma de
combustión lenta. Esto significa que los seres humanos inhalamos aire que es,
comparativamente, rico en oxígeno, pero exhalamos aire que, comparativamente,
ha agotado ese gas y se ha enriquecido en anhídrido carbónico. Unos cuidadosos
análisis químicos de aire exhalado demostraron que esto es cierto.

Existía entonces una explicación satisfactoria para el hecho de que una vela
que ardía en un contenedor cerrado, con el tiempo se apagara, de que un ratón
vivo en una cámara de este tipo al final se muriese, y de que el aire que
quedaba en estas cámaras no permitiera la combustión de ninguna vela más ni la
respiración de ningún otro ratón.

Lo que ocurría era que tanto el arder como la respiración consumían
gradualmente el contenido de oxígeno del aire y lo reemplazaba por anhídrido
carbónico, dejando intacto el nitrógeno. El aire compuesto por una mezcla de
nitrógeno y anhídrido carbónico no permitía la combustión ni la respiración.

Esto planteo un interesante problema. Todo animal vivo respira
ininterrumpidamente, inhala aire que tiene un 21% de oxigeno, y constantemente
también expira aire que sólo tiene un 16% de oxígeno. Sin duda llegaría un
momento en que el contenido de oxígeno de la atmósfera de la Tierra, en
conjunto, se agotaría hasta el punto de que la vida resultaría imposible.

Esto habría sucedido en un tiempo menor que el que abarca la historia conocida
de la civilización, por lo que únicamente podemos llegar a la conclusión de que
algo reemplaza el oxígeno con tanta rapidez como se consume. ¿Pero de qué se
trata?



El primer indicio de una respuesta al problema llegó de Priestley, incluso
antes de que descubriese el oxígeno.

Priestley había introducido un ratón en un recipiente de aire cerrado y, con el
tiempo, el ratón murió. El aire como estaba entonces no permitía que viviera en
él ningún animal más, y Priestley se preguntó si mataría también las plantas.
Si era así, ello demostraría que las plantas eran asimismo una forma de vida,
lo cual constituiría una conclusión interesante pero antibíblica. (Este
antibiblicismo no hubiera preocupado a Priestley, que era Unitario y, por lo
tanto, radical en religión, y también un radical social, digamos de paso.)

En 1771, Priestley colocó un ramito de menta en un vaso de agua, y lo metió en
un contenedor de aire en que había vivido y muerto un ratón. La planta no
murió. Creció durante meses y pareció medrar. Y lo que es más, pasado este
tiempo pudo colocarse un ratón en el aire encerrado y vivió durante una
temporada bastante larga, y una vela metida en el recipiente continuó ardiendo
durante un tiempo.

En resumen, la planta pareció haber revitalizado el aire que el animal había
consumido.

En términos modernos, podríamos decir que, mientras los animales consumen
oxígeno, las plantas lo producen. La combinación de ambos procesos deja
inmutable el porcentaje total de oxígeno en la atmósfera.

De este modo, las plantas llevan a cabo el doble servicio de proporcionar a la
vida animal su inagotable suministro de oxígeno, así como de alimentos, por lo
que, aunque los animales (incluyéndole a usted y a mí) respiran y comen
constantemente, siempre existe más oxigeno y alimentos para respirar y para
comer.

Una vez Lavoisier explicó la combustión y colocó los modernos cimientos de la
Química, el asunto de la actividad de las plantas suscitó un particular interés.

Un botánico holandés, Jan Ingenhousz (1730-1799), se enteró del experimento de
Priestley y decidió profundizar más en este asunto. En 1779 realizó numerosos
experimentos ideados para estudiar la manera en que las plantas revitalizaban
el aire consumido, y descubrió que las plantas producían su oxígeno sólo en
presencia de la luz. Esto lo hacían durante el día, pero no durante la noche.

Un botánico suizo, Jean Senebier (1742-1809), confirmó en 1782 los
descubrimientos de Ingenhousz y fue más lejos. Mostró que era necesario algo
más para que las plantas produjeran oxígeno: debían también estar expuestas al
anhídrido carbónico.

Era el momento adecuado para repetir el experimento de Helmont de un siglo y
medio antes, a la luz de los nuevos conocimientos. Esto fue realizado por otro
botánico suizo, Nicolas Théodore de Saussure (1767-1845). Dejó que las plantas
creciesen en un contenedor cerrado con una atmósfera que contenía anhídrido
Carbónico, y midió cuidadosamente cuánto anhídrido carbónico Consumía la planta
y cuánto peso de tejido se ganaba. La ganancia en peso de tejido fue
considerablemente mayor que el peso del anhídrido carbónico consumido, y De
Saussure mostró de una forma del todo convincente que la única posible fuente
del peso restante era el agua: Helmont había tenido en parte razón.

Para entonces se conocía lo suficiente para dejar claro que las plantas estaban
vivas igual que los animales, y para hacerse una idea de cómo se equilibraban
mutuamente las dos grandes ramas de la vida.

Los alimentos, ya sean de tejido vegetal o animal, son ricos en átomos de
hidrógeno y carbono, C y H. (La teoría atómica se estableció en 1803 y fue
adoptada con bastante rapidez por los químicos.) Cuando el alimento se
combinaba con oxígeno, formaba anhídrido carbónico (C02) y agua (H20).

La combinación de sustancias que contienen átomos de hidrógeno y carbono con
átomos de oxígeno liberan por lo general, energía. La energía química de las
sustancias de carbono-hidrógeno se convierte en el cuerpo en energía cinética,
como cuando los músculos se contraen, o en energía eléctrica, como cuando los
nervios dirigen los impulsos, etcétera. Por lo tanto, podríamos escribir:

alimento + oxígeno Þ anhídrido carbónico + agua + energía cinética (etc.)

Con las plantas se produce en sentido inverso:

luz + anhídrido carbónico + agua Þ alimento + oxígeno

Lo que esto quiere decir es que plantas y animales, al actuar juntos, mantienen
los alimentos y el oxígeno, por un lado, y el anhídrido carbónico y el agua por
el otro, en equilibrio, de modo que, en conjunto, las cuatro cosas permanecen
en cantidad constante, sin aumentar ni disminuir.

El único cambio irreversible es la conversión de energía luminosa en energía
cinética, etc. Así ha sido desde que existe la vida y puede continuar de este
modo sobre la Tierra mientras el Sol continúe irradiando luz, aproximadamente
de la forma actual. Esto fue reconocido y declarado por primera vez en 1845 por
el físico alemán Julius Robert von Mayer (1814-1878).

¿Cómo llegó a desarrollarse este equilibrio en dos sentidos? Podemos especular
sobre el tema.

En un principio, fue la luz ultravioleta del Sol la que, con probabilidad,
suministró la energía para formar moléculas relativamente grandes a partir de
las más pequeñas de las aguas sin vida del mar primitivo. (La conversión de
pequeñas moléculas en otras grandes, por lo general, implica una entrada de
energía; lo contrario normalmente también implica una salida de energía.)

Cuando por fin se formaron moléculas lo suficientemente grandes y complejas
para poseer las propiedades de la vida, éstas pudieron emplear (como alimento)
moléculas de moléculas intermedias (lo suficientemente complejas para producir
energía al descomponerse, pero no lo suficientemente complejas para ser vivas y
capaces de contraatacar).

La energía del Sol, que actúa sobre una base de todo o nada, se formaba, sin
embargo, sólo en la forma de moléculas intermedias, y éstas podían mantener por
si solas bastante vida.

Por lo tanto, correspondió a los sistemas vivos el constituir membranas por si
mismas (convirtiéndose en células), que podrían permitir que pasasen pequeñas
moléculas hacia adentro. Si los sistemas vivos poseyeran mecanismos que usaran
la energía solar para la formación de moléculas esas pequeñas moléculas
formarían otras más grandes antes de que tuviesen una oportunidad de salir de
nuevo, y las grandes, una vez formadas, tampoco podrían salir.

De esa manera, esas células (los prototipos de las plantas) vivirían en un
microambiente rico en alimentos y florecerían en un grado mucho mayor que las
formas de vida precelulares que carecían de capacidad para dirigir la
fabricación de alimentos a través del empleo de la energía solar.

Por otra parte, las células que carecen de capacidad para usar la energía solar
para constituir alimentos pueden aún crecer si desarrollan medios de hurtar el
contenido alimenticio de células que sí pueden hacerlo. Estos rateros fueron
los prototipos de los animales.

Pero ¿son esos rateros unos parásitos y nada más?

Tal vez no. Si las plantas existiesen solas concentrarían todas las pequeñas
moléculas disponibles en sus propios tejidos y después el crecimiento y el
desarrollo serían lentos. Los animales sirven para descomponer una razonable
proporción del complejo contenido de las células vegetales y permitir así el
crecimiento continuado de la planta, su desarrollo y la evolución en una
proporción mayor de lo que seria posible de otro modo.



Las moléculas alimenticias son mucho más grandes y más complejas que las
moléculas de anhídrido carbónico y agua. Las dos últimas poseen moléculas
compuestas por tres átomos cada una, mientras que las moléculas características
de los alimentos están compuestas por entre una docena y un millón de átomos.

La formación de moléculas grandes a partir de otras más pequeñas es denominada
«síntesis» por los químicos, según las palabras griegas que significan «unir».
Mientras que de una forma característica los animales descomponen las moléculas
alimenticias combinándolas con oxígeno para formar anhídrido carbónico y agua,
las plantas, de una forma también característica, sintetizan esas moléculas a
partir del anhídrido carbónico y el agua.

Las plantas tienen que emplear la energía de la luz. Por lo tanto, esa clase
particular de síntesis se denomina «fotosíntesis», y el prefijo «foto» procede
de la palabra griega que significa «luz». ¿No les había dicho que les
explicaría esa palabra?

Pero hay unas cuantas cosas más que puedo explicar también al respecto, pero
eso será en el capitulo siguiente.





X. VERDE, VERDE, VERDE ES EL COLOR...





Cuando estaba comprando la máquina de escribir eléctrica en la que estoy
escribiendo el primer borrador de este capítulo (la copia final la haré con mi
procesador de texto), el vendedor me planteó su última pregunta:

—¿Y de qué color le gustaría? —y me mostró una página en la que se ilustraban
varios colores de la forma más viva posible.

Para mí fue una pregunta incómoda, porque no me siento inclinado hacia lo
visual y, por lo general, no me preocupa el color que puedan tener las cosas.
Mientras miraba pensativamente aquellas muestras, me percaté de que había
tenido una máquina de cada uno de los colores indicados menos el verde. Por lo
tanto, pedí el color verde y en su momento, me llegó la máquina de escribir.

Entonces, Janet (mi querida esposa) mostró su asombro:

—¿Por qué escogiste el color verde? — me preguntó.

Se lo expliqué.

Y me contestó:

—Pero si tu alfombra es azul. ¿O no te has dado cuenta?

Miré la alfombra, que sólo hacia siete años que la tenía y, Dios bendito, mi
mujer tenía razón.

Respondí:

—¿Y eso qué importa?

—La mayoría de la gente —me explicó —cree que el verde y el azul no combinan.

Pensé en ello y repuse:

—La hierba es verde y el cielo es azul, la gente siempre está hablando de las
bellezas de la Naturaleza.

Por una vez la había atrapado. Se echó a reír y nunca más me dijo nada acerca
de mi máquina de escribir verde.

Sin embargo, yo, por mi parte, tengo intención de hablar un poco acerca del
verde.

En el capítulo anterior he explicado que los animales combinan las complejas
moléculas del alimento con el oxígeno del aire, y al hacerlo descomponen esas
moléculas complejas en las relativamente simples de anhídrido carbónico y agua.
La energía liberada por estos medios es utilizada por el cuerpo animal en todo
el proceso consumidor de energía característico de la vida: contracción
muscular, impulso nervioso, secreción glandular, acción renal, etcétera.

Por otra parte, las plantas emplean la energía del Sol para invertir el proceso
anterior (fotosíntesis), combinando anhídrido carbónico y agua para formar las
moléculas complejas del tipo que se encuentra en los alimentos, y liberando
oxígeno al hacerlo.

Plantas y animales, todos juntos, intervienen en un proceso químico cíclico que
mantiene las moléculas complejas, el oxígeno, el agua y el anhídrido carbónico
en un estado de equilibrio. El único cambio permanente es el de la conversión
de la energía solar en energía química.

La pregunta es: ¿Qué hace tan diferentes a las plantas y a los animales? ¿Qué
hay en las plantas que les permite fotosintetizar, empleando la energía del Sol
para ello; y qué hay en los animales que les imposibilita realizar lo mismo?
Antes de que nos sumerjamos en las profundidades de las células y moléculas en
búsqueda de algo muy sutil y delicado, podríamos volver atrás y ver si, por
alguna casualidad, existe algo muy evidente que nos responda esa pregunta.

Podría parecer que no tenemos muchas posibilidades de encontrar algo
inmediatamente en la superficie, dado que la Madre Naturaleza tiende a mantener
sus pequeños trucos ocultos bajo el sombrero, pero, en este caso, un punto muy
evidente se nos muestra al instante.

Algo que salta a la vista es que todas las plantas, o por lo menos las partes
más importantes de las plantas, son verdes. Y lo que es más, mientras los
animales pueden exhibir una gran variedad de colores, el verde brilla por su
ausencia.

Ninguna afirmación es por completo universal (y es mejor que lo diga antes de
que algún lector lo haga). Existen cosas vivas que parecen plantas en diversos
aspectos crecen en el suelo, poseen celulosa, y muestran otras diversas
propiedades físicas y químicas asociadas con las plantas y que, sin embargo, no
son verdes.

Los ejemplos más familiares son las setas, y esas plantas no verdes se agrupan
como «hongos», término que deriva de una palabra latina para designar las setas.

De la misma manera, existen los loros que, aunque indudablemente son animales,
poseen unos plumajes de un chillón color verde. (Sin embargo, no existe ningún
parecido químico entre el verde de las plumas de los loros y el verde de la
hierba.)

Semejantes excepciones son triviales y no quitan importancia a la
generalización de que las plantas son verdes y los animales no lo son.

Sin embargo, tal vez se trate de una coincidencia, y a lo mejor los dos
contrastes —verde contra no verde, y fotosíntesis contra no fotosíntesis —no
tengan nada que ver lo uno con lo otro.

¡No es así! En las plantas que son en parte verdes y en parte no verdes, es
invariablemente en la proporción verde donde tiene lugar la fotosíntesis. Así,
en un árbol, es en las hojas verdes donde encontramos la fotosíntesis, y no en
el tronco marrón o en las flores de diversos colores. Y, en los hongos, que son
plantas sin partes verdes, tampoco hay fotosíntesis. Los hongos, al igual que
los animales, pueden crecer sólo si, de una forma u otra, pueden ya disponer de
moléculas complejas.

Por esa razón, a menudo hablamos de fotosíntesis como de algo que tiene lugar
no en las plantas, sino en las plantas verdes, asegurándonos así de que no
generalizamos demasiado.



¿Y por qué el color debería tener algo que ver con la fotosíntesis? Recuerden
que ese proceso requiere el empleo de energía solar.

Si la luz del Sol traspasase una planta, no podría emplearse en absoluto para
suministrar la energía necesaria. Lo mismo ocurriría si la luz del Sol se
reflejase por entero. En el primer caso, la planta seria transparente, y en el
segundo seria blanca, y en ninguno de los dos casos habría fotosíntesis.

Para que la fotosíntesis tenga lugar, la luz solar debe ser detenida y
absorbida por la planta. Si toda la luz del Sol fuese absorbida, la planta
sería negra, pero no es necesaria la absorción total.

La luz solar es una mezcla de un enorme número de diferentes longitudes de
ondas de luz, y cada una de estas longitudes de onda está compuesta por cuantos
que poseen un contenido energético específico. (Cuanto más larga sea la
longitud de onda, más pequeño será el contenido de energía de los cuantos.)

Para que tenga lugar un cambio químico determinado, debe suministrarse una
cantidad determinada de energía, y esos cuantos trabajan mejor si se emplea la
cantidad correcta. En el caso de la fotosíntesis, es la luz roja la que actúa
mejor, y esto constituye algo bueno. La luz roja posee las más largas
longitudes de onda de la luz visible, y puede traspasar la niebla y las nubes
un poco mejor que las demás formas de luz visible, y se dispersa menos cuando
el Sol está bajo en el horizonte. Por lo tanto, las plantas hacen bien en
depender de la luz roja y no de cualquier otra forma de luz visible.

En ese caso, ¿por qué molestarse en desarrollar un sistema fotosintético que
absorba algo más que la luz roja? Absorber longitudes de onda más cortas no
serviría de nada, requeriría la evolución de compuestos especiales con la
capacidad necesaria y elevaría innecesariamente la temperatura de las plantas.

Por lo tanto, las plantas poseen un sistema fotosintético que tiende a absorber
la porción roja de la luz solar y a reflejar el resto. La luz solar reflejada
menos la porción roja que se absorbe es de color verde, por lo que las plantas
que fotosintetizan son verdes de modo natural, y cabe esperar que las plantas
que son verdes sean capaces de efectuar la fotosíntesis. Las dos cosas, el
color verde y la fotosíntesis, tienen una relación lógica, y el hecho de que
una vaya acompañada de la otra no constituye una coincidencia.



Sin embargo, tenemos que ir más allá del simple color verde.

Si un fragmento de tejido vegetal es verde, esto sólo se debe a que algún
producto químico específico dentro del tejido absorbe la luz roja, reflejando
el resto, y ese producto químico específico es por sí mismo verde.

Dos químicos franceses, Pierre Joseph Pelletier (1788-1842) y Joseph Bienaimé
Caventou (1795-1877) estaban particularmente interesados en aislar de las
plantas, productos químicos de importancia biológica. Entre los productos
químicos que se aislaron primero, entre 1818 y 1821, se encontraban alcaloides
como la estricnina, la quinina y la cafeína. Pero incluso antes de eso, en
1817, habían extraído materiales que contenía la materia colorante verde de las
plantas, y fueron los primeros en dar un nombre a esta sustancia. La llamaron
«clorofila», que procede de las palabras griegas que significan «hoja verde».

Este adelanto fue algo importante, pero es sólo el principio. Pelletier y
Caventou miraron una solución verde en un tubo de ensayo y le dieron un nombre,
pero ¿qué es la clorofila?

En 1817 la teoría atómica sólo tenía, más o menos, una década de antigüedad, y
los químicos no tenían modo de precisar la disposición de los átomos dentro de
una molécula complicada. Hasta 1906 no se realizó un ataque importante a la
estructura atómica de la clorofila, y lo hizo el químico alemán Richard
Willstatter (1872-1942).

Fue el primero en preparar clorofila en forma razonablemente pura, y descubrió
que no se trataba de uno, sino de dos productos químicos muy relacionados, a
los que llamó «clorofila-a» y «clorofila-b», difiriendo ambos levemente en sus
pautas de absorción de la luz. El primero era el más común, formando alrededor
de las tres cuartas partes de la combinación.

Teniendo los productos químicos puros, fue capaz de estudiar los diferentes
elementos que estaban presentes, con bastante seguridad de que dichos elementos
demostrarían ser, en realidad, parte de las moléculas de clorofila, y no parte
de cualesquiera impurezas que también pudiesen estar presentes. La clorofila
contiene átomos de carbono, de hidrógeno, oxígeno y nitrógeno, pero eso no
constituyó ninguna sorpresa. En la época de Willstatter se sabía que
prácticamente todas las moléculas complejas de los organismos vivos (las
llamadas moléculas orgánicas) contenían átomos de carbono, hidrógeno y oxígeno,
y que un buen porcentaje de las mismas contenía asimismo átomos de nitrógeno.

Sin embargo, Willstatter descubrió que la clorofila contenía también átomos de
magnesio. Fue la primera molécula orgánica descubierta que contenía dicho
elemento.

En la actualidad, sabemos que cada molécula de clorofila-a contiene 137 átomos,
mientras que cada molécula de clorofila-b contiene 136 átomos.

Hoy se sabe que una molécula de clorofila-a tiene 72 átomos de hidrógeno, 55
átomos de carbono, 5 átomos de oxígeno, 4 átomos de nitrógeno y 1 átomo de
magnesio. Una molécula de clorofila-b tiene dos átomos menos de hidrógeno y un
átomo más de oxígeno.

Si se conoce el número total de átomos de una molécula, y cuántos de cada
variedad están presentes, esto aún significa muy poco. Lo que cuenta es la
disposición de esos átomos y 136 ó 137 átomos de cinco clases diferentes pueden
ordenarse en un número astronómico de maneras diferentes.

Una forma de conseguir algún indicio de la disposición consiste en descomponer
las moléculas complejas, de algún modo, en fragmentos más simples que luego se
pueden estudiar. Un fragmento determinado podría contener no más de
aproximadamente una docena de átomos de tres clases diferentes, y podría
encajar razonablemente bien en sólo dos o tres formas distintas. Incluso podría
ser que la experiencia química llevara a suponer que la probabilidad de una
disposición determinada de esos pocos átomos es mucho mayor que cualquier otra.

Así pues, para aclarar el asunto, los químicos podían realmente sintetizar
varias moléculas que contenían el número requerido de diferentes tipos de
átomos en cada una de las distintas disposiciones probables, comparándolas con
el fragmento obtenido de la molécula de clorofila. Cuando aparece una identidad
de propiedades, se sabe que el fragmento es equivalente al compuesto sintético
con el que concuerda.

De este modo, Willstatter descubrió que, entre los fragmentos de las moléculas
de clorofila, debían encontrarse pequeñas moléculas que contuviesen cuatro
átomos de carbono y un átomo de nitrógeno, estando esos cinco átomos dispuestos
en forma de anillo. El anillo más simple de éstos tenía un átomo de hidrógeno
unido a cada uno de los cinco átomos del anillo. A este compuesto le llamó
«pirrol» el químico alemán Friedlieb Ferdinand Runge (1795-1867), que fue el
primero que lo aisló, en 1834. El nombre procede de una voz griega que designa
un rojo vivo, puesto que cuando se trata el pirrol con ciertos ácidos, se forma
una brillante sustancia roja.

Por lo tanto, parecía lógico suponer que la clorofila consistía en anillos de
pirrol dispuestos de tal forma que producía una pauta aún más complicada. En
1912, un químico llamado William Kúster propuso que cuatro anillos de pirrol
podían formar un anillo más grande, estando conectado cada par de pirroles por
un puente consistente en un sólo átomo de carbono.

Un compuesto constituido por un anillo así de anillos de pirrol se denomina
«porfirina», un término empleado por primera vez por el bioquímico alemán Félix
Hoppe-Seyler (1825-1895), hacia el año 1860. Porfirina deriva de una voz griega
para designar «púrpura», dado que muchas porfirinas son de este color.

Así, pues en la época en que se realizó el trabajo de Willstatter, parecía del
todo seguro que la clorofila poseía una molécula que tenía un anillo de
porfirina en el centro, pero quedaban aún muchos detalles que tenían que ser
dilucidados.

El anillo de anillos de porfirina posee muchas simetrías en la disposición de
los átomos, y dichas simetrías contribuyen a la estabilidad de la molécula. (El
químico estadounidense Linus Pauling (n. 1901) demostró este tipo de cosas en
su revolucionaria aplicación de la mecánica de los cuantos a la estructura
molecular, hace cincuenta años.) Por consiguiente, la estructura de la
porfirina, con su esqueleto de anillo compuesto por 20 átomos de carbono y 4
átomos de nitrógeno, se encuentra comúnmente en la vida y está incluida en
diversos componentes esenciales, tanto de las plantas como de los animales, y
no sólo en la clorofila.

Así, en muchos animales (incluyendo a los seres humanos) existe una porfirina
púrpura, el «heme». Este heme, cuando se une a una proteína adecuada, forma
hemoglobina, la sustancia roja que absorbe oxígeno en los pulmones, o
branquias, y lo pasa a las células del tejido. En combinación con otras
proteínas, el heme forma enzimas implicadas en el manejo del oxígeno por las
células, y éstas se encuentran universalmente en todas las células que usan
oxigeno, tanto en las plantas como en los animales.

Constituye un ejemplo de la economía de la Naturaleza el que el mismo anillo de
anillos estable pueda, con leves modificaciones, producir la clorofila verde,
tan esencial para las plantas, y el heme, tan útil para los animales. (Mientras
que en la clorofila el color verde es algo esencial, en el heme el color
púrpura es un mero resultado secundario y no desempeña ningún papel en su
funcionamiento.)

Pero ¿cómo se modifica el anillo de porfirina para formar éste o aquél
compuesto?

Los cuatro anillos de pirrol están dispuestos con los átomos de nitrógeno
señalando hacia el centro. Los dos átomos de carbono que están al lado del
átomo de nitrógeno en cada anillo de pirrol intervienen en la formación del
anillo grande (estos átomos de carbono son aquellos con los que los anillos de
pirrol «se dan la mano»).

Esto deja libres a los dos átomos de carbono en el extremo más alejado del
anillo de pirrol. Estos ocho átomos de carbono (dos en cada uno de los anillos
de pirrol) pueden estar unidos a una cadena lateral de uno o más átomos de
carbono a la cual, a su vez, pueden estar unidos aún otros átomos. Así pues,
¿qué cadenas laterales concretas se hallan implicadas, y dónde enlaza cada
cadena lateral en el anillo de porfirina?

El problema fue abordado por el químico alemán Hans Fischer

(1881-1945) en los años veinte. Trabajó con heme y, tras separar las cadenas
laterales, estudió y analizó la mezcla resultante. Demostró que cada molécula
de heme posee cuatro cadenas laterales formadas por 1 átomo de carbono y 3
átomos de hidrógeno (un «grupo metilo»); otras dos se hallaban formadas por 2
átomos de carbono y 3 átomos de hidrógeno (un «grupo vinilo»), y dos cadenas
laterales que consistían en 3 átomos de carbono, 5 átomos de hidrógeno y 2
átomos de oxígeno (un «grupo de ácido propiónico»).

Esos ocho grupos de tres variedades diferentes pueden ordenarse de quince
formas distintas en el esqueleto del anillo de porfirina. ¿Y qué forma es la
correcta?

Fischer había desarrollado métodos para sintetizar moléculas de porfirina
completas con las cadenas laterales, y por tanto adoptó una estrategia de
asalto en masa. Pidió a cada uno de quince estudiantes graduados que
sintetizasen una molécula diferente de porfirina con las cadenas laterales
dispuestas de una manera concreta, para que pudiesen producirse las quince. En
1929 mostró que una en particular de las quince era la correcta. La disposición
de la cadena lateral, al dar la vuelta al anillo de porfirina, resultó ser
metilo, vinilo, metilo, vinilo, metilo, ácido propiónico, ácido propiónico,
metilo.

A continuación, Fischer se ocupó de la clorofila. Obviamente tenían que existir
diferencias, siendo la más importante de ellas que el heme poseía un átomo de
hierro en el centro del anillo de porfirina, mientras que la clorofila tenía un
átomo de magnesio. Sin embargo, si se separaba el átomo de hierro del primero y
el átomo de magnesio del segundo, lo que quedaba en ambos casos tampoco era
idéntico. Había también otras diferencias.

Para empezar, los cuatro grupos metilo se encuentran en el mismo lugar en la
clorofila-porfirina y en el heme-porfirina. Lo mismo ocurre con los dos grupos
vinilo, excepto que en el segundo hay dos átomos adicionales de hidrógeno para
formar un «grupo etilo». Los grupos de ácido propiónico están en el mismo lugar
que en el heme, pero considerablemente modificados. Uno de los grupos de ácido
propiónico se enrosca para combinarse con el anillo de pirrol adyacente para
formar un quinto anillo, y se añade un átomo adicional de carbono. En el caso
del otro, queda libre, pero lleva unida a él una larga cadena de veinte
carbonos (el «grupo fitilo»)

Al menos esto es la clorofila-a. En la clorofila-b, una de las cadenas
laterales de metilo se convierte en un «grupo aldehído», compuesto por un átomo
de carbono, uno de hidrógeno y uno de oxigeno.

Esta descripción de la estructura de la clorofila fue deducida de los análisis
de fragmentos de Fischer, pero la confirmación final no podía lograrse hasta
que se construyera una estructura de clorofila en el laboratorio, que encajase
con la estructura sugerida. Si se demostraba que la molécula sintética era
idéntica en todas las propiedades a la natural, la estructura quedaría
demostrada sin lugar a dudas.

La clorofila tiene una estructura más complicada que el heme, no obstante, y
Fischer no logró su síntesis. No se consiguió con éxito hasta 1960, cuando el
químico estadounidense Robert Burns Woodward (1917-1979) llevó a cabo la tarea,
y se confirmó la estructura.



Una vez tenemos la clorofila, e incluso podemos sintetizarla, ¿existe la
posibilidad de que podamos cortocircuitar el mundo de las plantas? Tal vez
pudiésemos aislar la clorofila y hacerla funcionar en grandes instalaciones
químicas. Aplicando luz sobre ella y proporcionándole condiciones favorables,
¿podríamos lograr convertir anhídrido carbónico y agua en sustancias
alimenticias con gran eficacia y sin precisar su esfuerzo para satisfacer las
necesidades de la estructura y funcionamiento de la planta?

¡No! Si ponemos clorofila en un tubo de ensayo y la exponemos a la luz, no
fotosintetiza. Aunque se extraigan otros compuestos también presentes en las
células de las plantas y se añadan a la clorofila, no tendrá lugar la
fotosíntesis. Al parecer, dentro de las células de la planta, la clorofila
constituye una parte de un intrincado y bien organizado sistema que actúa como
un todo, que trabaja con suavidad, para desarrollar el proceso de fotosíntesis
que incluye muchos pasos. La clorofila hace posible el paso clave, y sin ella
no puede suceder nada, pero ese paso clave no es por si mismo suficiente.

Un organismo está compuesto por células, pero cada célula no es una gota de
protoplasma desorganizada. Más bien, dentro de cada célula existen estructuras
aún más pequeñas denominadas organelas, estando cada una de ellas altamente
organizada. Como ejemplo, un tipo importante de organelas presente
prácticamente en todas las células son los cromosomas, que contienen la
maquinaria genética que hace posible la reproducción. Otro ejemplo lo
constituyen los mitocondrios, que son las centrales eléctricas de la célula y
que contienen un complejo sistema de enzimas tan organizado, que hace posible
el combinar alimentos y oxígeno de manera que se produzca energía de una forma
controlada y útil.

En el interior de las células de las plantas, la clorofila resulta que está
también confinada en ciertas organelas. Esto fue demostrado por primera vez en
1865, por el fisiólogo botánico alemán Julius von Sachs (1832-1897). Esas
organelas recibieron el nombre de cloroplastos.

Los cloroplastos son organelas grandes dos o tres veces más grandes y más
gruesas que las mitocondrias, por ejemplo, y no resulta sorprendente que la
estructura de los cloroplastos sea, en consecuencia, el más complejo de los dos.

El interior del cloroplasto está compuesto por numerosas membranas delgadas que
se extienden en todo lo ancho de la organela. Son las lamelas. En la mayoría de
tipos de cloroplastos, esas lamelas se hacen más gruesas y se oscurecen en
ciertos lugares para formar condensaciones llamadas grana. Las moléculas de
clorofila se encuentran en los grana.

Si los grana se estudian bajo el microscopio electrónico, a su vez parecen
estar formados por diminutas unidades, apenas visibles, que tienen el aspecto
de las baldosas bien puestas del suelo de un cuarto de baño. Cada uno de esos
objetos puede ser una unidad fotosintetizadora que contiene de 250 a 300
moléculas de clorofila.

Los cloroplastos son mucho más difíciles de manejar que las mitocondrias, ya
que a su mayor complejidad estructural, al parecer, se añade una mayor
fragilidad. Cuando las células se descomponen, por ejemplo, los mitocondrios
pueden ser aislados, intactos, con relativa facilidad, e incluso puede hacerse
que sigan llevando a cabo su función.

No ocurre así con los cloroplastos. Incluso los métodos más delicados de
extraerlos de células fragmentadas los destruyen. Aun cuando parezcan intactos,
no lo están, puesto que no fotosintetizarán.

Hasta 1954 no se consiguieron unos cloroplastos lo suficientemente intactos
para llevar a cabo la completa reacción fotosintética, gracias al fisiólogo
botánico polaco-norteamericano Daniel Israel Arnon (n. 1910), trabajando con
células desbaratadas de hojas de espinaca.

Entonces, ¿es ésa la respuesta? ¿Podemos aislar cloroplastos en vez de
clorofila y ponerlos a trabajar en el laboratorio, en condiciones óptimas, para
que elaboren para nosotros almidón, grasas y proteínas?

Teóricamente, sí, pero en la práctica, no. En primer lugar, tendríamos que
depender del mundo vegetal para abastecernos de cloroplastos. En segundo lugar,
los cloroplastos son tan frágiles, que continuamente tendríamos que estar
renovando los suministros. Sería muchísimo más barato y más eficaz a la larga,
continuar empleando los cloroplastos donde pueden conservarse y reproducirse
con facilidad: en el interior de la célula vegetal intacta y viva.

Pero ¿por qué hemos de tratar de reproducir la fotosíntesis en los términos de
las plantas? ¿No podríamos encontrar un sustituto?

El paso clave en la fotosíntesis es la descomposición de la molécula de agua en
hidrógeno y oxígeno. Los químicos pueden llevar a cabo eso con facilidad, pero
sólo con un gran gasto de energía. Pueden realizarlo calentando fuertemente las
moléculas de agua, lo suficiente para que vibren y se rompan en pedazos, o
haciendo pasar una corriente eléctrica a través de una solución diluida de
ácido sulfúrico, para que las cargas eléctricas separen las moléculas. Tanto el
calor como la electricidad, sin embargo, representan un enorme gasto de
energía. El hidrógeno que aislásemos de este modo podría, cuando se recombinase
con oxígeno, liberar una energía considerable que podríamos utilizar; pero la
energía liberada no seria tanta como la que gastaríamos para romper la molécula
de agua y obtener en primer lugar el hidrógeno.

Sin embargo, supongamos que pudiésemos descomponer la molécula de agua
empleando la luz solar, como hacen las plantas. Naturalmente, la energía de la
luz del Sol sería mayor que!a energía que obtendríamos luego combinando el
hidrógeno liberado con oxígeno, pero no tendríamos que invertir nada para
producir la luz solar. Esta está siempre ahí, y se desperdiciaría si no la
utilizáramos.

Las plantas realizan esto a través de sus cloroplastos; pero ¿podríamos
nosotros hacerlo a través de un sistema más simple, estable y eficaz, y que
trabajase incansablemente bajo nuestra dirección?

El hidrógeno y el oxigeno que formásemos del agua podrían recombinarse para
producir energía que seria más concentrada y útil que la luz solar original.
Con eso volverían a formarse moléculas de agua. No se consumiría agua, ni
hidrógeno, ni oxígeno, y el único cambio permanente sería la conversión de la
luz solar diluida en energía química concentrada. El proceso continuaría
mientras el Sol brillase en su forma actual.

Y lo que es más, una vez se formase el hidrógeno, podríamos elaborar métodos
para combinarlo con anhídrido carbónico para formar alimentos. De este modo,
podríamos mirar hacia un futuro en el que los seres humanos, a voluntad podrían
vivir sin el mundo vegetal. Conseguiríamos alimentos y combustible a expensas
de la luz solar.

Naturalmente, no estoy abogando por la eliminación del mundo vegetal, pero
puede que haya épocas en que, de modo temporal, debamos pasar sin él: en viajes
largos a través del espacio en naves no lo suficientemente grandes para tener
un equilibrio ecológico natural, por ejemplo.

En ese caso, sería útil que pudiésemos establecer un sistema artificial para
resolver el problema.

Y los químicos están en ello. El bioquímico estadounidense Melvin Calvin (n.
1911), que, en 1961, obtuvo un premio Nobel por su trabajo al descifrar los
detalles de la reacción fotosintética, está empleando compuestos sintéticos con
metales ideados para imitar la actividad de la clorofila.

Y otros están trabajando asimismo en este campo.

Hasta ahora, nadie ha creado por completo el equivalente de una célula vegetal
artificial, pero no existe razón para que con el tiempo no se consiga y que
ello haga posible que los seres humanos complementen sus suministros de
alimentos y de combustibles de esta forma, e incluso, si es necesario, que
funcionen durante períodos largos en una situación en que ellos mismos (más sus
parásitos internos) sean los únicos organismos vivos.





Cuarta parte





BIOLOGÍA





XI. MAS PENSAMIENTOS ACERCA DEL PENSAMIENTO





En mi libro The Planet that wasn’t (Doubleday, 1976), se encuentra un ensayo
mío que lleva el título de «Pensamientos acerca del pensamiento». En él
expresaba mi insatisfacción con las pruebas de inteligencia y daba mis razones
al respecto. Presentaba argumentos para suponer que la palabra «inteligencia»
implicaba un concepto sutil que no podía medirse con un simple número, tal y
como se representa en el «cociente de inteligencia» (CI).

Quedé muy complacido con el artículo, sobre todo porque fui atacado por un
psicólogo por cuyo trabajo yo tenía muy poco respeto (véase el artículo «Por
desgracia, todo es humano», en El sol brilla luminoso, publicado en esta
colección), tampoco creí que jamás tuviera que añadir nada. En realidad, más
bien sospechaba que había expuesto todas las posibles ideas que pudiese tener
respecto al tema de la inteligencia.

Y luego, no mucho antes de escribir esto, me encontré sentado a la mesa en una
cena con Marvin Minsky, del M.I.T., a mi derecha, y con Heinz Pagels, de la
Universidad Rockefeller, a mi izquierda.

Pagels estaba dirigiendo una conferencia de tres días acerca de ordenadores, y
a primera hora de aquel mismo día había hecho de moderador en una discusión
profesional titulada «¿Ha iluminado la investigación de la inteligencia
artificial el pensamiento humano?»

Yo no asistí a esta discusión de expertos (varios compromisos ineludibles me lo
impidieron), pero mi querida esposa, Janet, si lo hizo y. según me contó, al
parecer Minsky, uno de los expertos. y John Searle, de la Universidad de
California, se habían enzarzado en una discusión acerca de la naturaleza de la
inteligencia artificial. Minsky, uno de los más destacados en este campo de
investigación. se oponía al punto de vista de Searle de que la conciencia era
un fenómeno puramente biológico y que ninguna máquina podría tener nunca
conciencia o inteligencia.

Durante la cena, Minskv continuó manteniendo su parecer de que la inteligencia
artificial no era una contradicción conceptual mientras que Pagels apoyaba la
legitimidad del punto de vista de Searle. Dado que yo estaba sentado entre
ambos, el educado pero intenso debate se realizaba por encima de mi cabeza,
tanto literal como figuradamente.

Yo escuchaba los razonamientos con creciente ansiedad, puesto que,
despreocupadamente, había aceptado, meses atrás, dar una charla aquella noche
después de la cena. Y ahora me parecía que el debate Minsky-Searle constituía
el único tema en la mente colectiva de los asistentes a aquella cena, y que
sería absolutamente necesario por mi parte hablar de aquel tema, si quería
tener alguna probabilidad de captar su atención.

Ello significaba que debía volver a pensar acerca del pensamiento. y que tenía
menos de media hora para hacerlo. Naturalmente, salí del apuro, de lo contrario
no les estaría contando esto. En realidad, me dijeron que, durante el resto de
la conferencia, fui de vez en cuando citado con aprobación.

No puedo repetir mi charla palabra por palabra, dado que hablé de forma
improvisada, como siempre hago, pero he aquí un razonable facsímil.



Supongamos que comenzamos con la fácil suposición de que el Homo sapiens es la
especie más inteligente de la Tierra, que viva hoy o lo haya hecho en el
pasado. Por lo tanto, no debería sorprender que el cerebro humano sea tan
grande. Tenemos la tendencia con bastante razón, de asociar el cerebro con la
inteligencia, y viceversa.

El cerebro del humano adulto del sexo masculino tiene una masa de,
aproximadamente, 1,4 kilogramos, como promedio, y es con mucho más grande que
cualquier cerebro que no sea de mamífero, pasado o actual. Esto no resulta
sorprendente, considerando que los mamíferos son una clase que tiene el cerebro
más grande y son más inteligentes que cualquier otro tipo de organismos vivos.

Entre los mismos mamíferos, tampoco resulta sorprendente que cuanto mayor es el
organismo en conjunto, mayor es el cerebro, pero el cerebro humano se aparta de
esta norma. Es más grande que el de aquellos mamíferos que son mucho más
voluminosos que los humanos. El cerebro del hombre es más grande que el del
caballo, el rinoceronte, o el gorila, por ejemplo.

Y, sin embargo, el cerebro humano no es el más grande que existe. El cerebro de
los elefantes es mayor. Se ha encontrado que los cerebros de elefante más
grandes poseen masas de unos 6 kilogramos, más o menos 4 1/4 veces la del
cerebro humano. Y lo que es más, se ha comprobado que los cerebros de las
grandes ballenas son aún más voluminosos. El cerebro de mayor masa jamás medido
fue el de un cachalote, que poseía una masa de 9,2 kilogramos, es decir, 6,5
veces la del cerebro humano.

Sin embargo, nunca se ha pensado que los elefantes y las ballenas grandes,
aunque sean más inteligentes que la mayoría de los animales, pudiesen ni
remotamente compararse con los seres humanos en cuanto a inteligencia. En
resumen: la masa cerebral no es lo único que hay que tener en cuenta en lo que
a la inteligencia se refiere.

El cerebro humano constituye, más o menos, el 2% de la masa total del cuerpo
humano. No obstante, un elefante con un cerebro de 6 kilogramos tendría una
masa de 5.000 kilogramos, de modo que su cerebro constituiría sólo el 0,12% de
la masa de su cuerpo. En cuanto al cachalote, que puede alcanzar una masa de
65.000 kilogramos su cerebro de 9,2 kilogramos representaría sólo el 0,014% de
la masa de su cuerpo.

En otras palabras, por unidad de masa corporal, el cerebro humano es 17 veces
mayor que el del elefante, y 140 veces más grande que el del cachalote.

¿Es razonable poner en relación cerebro/cuerpo por delante de la simple masa
cerebral?

Bueno, al parecer nos da una respuesta verdadera, puesto que señala el hecho
aparentemente obvio de que los seres humanos son más inteligentes que los
elefantes y las ballenas, que tienen cerebros más grandes. Además, podríamos
argumentar (probablemente de una manera simplista) de esta manera:

El cerebro controla las funciones del cuerpo, y lo que queda después de esas
actividades de bajo control de pensamiento puede reservarse para actividades
tales como la imaginación, el razonamiento abstracto y las fantasías creativas.
Aunque los cerebros de los elefantes y ballenas son más grandes, los cuerpos de
esos mamíferos son enormes, por lo que sus cerebros. por muy grandes que sean,
están totalmente ocupados con toda la rutina de hacer funcionar esas vastas
masas, y les queda muy poco para funciones «más elevadas». Elefantes y ballenas
son, pues, menos inteligentes que los seres humanos, a pesar del tamaño de sus
cerebros.

(Y ésa es la razón de que la mujer posea un cerebro con un 10% menos de masa
que el del hombre, como promedio, y no sea un 10% menos inteligente. Su cuerpo
es también más pequeño, y su relación de masa cerebro/cuerpo es, en todo caso,
un poco más elevada que la del hombre.)

De todos modos, la relación de masa cerebro/cuerpo tampoco puede serlo todo.
Los primates (simios y monos) tienen relaciones elevadas de cerebro/cuerpo y,
en conjunto, cuanto más pequeño es el primate, más elevada es la relación. En
algunos monos pequeños, el cerebro constituye el 5,7 % de la masa corporal, y
eso es casi tres veces la proporción que se da en los seres humanos.

¿Por qué, pues, esos pequeños monos no son más inteligentes que los seres
humanos? Aquí la respuesta puede ser que sus cerebros son demasiado pequeños
para servir a ese propósito.

Para tener una inteligencia realmente elevada, se necesita un cerebro lo
suficientemente grande para proporcionar el poder de pensamiento necesario, y
un cuerpo lo suficientemente pequeño para no emplear todo el cerebro no dejando
nada para el pensamiento. Esta combinación de cerebro grande y cuerpo pequeño
parece encontrar su mejor equilibrio en el ser humano.

¡Pero esperen! Igual que los primates tienden a poseer una proporción
cerebro/cuerpo más elevada a medida que se hacen más pequeños, lo mismo hacen
los cetáceos (la familia de las ballenas). El delfín común no es más voluminoso
que un hombre, en conjunto, pero tiene un cerebro que posee unos 1,7 kilogramos
de masa, o 1/5 más masa que el cerebro humano. La proporción cerebro/cuerpo es
del 2,4 %.

En ese caso, ¿por qué no es el delfín más inteligente que el ser humano? ¿Puede
existir alguna diferencia cualitativa entre las dos clases de cerebros que
condene a los delfines a una relativa estupidez?

Por ejemplo, las células cerebrales propiamente dichas están situadas en la
superficie del cerebro y constituyen la «materia gris». El interior del cerebro
está compuesto. en gran parte por las protuberancias recubiertas de grasa que
se extienden desde las células y (gracias al color de las grasas) constituye la
«materia blanca».

Es la materia gris la que se asocia con la inteligencia y. por tanto, el área
superficial del cerebro es más importante que su masa. Cuando consideramos las
especies en orden de inteligencia creciente, hallamos que el área superficial
del cerebro aumenta con mayor rapidez que la masa. Una manera en que esto se
hace aparente es que el área superficial aumenta hasta el punto en que no puede
esparcirse de forma llana por el interior del cerebro, sino que se retuerce
formando circunvoluciones. Un cerebro con circunvoluciones tendría una mayor
área superficial que un cerebro liso de la misma masa.

Por lo tanto, asociamos las circunvoluciones con la inteligencia y, con
seguridad, los cerebros de los mamíferos poseen circunvoluciones mientras que
los cerebros de los no mamíferos no las tienen. El cerebro de un mono posee más
circunvoluciones que el cerebro de un gato. No resulta sorprendente que un
cerebro humano tenga más circunvoluciones que el de cualquier otro mamífero
terrestre, incluyendo incluso a los relativamente inteligentes como los
chimpancés y los elefantes.

Y, sin embargo, el cerebro del delfín tiene más masa que el cerebro humano,
posee una mayor proporción masa de cerebro/cuerpo y, además, tiene más
circunvoluciones que el cerebro humano.

Entonces, ¿por qué los delfines no son más inteligentes que los seres humanos?
Para explicarlo, debemos volver a la suposición de que existe algún defecto en
la estructura de las células del cerebro del delfín, o en su organización
cerebral, puntos respecto de los cuales no existe ninguna evidencia.

No obstante, permítanme sugerir un punto de vista alternativo. ¿Cómo sabemos
que los delfines no son más inteligentes que los seres humanos?

Sin duda, no poseen tecnología, pero esto no es sorprendente. Viven en el agua,
donde el fuego resulta imposible, y el hábil empleo del fuego constituye la
base fundamental de la tecnología humana. Y lo que es más, la vida en el mar
hace esencial el ser aerodinámico, por lo que los delfines carecen del
equivalente de las manos delicadamente manipuladoras que poseen los seres
humanos.

¿Pero es la tecnología sola una medida suficiente de la inteligencia? Cuando
nos interesa, dejamos de lado la tecnología. Consideremos las estructuras
construidas por algunos insectos sociales, tales como abejas, hormigas y
termitas. o la delicada tracería de la tela de las arañas. ¿Todas esas
realizaciones hacen a la abeja, la hormiga, la termita o la araña más
inteligentes que el gorila, que construye un tosco nido en un árbol?

Decimos «no» sin titubear un momento. Consideramos que los animales inferiores,
por maravillosos que sean sus logros, actúan sólo por instinto. y que esto es
inferior al pensamiento consciente. Sin embargo, puede que esto sólo sea
nuestra opinión personal.

¿No podría ser concebible que los delfines considerasen nuestra tecnología el
resultado de una forma inferior del pensamiento. y no aceptarlo como una prueba
de inteligencia, según un juicio propio sólo de ellos?

Naturalmente, los seres humanos tienen la facultad del habla. Empleamos
complejas modulaciones del sonido para expresar ideas infinitamente sutiles. y
ninguna otra especie de seres vivos lo hace o llega siquiera a algo parecido.
(Tampoco pueden comunicarse con la equivalente complejidad, versatilidad y
sutileza por ningún otro medio, por lo que sabemos hasta ahora.)

Sin embargo, la ballena de joroba canta complejas «canciones» mientras que el
delfín es capaz de producir una mayor variedad de sonidos diferentes que
nosotros. ¿Qué nos hace estar tan seguros de que los delfines no pueden hablar?

Pero la inteligencia es algo que se percibe. Si los delfines son tan listos,
¿por qué no resulta obvio que lo son?

En «Pensamientos acerca del pensamiento» mantenía que existen diferentes clases
de inteligencia entre los seres humanos, y que las pruebas de CI son
equivocadas por esta razón. No obstante, aunque fuese así, todas las variedades
inteligenciales humanas (tengo que inventar esta palabra) pertenecen claramente
al mismo género. Nos es posible reconocer estas variedades, aunque sean del
todo diferentes. Podemos ver que Beethoven tenía una clase de inteligencia y
Shakespeare otra, Newton otra aún, y Peter Piper (el experto en elegir adobos)
tiene otra, y podemos comprender el valor de cada una de ellas.

Y. sin embargo, ¿qué podemos decir de una variedad inteligencial diferente de
las que poseen los seres humanos? ¿También la reconoceríamos como inteligencia,
sin importar cómo la estudiásemos?

Imaginemos que un delfín, con su enorme y circunvolucionado cerebro y su amplio
repertorio de sonidos, tuviera una mente que pudiera considerar ideas complejas
y un lenguaje que pudiera expresarlas con infinita sutileza. Pero supongamos
que esas ideas y ese lenguaje fueran tan diferentes de todo a lo que
estuviéramos acostumbrados, que no pudiéramos siquiera captar el hecho de que
eran ideas y lenguaje, y mucho menos entender su contenido.

Supongamos que una colonia de termitas, todas juntas, poseyeran un cerebro
comunitario que pudiera reaccionar de una forma tan diferente a las de nuestras
individualidades, que no viéramos la inteligencia comunitaria, por muy
notoriamente «obvia» que pudiera ser.



El problema puede ser parcialmente semántico. Insistimos en definir el
«pensamiento» de tal manera que llegamos a la conclusión automática de que sólo
los seres humanos piensan. (En realidad los fanáticos a través de toda la
historia, han estado seguros de que sólo los seres masculinos similares en
apariencia a ellos podían pensar, y que las mujeres y «razas inferiores» no
podían hacerlo. Las definiciones que benefician a uno pueden servir de mucho.)

Supongamos que definimos el «pensamiento» como ese tipo de acción que lleva a
una especie a tomar las medidas que aseguren mejor su supervivencia. Según esta
definición, todas las especies piensan, de algún modo. El pensamiento humano no
es sino una variedad más, y no necesariamente mejor que las otras.

En realidad, si consideramos que la especie humana, con plena capacidad para la
premeditación, y conociendo exactamente lo que hace y lo que puede suceder, de
todos modos tiene grandes probabilidades de destruirse a sí misma en un
holocausto nuclear, la única conclusión lógica a la que podemos llegar, según
mi definición, es que el Homo sapiens piensa más pobremente, y es menos
inteligente, que cualquier otra especie que viva, o haya vivido en la Tierra.

Por lo tanto, es posible que, así como los que analizan el Cl logran sus
resultados definiendo cuidadosamente la inteligencia de un modo que hace que
ellos mismos y la gente como ellos, sean «superiores», del mismo modo la
Humanidad, en conjunto, realiza algo parecido con su cuidadosa definición de lo
que constituye el pensamiento.

Para hacerlo más sencillo, consideremos una analogía.

Los seres humanos «andan». Lo hacen sobre dos piernas con su cuerpo de mamífero
erguido, produciendo una inclinación hacia atrás en su columna vertebral. en la
región lumbar.

Podríamos definir el «andar» como el movimiento sobre dos piernas con el cuerpo
en equilibrio sobre una columna curvada.

Según esta definición, andar sería algo único de los seres humanos y podríamos
estar muy orgullosos de este hecho, y con razón. Esta manera de andar liberó a
nuestros miembros superiores de toda necesidad de ayudarnos a movernos
(excepción hecha de ciertas situaciones de emergencia), y nos permitió tener
las manos permanentemente disponibles. Este desarrollo de la posición erguida
precedió al desarrollo de nuestro gran cerebro y puede que, en realidad, nos
llevara a ello.

Otros animales no andan. Se mueven sobre cuatro patas o sobre seis, ocho,
docenas, o ninguna. O vuelan, o nadan. Incluso esos cuadrúpedos que pueden
erguirse sobre sus patas traseras (como los osos y los simios) lo hacen sólo
temporalmente, y están más cómodos sobre sus cuatro patas.

Existen animales que son estrictamente bípedos, como los canguros y las aves,
pero a menudo saltan más que andan. Incluso las aves que andan (como las
palomas y los pingüinos) son principalmente voladoras o nadadoras. Y las aves
que no hacen nunca otra cosa excepto andar (o, su primo más rápido, correr)
como el avestruz, carecen de una columna vertebral curvada.

Así pues, supongamos que insistiéramos en hacer del «andar» algo por completo
único, hasta el punto de que careciéramos de palabras para las maneras en que
otras especies avanzan. Supongamos que nos contentásemos con decir que los
seres humanos fuesen «andantes» y que las demás especies no, y nos negásemos a
ampliar nuestro vocabulario.

Si insistiésemos en hacerlo con suficiente fervor, no necesitaríamos prestar
atención a la bella eficiencia con que algunas especies botan, o saltan, o
corren, o vuelan, o planean, o se zambullen, o se deslizan. No desarrollaríamos
ninguna frase del tipo «locomoción animal» para cubrir todas esas variedades de
modos de avanzar.

Y si dejásemos de lado todas las formas de locomoción animal, menos las
nuestras, como simplemente «no andantes», nunca tendríamos que enfrentarnos con
el hecho de que la locomoción humana es, en muchas formas, no tan grácil como
la de un caballo o un halcón y que es incluso una de las menos gráciles y
admirables formas de locomoción animal.



Supongamos, pues, que inventamos una palabra para designar todas las formas en
que las cosas vivas podrían comportarse para hacer frente a un desafío o para
promover la supervivencia. Llamémoslo «zorquear». El pensar, en el sentido
humano, podría ser una manera de zorquear, mientras que otras especies de cosas
vivas podrían mostrar otras formas de zorquear.

Si abordamos el zorqueo sin ninguna clase de juicio preconcebido, podríamos
descubrir que el pensar no es siempre la manera mejor de zorquear. y podríamos
tener una posibilidad ligeramente mayor de comprender el zorqueo de los
delfines o de las comunidades de termitas.

O supongamos que consideramos el problema de si las máquinas pueden pensar, si
un ordenador puede llegar a tener conciencia; si es posible que los robots
sientan emociones, dónde, en resumen, conseguiremos, en el futuro, una cosa tan
auténtica como la «inteligencia artificial».

¿Cómo podemos discutir una cosa así, sin detenernos primero a considerar qué
podría ser la inteligencia? Si es algo que sólo un ser humano pueda tener por
definición, en ese caso, naturalmente, una máquina no puede tenerla.

Pero cualquier especie puede zorquear, y es posible que los ordenadores también
sean capaces de hacerlo. Tal vez los ordenadores no zorqueen de la forma en que
lo haga cualquier especie biológica, por lo que también necesitamos una nueva
palabra para lo que hacen. En mi improvisada charla acerca de la fuerza del
ordenador, empleé la palabra «groquear», y me parece que servirá igual que
cualquier otra.

Entre los seres humano existe un número indefinido de maneras diferentes de
zorquear; distintas que son suficientemente parecidas para que se incluyan bajo
el titulo general de «pensar». Y, asimismo, entre los ordenadores es seguro que
existe un número indefinido de diferentes formas de zorquear, pero unas formas
tan diferentes de las encontradas en los seres humanos, como para incluirlas
bajo el título general del «groquear».

(Y los animales no humanos pueden zorquear también de diferentes maneras. de
modo que tendríamos que inventarnos docenas de diferentes palabras para las
variedades de zorquear y clasificarlas de un modo complicado. Y lo que es más.
a medida que se desarrollaran los ordenadores, podríamos encontrar que groquear
no era suficiente, por lo que deberíamos elaborar más subtítulos. Pero todo
esto corresponde al futuro. Mi bola de cristal no es infinitamente clara.)

En realidad, diseñamos nuestros ordenadores de tal modo que pueden resolver
problemas que nos son de interés y, por lo tanto, tenemos la impresión de que
piensan. Sin embargo, debemos reconocer que, aunque un ordenador resuelva un
problema que nosotros mismos tendríamos que resolver sin él, él y nosotros lo
solucionamos a través de unos procesos por completo diferentes. Ellos groquean
y nosotros pensamos, y es inútil darle vueltas y discutir de si los ordenadores
piensan. Los ordenadores también podrían darle vueltas y discutir silos seres
humanos groquean.

Pero, ¿es razonable suponer que los seres humanos crearían una inteligencia
artificial tan diferente de la inteligencia humana que requiriese un
reconocimiento del groqueo del ordenador como algo independiente del
pensamiento humano?

¿Por qué no? Ya ha sucedido antes. Durante incontables millares de años, los
seres humanos han transportado objetos poniéndoselos debajo del brazo o
manteniéndolos en equilibrio sobre la cabeza. Al hacerlo, sólo podían
transportar como mucho su masa.

Si los seres humanos apilaban objetos a lomos de asnos, caballos, bueyes,
camellos o elefantes, podían transportar masas mayores. Esto, sin embargo, es
sólo la sustitución del empleo directo de unos músculos más grandes en vez de
otros más pequeños.

Sin embargo, finalmente, los seres humanos inventaron un mecanismo artificial
que hacía más fácil el transporte. ¿Y cómo realizaba esto la máquina? ¿Lo
realizaba produciendo un andar artificial, una carrera o un vuelo, o cualquiera
de la minada de otras formas de locomoción animal?

No. Algunos seres humanos, en los oscuros días de la prehistoria, inventaron la
rueda y el eje. Como resultado de ello, pudo colocarse una masa mucho más
grande en un carro, y ser arrastrado por músculos humanos o animales que la que
podía transportarse directamente con esos músculos.

La rueda y el eje trasero constituyen el más asombroso invento jamás realizado
por los seres humanos, en mi opinión. El empleo humano del fuego fue, por lo
menos, precedido de la observación de los incendios naturales producidos por el
rayo. Pero la rueda y el eje no tenían ningún antepasado natural. No existen en
la Naturaleza; ninguna forma de vida los ha desarrollado hasta hoy. Así la
«locomoción con ayuda de máquinas» fue, desde su concepción, algo completamente
diferente de todas las formas de locomoción humana y, del mismo modo, no
resultaría sorprendente que el zorqueo mecánico fuese distinto de todas las
formas de zorqueo biológico.

Naturalmente, los carros primitivos no podían moverse por sí mismos, pero, con
el tiempo se inventó la máquina de vapor, y más tarde el motor de combustión
interna y el cohete, ninguna de estas cosas se comporta de forma parecida a los
músculos.

Los ordenadores se encuentran, sin embargo, en la actualidad, en el período
anterior a la máquina de vapor. Los ordenadores pueden realizar sus funciones,
pero no lo hacen «por sí mismos». Con el tiempo se desarrollará el equivalente
de una máquina de vapor y los ordenadores serán capaces de resolver los
problemas por sí mismos, pero, de todos modos, a través de un proceso
totalmente diferente al del cerebro humano. Lo harán groqueando más que
pensando.

Todo esto parece descartar el miedo a que los ordenadores «nos reemplazarán», o
que los seres humanos se harán superfluos y desaparecerán.

A fin de cuentas, las ruedas no han hecho superfluas las piernas. Hay ocasiones
en que andar resulta más conveniente y más útil que ir sobre ruedas. Abrirse
camino por un terreno accidentado es fácil andando, y muy difícil en automóvil.
Y no imagino ningún modo de ir de mi dormitorio al cuarto de baño que no sea
andando.

Pero ¿no podrían los ordenadores llegar a hacer todo lo que los seres humanos
pueden realizar, aunque groqueen en vez de pensar? ¿No podrían los ordenadores
groquear sinfonías, dramas, teorías científicas, asuntos amorosos, cualquier
cosa que se quiera imaginar?

Tal vez. De vez en cuando veo una máquina diseñada para levantar las piernas
por encima de obstáculos, para que camine. Sin embargo, la máquina es tan
complicada y el movimiento tan poco grácil, que no me sorprende que nadie
llegue a tomarse la enorme molestia de tratar de producir y emplear semejantes
cosas como algo más que un tour de force (como el aeroplano que voló sobre el
canal de la Mancha impulsado por la fuerza de una bicicleta, y que ya no volvió
a usarse más).

Resulta obvio que groquear, sea lo que fuere, está mejor adaptado a la
manipulación increíblemente rápida e infalible de cantidades aritméticas.
Incluso el ordenador más simple puede groquear la multiplicación y división de
cifras enormes mucho más deprisa de lo que los seres humanos pueden pensar la
solución

Esto no significa que groquear sea superior a pensar. Simplemente, significa
que groquear está mejor adaptado a ese proceso particular. En cuanto a pensar,
está bien adaptado al proceso que implica intuición, previsión y la combinación
creativa de datos para la producción de resultados inesperados.

Los ordenadores pueden tal vez estar diseñados para hacer cosas así hasta
cierto punto, al igual que los prodigios matemáticos pueden groquear en cierto
modo, pero tanto una cosa como la otra constituye una pérdida de tiempo.

Dejemos que los pensadores y los groqueadores desarrollen sus especialidades y
guarden sus resultados. Me imagino que los seres humanos y los ordenadores,
trabajando juntos, pueden hacer mucho más que cualquiera de ellos por separado.
Es la simbiosis de ambos lo que representa los perfiles del futuro.



Una cosa más. Si el groquear y el pensar son cosas muy diferentes, ¿se puede
esperar que el estudio de los ordenadores llegue a esclarecer el problema del
pensamiento humano?

Volvamos al problema de la locomoción.

Una máquina de vapor puede propulsar las máquinas para que realicen el trabajo
que ordinariamente llevan a cabo los músculos, y lo hacen con mayor intensidad
y sin esfuerzo, pero esa máquina de vapor tiene una estructura que no se parece
en nada al músculo. En la máquina de vapor, el agua se calienta hasta el punto
de ebullición y la fuerza del vapor mueve los pistones. En el músculo, una
delicada proteína llamada actomiosina experimenta cambios moleculares que hacen
que el músculo se contraiga.

Parece pues que uno puede estudiar agua hirviendo y el vapor que sale durante
un millón de años y, sin embargo, no ser capaz de deducir de ello la menor cosa
acerca de la actomiosina. O, a la inversa, uno podría estudiar todos los
cambios moleculares que sufre la actomiosina y, sin embargo, no aprender lo más
mínimo acerca de qué es lo que hace hervir el agua.

No obstante, en 1824, un joven físico francés, Nicolás L. S. Carnot
(1796-1832), estudió la máquina de vapor a fin de determinar qué factores
regulaban la eficacia con que funciona. Al hacerlo, fue el primero en iniciar
una serie de pruebas que, a fines de siglo, le habían hecho desarrollar por
completo las leyes de la termodinámica.

Esas leyes se encuentran entre las más importantes generalizaciones en física.
y se descubrió que eran aplicables con pleno rigor tanto a los sistemas vivos
como a cosas más simples como las máquinas de vapor.

La acción muscular, pese a lo complicado de sus más íntimas funciones, debe
actuar impulsada por las leyes de la termodinámica, igual que deben hacerlo las
máquinas de vapor, y esto nos dice algo acerca de los músculos que resulta de
la mayor importancia. Y lo que es más, lo hemos aprendido a partir de las
máquinas de vapor y nunca lo hubiéramos sabido a través, únicamente, del
estudio de los músculos.

De manera similar, el estudio de los ordenadores tal vez nunca llegue a
decirnos, directamente, nada acerca de la estructura íntima del cerebro humano,
o de las células del cerebro humano. Sin embargo, el estudio del groqueo nos
puede llevar a la determinación de las leyes básicas del zorqueo, y puede que
averigüemos que esas leyes del zorqueo son aplicables tanto al pensar como al
groquear.

Así pues, es posible que, aunque los ordenadores no se parezcan en nada al
cerebro, nos enseñen cosas acerca de los cerebros que nunca descubriríamos
estudiando sólo éstos. Por ello, en último análisis, estoy del lado de Minsky.





XII. VOLVIENDO AL PUNTO DE PARTIDA





Durante el otoño de 1983, me fascinaron las cada vez más populares operaciones
de bypass, y por una buena razón. Mi angina de pecho, que había sido de poca
importancia y estable durante seis años, de repente se había desencadenado. Me
hicieron unas pruebas y, cuando me expusieron cuidadosamente los resultados de
dichas pruebas, me percaté de que tenía la más interesante de las alternativas:
ninguna.

Iba a necesitar un triple bypass.

Por lo tanto, hablé con mis diversos médicos y parecía haber una pregunta que
no me oían plantear. Por lo menos, siempre se lanzaban a darme otras respuestas.

Finalmente, acorralé a mi anestesista.

Le dije:

—Hay una cosa que no comprendo. Si van a insertar una arteria o vena en mi
aorta y en mis arterias coronarias, para que la sangre circule alrededor del
punto de estrangulamiento, ¿cómo lo harán? A menos que recurran a la cuarta
dimensión, deberán cortar en la aorta, por ejemplo, y hacer un agujero redondo
en el que puedan acoplar el nuevo vaso.

—Pues sí.

—Y al primer corte —proseguí —la sangre brotará con una fuerza enorme, y me
moriré.

—Oh, no —replicó. —¿No se lo ha explicado nadie? Una vez tengamos su corazón al
descubierto, lo pararemos.

Sentí que me ponía ligeramente verde.

—¿Que lo pararán?

—Sí, le daremos una fuerte dosis de ion potasio y lo enfriaremos, y dejará de
latir.

—Pero eso me dejará a cinco minutos de la muerte cerebral.

—No, no es así. Será usted conectado a una máquina corazón-pulmón que le
mantendrá vivo durante horas, si es necesario.

—Pero ¿ y si se avería?

—No puede averiarse. Y aunque se produzca un corte de corriente en todo el
Nordeste, nosotros continuaremos con nuestros generadores de emergencia.

Me sentí un poco mejor, y pregunté:

—¿Y cuándo pondrán de nuevo en marcha mi corazón? ¿Y si no funciona?

—Eso no puede suceder —respondió con seguridad. —El corazón no desea otra cosa
que funcionar. Tenemos que trabajar mucho para mantenerlo inmóvil. En cuanto
dejamos que salga el potasio, comienza a funcionar de nuevo, especialmente si
está en tan buena forma como el suyo.

Tenía razón, la operación de triple bypass se realizó el 14 de diciembre de
1983, y el 2 de enero de 1984 celebraré mi 1.000.000º cumpleaños (en la escala
binaria), y el 8 de enero de 1984 empiezo otro ensayo. ¿Y de qué iba a hablar
sino del corazón y de los vasos sanguíneos?



Aristóteles (384-322 a. de C.) creía que el corazón era la sede de la
inteligencia. Esto no resultaba tan irrazonable como hoy parece. A fin de
cuentas, es un órgano que constantemente se halla en movimiento y que se
acelera cuando se está excitado, se hace más lento en los períodos de calma, es
tumultuoso cuando se trata de afectos, etcétera. Cualquiera que observe esto, y
luego se percate de que el cerebro, simplemente, se limita a estar allí, sin
hacer nada, es probable que deje de lado el cerebro y lo considere, todo lo
más, un órgano auxiliar.

Aristóteles creía que era simplemente un agente enfriante para el corazón, el
cual, de otro modo, se sobrecalentaría. El enfriamiento se llevaba a cabo
mediante un fluido parecido a la saliva, al que los griegos llamaban pituita
(que ha dado origen también a la palabra esputar). Existe un pequeño órgano en
la base del cerebro al que denominamos glándula pituitaria, que es en extremo
importante (tal vez esto dé origen, en su día, a otro ensayo), pero no tiene
nada que ver con esputar.

Aristóteles no distinguía entre venas, arterias, nervios y tendones.

No obstante, poco después de la muerte de Aristóteles se produjo un breve
período de inteligentes disecciones en Alejandría, Egipto, y las cosas
comenzaron a ponerse un poco en orden.

Por ejemplo, las arterias estaban claramente conectadas al corazón. Pero, en
los cadáveres las arterias grandes parecían vacías. (Las últimas pulsaciones
las habían vaciado de sangre.) Praxágoras (340-? a. de C.) hizo la lógica
sugerencia, por lo tanto, de que transportaban aire. En realidad, la palabra
«arteria» procede de una voz griega que significa conducto de aire.

Herófilo (320-? a. de C.), un estudiante de Praxágoras, observó que las
arterias latían y que las venas no lo hacían. Al parecer, creyó que las
arterias llevaban sangre, pero conservó el nombre que les había dado su maestro.

El discípulo de Herófilo, Erasistrato (304-250 a. de C.), creyó que venas,
arterias y nervios eran tubos huecos que transportaban algún fluido u otro a
las diversas partes del cuerpo; que se dividían y subdividían hasta hacerse
demasiado pequeños para poder verse. En todo esto se hallaba notablemente
cerca, puesto que incluso los nervios transportan un impulso eléctrico, que
puede considerarse como una sutil clase de fluido.

Todos estaban de acuerdo en que las venas transportaban sangre. («Vena» procede
de la idéntica palabra latina. La voz griega es phleb, y por ello a la
inflamación de las venas se le denomina flebitis.)

Algunos creían que las arterias contenían una mezcla de sangre y aire, o de
sangre y algún «espíritu vital», y si pensamos que las arterias transportaban
sangre oxigenada, como así es en efecto, descubrimos que los antiguos griegos
no hacían conjeturas descabelladas.

Sin embargo, seguían existiendo cosas confusas, y pasaron siglos antes de que
los médicos comprendieran con claridad que los nervios y tendones no tenían
nada que ver con el corazón y no eran vasos sanguíneos de ningún tipo. Tampoco
veían con claridad la diferencia entre venas y arterias.

Galeno, el más famoso de los médicos antiguos, un griego de la época romana
(130-200), creía que las arterias tenían su origen en el corazón y llegaban
hasta los diversos tejidos. Pensaba que las venas se originaban en el hígado,
iban de allí al corazón desde donde, de nuevo, se dirigían a los diferentes
tejidos. (En realidad, una suposición razonable. El hígado es un órgano grande
que está lleno de vasos sanguíneos y mientras las arteria laten cuando el
corazón lo hace, las venas siguen inmóviles al igual que el hígado.)

Galeno creía que la sangre fluía desde el corazón a través de las arterias y
venas por igual, y que era consumida por los tejidos. Continuamente se
fabricaba sangre nueva, pensaba él, en el hígado (suponía que a partir de los
alimentos), tan deprisa como era consumida por los tejidos. La sangre se
consumía en los tejidos igual que lo haría la madera en una chimenea. El aire
que respiramos alimentaba el proceso, y el aire que exhalamos era análogo al
humo de una hoguera.

Sin embargo, aquí había una trampa. El corazón no es simplemente una bomba. En
realidad son dos bombas, dado que está dividido en dos cámaras principales: el
ventrículo izquierdo y el ventrículo derecho. («Ventrículo» procede de la voz
latina para designar «pequeña bolsa».)

Cada ventrículo de paredes gruesas tiene una antecámara de paredes más
delgadas, llamada «aurícula izquierda» y «aurícula derecha», respectivamente,
por lo que, en conjunto, el corazón posee cuatro cámaras.

Existe un paso claro entre cada aurícula y cada ventrículo, pero no hay ninguno
entre las dos series de aurículas-ventrículos. El ventrículo izquierdo (muy
musculoso) conduce a la mayor arteria del cuerpo, la aorta (nombre de origen
incierto), mientras que el ventrículo derecho (menos musculoso) conduce a la
arteria pulmonar. Cada ventrículo posee asimismo sus propias venas.

Podría parecer que cada ventrículo envía sangre y que no existe una conexión
obvia entre las dos corrientes sanguíneas. Sin embargo, Galeno no pudo ver por
qué debería haber dos corrientes sanguíneas, y decidió que aquello carecía de
sentido. Debía haber una conexión, y si no era obvia, tendría que estar oculta.

La pared entre ambos ventrículos es gruesa y musculosa y, según todas las
apariencias, está por completo intacta. Sin embargo, razonó Galeno, debían
existir pequeños agujeros, agujeros demasiado diminutos para verlos, a través
de los cuales la sangre era enviada y recibida de uno a otro ventrículo,
permitiendo así que existiera una sola corriente sanguínea.

Durante unos catorce siglos, los médicos creyeron fielmente en los poros
interventriculares, aunque nadie los había visto, y aunque, en realidad, no
existen. Pero no se rían demasiado. Aquello tenía sentido en el sistema de
Galeno, y aunque se demostró que era erróneo, el sistema correcto, cuando se
descubrió, también dependía de unos pasos invisibles.

Sin embargo, no hubo la menor posibilidad de efectuar progresos, en el asunto
del corazón y los vasos sanguíneos, hasta que la anatomía humana se estableció
como una firme disciplina médica. Esto resultó difícil puesto que muchas
personas consideraban la disección de los cadáveres (no estoy hablando de la
vivisección de cuerpos vivos) algo blasfemo. Los egipcios, judíos y,
finalmente, los cristianos, se horrorizaban ante tal práctica, y la anatomía
desapareció a partir del año 200 a. de C. y quedó restringida a los animales
durante un millar de años.

Las primeras grandes escuelas modernas de medicina en Europa se fundaron en la
Italia renacentista, y fueron las que dirigieron el mundo occidental durante
tres siglos. En la Universidad de Bolonia, Mondino de Luzzi (1275-1326) fue el
primero en llevar a cabo disecciones sistemáticas. En 1316 publicó el primer
libro de la historia dedicado enteramente a la anatomía. Por desgracia, tenía
ayudantes para realizar las disecciones, mientras él daba las conferencias (sin
mirar) siguiendo los principios galénicos. Por lo tanto, cometió egregios
errores, pero durante dos siglos y medio su libro fue el mejor de que se
disponía.

(Diré de paso, que el aumento del interés por el arte naturalista en la Italia
del Renacimiento convirtió la anatomía en una necesidad artística, lo mismo que
le ocurriera a la geometría proyectiva. De este modo, el arte contribuyó a la
medicina y a las matemáticas, mientras cada una de éstas, a su vez, también
contribuyó al arte. En la historia existen en todas partes conexiones entre lo
intelectual y la tecnología. Leonardo da Vinci (1452-1519) diseccionó treinta
cadáveres en el transcurso de su vida.)

Finalmente, apareció d primer gran anatomista moderno, un flamenco llamado
Andreas Vesalio (1514-1564). Estudió en las facultades médicas italianas y
quedó fascinado por la anatomía. Consiguió causar sensación, por ejemplo, al
mostrar que el hombre y las mujeres poseen igual número de costillas,
veinticuatro cada uno, distribuidas en doce pares.

A fin de cuentas, la Biblia explicaba que Eva fue creada de una costilla sacada
de Adán, de lo que se dedujo que tenía que faltar una, no sólo a Adán, sino a
todos los hombres. Todo el mundo «sabía» eso sin tener que mirarlo, hasta que
Vesalio lo miró, y lo que fue peor, las contó.

Como resultado de sus investigaciones, Vesalio escribió uno de los mayores
clásicos en la historia científica, la obra Acerca de la estructura del cuerpo
humano. Se publicó en 1543, cuando él tenía veintinueve años, y fue el mismo
año en que Copérnico publicó el libro en el que explicaba que la Tierra giraba
en tomo del Sol, y no al revés. Constituyó un doble éxito para la ciencia
griega.

El libro de Vesalio fue el primero relativamente exacto acerca de anatomía, y
se imprimió. Esto significó que pudo tener ilustraciones que se podían
reproducir con exactitud un gran número de veces, y Vesalio consiguió un
artista de primera clase para que las hiciese, un tal Jan Stephen van Calcar
(1499-1550), discípulo de Ticiano (1477-1576). Las ilustraciones eran
naturalistas, y las de los músculos en particular nunca se habían hecho mejor.

Otros anatomistas, más ancianos y conservadores, combatieron con fuerza el
libro, simplemente porque no podían apartarse de Galeno. Veinte años después,
consiguieron que Vesalio fuese acusado de herejía, de destrozar cadáveres y de
efectuar disecciones. Se vio obligado a realizar una peregrinación a Tierra
Santa como penitencia, y murió en el transcurso de una tormenta.

No obstante ni siquiera Vesalio abandonó a Galeno. Estaba a favor de Galeno y
en contra de Aristóteles, en lo de preferir el cerebro al corazón como sede de
la inteligencia; y desde entonces nadie ha tenido la menor duda al respecto.

Además, en sus investigaciones anatómicas, Vesalio no encontró el modo de
explicar la naturaleza de bomba doble del corazón, excepto de la misma forma en
que lo hiciera Galeno. Por lo tanto, aceptó los poros invisibles en la pared
interventricular del corazón, aunque se supone que al final de su vida empezó a
tener dudas al respecto.

A pesar de los problemas de Vesalio con los poderes establecidos de su tiempo,
revolucionó la anatomía. Después de él, los anatomistas diseccionaron con
cuidado y estudiaron con detalle todo cuanto veían.

Uno de ellos fue Girolamo Fabrici (1537-1619), conocido usualmente como
Fabricius ab Aquapendente. En 1574, estudió las venas de las piernas y observó
que tenían pequeñas válvulas en toda su longitud. Otros anatomistas de su época
informaron acerca de ellas. y se produjeron fuertes discusiones acerca de la
prioridad.

Sin embargo, Fabrici llevó a cabo el estudio más cuidadoso y total, y permitió
a uno de sus estudiantes publicar ilustraciones de esas válvulas en 1585, y por
ello generalmente se ha atribuido a Fabrici ese descubrimiento.

No obstante, Fabrici no interpretó correctamente su función. Seguía esclavo de
la noción galénica de los poros interventriculares que permitían que una sola
corriente sanguínea se moviera centrífugamente desde el corazón hasta los
tejidos, donde se consumía.

Quedaba claro que las válvulas impedían que la sangre fluyese hacia abajo en
las venas. La acción muscular, al andar y al realizar otros movimientos,
oprimía las venas de las piernas y otras venas de la parte baja del cuerpo, y
obligaba a la sangre a ir hacia arriba porque era la única dirección en la que
podía circular. Si trataba de ir hacia abajo, en la dirección de la atracción
gravitacional, las válvulas se lo impedían.

Esto significaba que la sangre de las venas y, posiblemente, en todas las
venas, podía moverse sólo en dirección al corazón.

Pero Fabrici no podía aceptarlo, a pesar del hecho de que (ahora lo sabemos)
sencillamente era así. Dio por supuesto que las válvulas tan sólo retardaban e
igualaban el flujo sanguíneo que iba hacia abajo, para que todas las partes del
cuerpo recibiesen su ración. Con esto, Fabrici salvaba la teoría galénica de la
acción del corazón, pero perdió la inmortalidad.



¿Nadie puso en tela de juicio los poros galénicos?

Algunos lo hicieron, ciertamente, pero el primero no fue un europeo, sino un
estudioso árabe, Ibn al-Nafis (1210-1288), nacido cerca de Damasco.

En 1242 escribió un libro que trataba de cirugía, y en el mismo negaba
específicamente la existencia de los poros de Galeno. Afirmó que la pared
interventricular era gruesa y sólida, y que no había modo de que la sangre la
atravesase.

Y, sin embargo, la sangre tenía que ir de un lado de la pared al otro de alguna
forma. Una bomba doble no tenía sentido.

Al-Nafis sugirió que la sangre del ventrículo derecho era bombeada en la
arteria pulmonar que la llevaba a los pulmones. Allí, en los pulmones, se
dividía en vasos cada vez más pequeños. dentro de los cuales la sangre tomaba
aire de los pulmones. Esos vasos eran luego reunidos en otros cada vez más
grandes, hasta que se vaciaban en las venas pulmonares que llevaba la sangre,
junto con su mezcla de aire, a la aurícula derecha, y de ahí hasta el
ventrículo izquierdo y a la aorta.

De este modo, al-Nafis descubrió la «circulación menor» de la sangre, y la
descripción era muy interesante. La sangre (creada tal vez en el hígado, como
Galeno creía) se vertía en la aurícula derecha y en el ventrículo derecho,
luego viajaba hasta la aurícula izquierda y el ventrículo izquierdo a través de
los pulmones. A continuación, aireada, iba hasta los tejidos en general.

De este modo, se eliminaban los poros galénicos y se explicaba la razón de la
bomba doble. Era una manera de asegurar que la sangre cogía aire antes de
dirigirse a todos los tejidos.

Pero había dos trampas en las teorías de al-Nafis. En primer lugar, no existían
signos de vasos sanguíneos continuos en los pulmones. La arteria pulmonar se
dividía y subdividía hasta desaparecer, mientras las venas pulmonares se
formaban, aparentemente, de la nada. Era justo suponer que la subdivisión final
se hacía demasiado pequeña para verla, y que las arterias y venas más pequeñas
se conectaban de esta manera. Sin embargo, en este caso, unos vasos invisibles
sustituían a unos poros invisibles. ¿Constituía esto realmente un progreso?

La segunda trampa es que el libro de al-Nafis no se conoció en Occidente hasta
1924 (!) y, por lo tanto, no tuvo la menor influencia en el desarrollo de la
moderna teoría médica.

Europa tardó más de trescientos años en captar la inspiración de al-Nafis, y el
que lo hizo fue un médico español llamado Miguel Servet (1511-1553).

Era la época de la reforma protestante, y toda Europa se hallaba convulsionada
con las discusiones teológicas. Servet desarrolló unas ideas radicales que
incluso hoy se describirían como unitarias. Las expuso sin el menor cuidado,
con lo que enfureció tanto a los católicos como a los protestantes, dado que
ambos estaban comprometidos con la divinidad de Jesús. En 1536, Servet conoció
a Juan Calvino en París. Juan Calvino era uno de los más destacados de los
primeros protestantes, un firme y terco doctrinario. Cuando Servet envió a
Calvino un ejemplar que contenía sus puntos de vista, Calvino quedó horrorizado
e interrumpió la correspondencia, pero no se olvidó del asunto.

En 1553, Servet publicó anónimamente sus ideas teológicas, pero Calvino conocía
aquellos puntos de vista y reconoció al autor. Lo comunicó a las autoridades
francesas, que arrestaron a Servet. Este consiguió escaparse tres días después
y se dirigió a Italia.

Sin darse cuenta, pasó cerca de Ginebra, que entonces se hallaba bajo el
estricto control del sombrío y amargado Calvino, quien había fundado una de las
más notables teocracias de la Europa moderna. Servet no era súbdito ni
residente de Ginebra. y no había cometido ningún delito en esa ciudad, por el
que pudiese ser retenido legalmente. No obstante, Calvino insistió en que se le
condenara a muerte, por lo que Servet proclamando hasta el fin su doctrina
unitaria fue quemado en la hoguera.

Calvino no quedó satisfecho quemando el cuerpo de Servet. Le pareció necesario
quemar también su mente. Persiguió todos los ejemplares que pudo del libro de
Servet y los quemó también. No fue hasta 1694, un siglo y medio después de la
muerte de Servet, cuando se descubrieron algunos ejemplares que permanecieron
sin quemar, y los eruditos europeos tuvieron la posibilidad de leer sus puntos
de vista unitarios.

Eso hicieron y, tal vez ante su asombro, descubrieron que también había
descrito en el libro la circulación menor (exactamente como había hecho
al-Nafis, si Europa lo hubiera conocido.)

Servet perdió el crédito del descubrimiento, excepto retrospectivamente, pues
en 1559 un anatomista italiano, Realdo Colombo (1516-1559), había publicado un
libro que describía la circulación menor exactamente como habían hecho al-Nafis
y Servet, y esta obra sobrevivió. Por lo general, se atribuye a Colombo el
mérito del descubrimiento, pero su trabajo fue más detallado y cuidadoso que el
de los otros dos y, dadas las circunstancias, fue la obra de Colombo la que
influyó en los avances posteriores, por lo que tiene bien merecida su fama.

Luego apareció el médico inglés William Harvey (1578-1657).

Era hijo de un comerciante acomodado, y el mayor de nueve hijos. Recibió su
graduación en Cambridge en 1597, y luego se fue a Italia a estudiar medicina.
Fabrici fue uno de sus maestros.

Harvey regresó a Inglaterra y tuvo un gran éxito profesional, pues fue médico
de la Corte tanto del rey Jacobo I como de Carlos I.

Harvey era un experimentador. Para él, el corazón era un músculo que sin cesar
se contraía y expulsaba sangre, y debía investigarse sobre esta base y no otra.

Mediante la disección, estudió las válvulas entre las dos aurículas y los dos
ventrículos de forma cuidadosa, y observó que eran de una sola dirección. La
sangre podía viajar desde la aurícula izquierda al ventrículo izquierdo y desde
la aurícula derecha al ventrículo derecho, pero no a la inversa.

Y lo que es más, naturalmente Harvey conocía las válvulas venosas, según le
había enseñado el viejo maestro Fabrici. Con el concepto de las válvulas de una
dirección muy claro en su mente, evitó el error de Fabrici. En las venas, la
sangre iba sólo en una dirección hacia el corazón. Incluso experimentó ligando
venas en el transcurso de sus experimentos con animales. De una forma
inevitable, la sangre llenaba y abultaba la vena en el lado alejado del
corazón, mientras trataba de fluir hacia éste y no podía hacerlo. La situación
era precisamente inversa cuando ligaba una arteria, que al instante se llenaba
de sangre y abultaba en el lado hacia el corazón.

En 1615, para Harvey el asunto estaba claro. Finalmente conocía las diferencias
fisiológicas entre arterias y venas. La sangre salía del corazón a través de
las arterias, y luego regresaba al mismo gracias a las venas. La circulación
menor de la que había hablado Colombo era sólo la menor. Desde el ventrículo
izquierdo, la sangre era bombeada a la aorta y luego se dirigía a los tejidos
corporales en general, regresando por las venas a la aurícula derecha y al
ventrículo derecho, desde donde era bombeada a los pulmones para volver a la
aurícula y ventrículo derechos.

En otras palabras; la sangre está, constantemente, volviendo al punto de
partida. «Circula».

Harvey hizo algunos cálculos sencillos que podría haber hecho Galeno, si la
idea de la medición relacionada con la biología hubiera sido algo claro para
los griegos. Harvey mostró que, en una hora, el corazón bombeaba una cantidad
de sangre que era tres veces el peso de un hombre. Parecía inconcebible que la
sangre se formase y consumiese en esa proporción, por lo que la noción de la
circulación de la sangre pareció una necesidad tanto biológica como
experimental.

Harvey, que no era polemista, comenzó a dar conferencias acerca de la
circulación de la sangre en 1616, pero no vertió sus conocimientos en un libro
hasta 1628. Era un ejemplar de 72 páginas, miserablemente impreso en los Países
Bajos, con un papel delgado y barato, y lleno de erratas tipográficas. Sin
embargo, los experimentos en él descritos estaban claros, eran concisos y
elegantes, y las conclusiones resultaban incontrovertibles. El libro, llamado
Acerca de los movimientos del corazón y de la sangre, se convirtió en uno de
los grandes clásicos científicos.

Inevitablemente, el libro de Harvey al principio fue atacado, pero él vivió lo
suficiente para ver que la circulación de la sangre era aceptada de modo
general por la medicina europea. Fue su libro el que terminó de una vez para
siempre con la fisiología galénica.

Y, sin embargo, también aquí había una trampa. La sangre salía del corazón a
través de las arterias y volvía por las venas, pero no había conexiones
visibles entre ambas. Se tenía que dar por supuesto que existían unas
conexiones invisibles: unos tubitos demasiado pequeños para poder verse, como
los poros galénicos invisibles en el músculo interventricular.

Mientras dependamos de la invisibilidad, no podemos estar seguros.

Ah, pero, ahora había una diferencia. Durante la última década de la vida de
Harvey, los fisiólogos estaban comenzando a emplear microscopios, muy
imperfectos, pero que podían ampliar los objetos que, de ordinario, eran
demasiado pequeños para ser vistos, haciéndolos visibles con cierto detalle.

El primero en aparecer por un tiempo en este campo fue el fisiólogo italiano
Marcello Malpighi (1628-1694), que había aprendido medicina en la Universidad
de Bolonia y que con el tiempo, aunque a desgana, acabó convirtiéndose en el
médico privado del papa Inocencio XII.

Malpighi comenzó su trabajo con el microscopio en los años 1650, cuando
investigaba los pulmones de las ranas. Empezó por ver pequeños vasos sanguíneos
parecidos a cabellos, que no podía percibir sin el microscopio. Al observar las
membranas de las alas de los murciélagos al microscopio, en 1661, pudo ver
realmente pequeñas arterias y venas conectadas con estos vasos parecidos a
cabellos. Los llamó capilares, de las palabras latinas que significan «parecido
a cabello».

El descubrimiento, que completó e hizo perfecto el concepto de la circulación
de la sangre, se efectuó, por desgracia, cuatro años después de la muerte de
Harvey. Pero estoy seguro de que Harvey confiaba en que los capilares existían
y que llegarían a descubrirse.

Un último punto. Cuando el ventrículo izquierdo del corazón bombea su sangre en
la gran aorta, aparecen casi inmediatamente tres arterias pequeñas, que llevan
la sangre más recientemente oxigenada al —¿dónde si no? —mismo músculo
cardiaco. El corazón se sirve el primero y con la mayor abundancia. ¿Y por qué
no? Se lo merece.

Esos vasos son las «arterias coronarias» (porque rodean el corazón como una
corona). Incluso más que las arterias ordinarias, las coronarias tienen
tendencia a obstruirse con el colesterol, si uno come y vive de forma alocada.

La obstrucción, por lo general tiene lugar donde las arterias se separan de la
aorta, y las pruebas mostraron que mis coronarias (en orden de tamaño
decreciente) se hallaban obstruidas en un 85%, un 70% y un 100%.

Me hicieron un bypass en la coronaria más grande con una arteria cercana
(afortunadamente en perfecto estado). En las dos más pequeñas me lo hicieron
con una vena sacada de mi pierna izquierda.

Estoy asustado y no completamente curado, pero mi corazón está consiguiendo
toda la sangre que necesita; me estoy reponiendo con rapidez y, con mucho lo
más importante, aún puedo escribir estos capítulos.





Quinta Parte





TECNOLOGÍA





XIII. ¿QUÉ CAMIÓN?





No soy una persona visual. Y lo que es más, poseo una vida interior muy
intensa, por lo que siempre hay cosas dando saltos en el interior de mi cráneo,
y eso me distrae. Las demás personas se quedan atónitas ante las cosas que no
veo. La gente cambia de peinado y no me doy cuenta de ello. Entran muebles
nuevos en casa, y los utilizo sin hacer el menor comentario.

Sin embargo, en una ocasión, parece que batí el récord al respecto. Iba
caminando por Lexington Avenue, hablando animadamente (como suelo hacer) con
alguien que paseaba conmigo. Crucé la calzada, sin dejar de hablar, mientras mi
acompañante cruzaba también pero con lo que parecía cierta reluctancia.

Al llegar al otro lado, mi compañero confesó:

—Ese camión no nos ha arrollado por milímetros. —Y yo respondí, con la mayor
inocencia:

—¿Qué camión?

Así que recibí una regañina más bien floja, que no me reformó, pero que me hizo
pensar acerca de la facilidad con que uno puede dejar de ver los camiones.

Por ejemplo...



Hace algún tiempo, un lector me envió un ejemplar del número de octubre de 1903
del Munsey´s Magazine, y lo miré con considerable interés. La enorme sección de
anuncios parecía una ventana a otro mundo. Sin embargo, lo que había causado
una particular fascinación al lector, y sobre lo que quería llamar mi atención,
era un articulo titulado «¿Pueden los hombres visitar la Luna?», de Ernest
Creen Dodge, licenciado en Letras.

Era la clase de articulo que yo mismo podía haber escrito ochenta años atrás.

En realidad, he tenido a menudo la ocasión de preguntarme si mis propios
intentos por escribir acerca de la tecnología del futuro podrían parecer menos
que inspirados a la luz brillante de la visión retrospectiva. Con frecuencia,
he sentido, con bastante tristeza, que sería así, que resultaría que habría
camiones que no había visto, o camiones que había visto y que realmente no
estaban allí.

No puedo esperar vivir ochenta años más y comprobarlo yo mismo, pero ¿qué
pasaría si mirase las observaciones que pudiera haber hecho ochenta años atrás,
y comprobar qué tal sonarían a la luz de lo que ahora sabemos?

El artículo de Mr. Dodge es la forma perfecta de hacer esto, puesto que era un
hombre claramente racional, con un buen conocimiento de la ciencia y con una
fuerte pero disciplinada imaginación. En resumen, era como me gusta imaginar
que soy yo.

En ciertos aspectos da exactamente en el blanco.

Referente a un viaje a la Luna, dice «... no es, como el movimiento perpetuo o
la cuadratura del círculo, una imposibilidad lógica. Lo peor que puede decirse
es que ahora nos parece tan difícil como debió de parecerle en otro tiempo el
cruzar el gran Atlántico al desnudo salvaje de sus riberas, sin más navío que
un tronco derribado, y sin más remos que sus simples manos. La imposibilidad
del salvaje se convirtió en el triunfo de Colón, y el sueño imposible del siglo
XIX puede convertirse en el logro incluso del siglo XX».

¡Exactamente! Los seres humanos pisaron la Luna sólo sesenta y seis años
después de que apareciese el artículo de Dodge.

Dodge prosigue con la lista de dificultades del viaje espacial que, según
señala, surgen de forma primaria del hecho de que «el espacio está en realidad
vacío, en un sentido al que ningún vacío artificial se puede aproximar... una
porción del espacio exterior del tamaño de la tierra no contiene absolutamente
nada, por lo que sabemos, excepto unos cuantos granos flotantes de piedras
meteóricas, con un peso tal vez de diez o quince libras en total».

Dodge es un hombre cuidadoso. Aunque la afirmación parecía irrefutable en 1903,
inserta la cautelosa frase «por lo que sabemos» y estuvo muy acertado al
hacerlo.

En 1903, las partículas subatómicas comenzaban sólo a conocerse. Los electrones
y las radiaciones radiactivas se habían descubierto menos de una década antes.
Sin embargo, se trataba sólo de fenómenos terrestres, y los rayos cósmicos no
se descubrieron hasta 1911. Dodge por lo tanto, no podía saber que el espacio
estaba lleno de partículas energéticas cargadas eléctricamente de una masa
insignificante, pero de una importancia considerable.

Sobre la base de lo que conocía en 1903, Dodge da la lista de cuatro
dificultades que podrían surgir al viajar desde la Tierra a la Luna a través
del vacío del espacio exterior.

Naturalmente, la primera es que no existe nada para respirar. De una forma casi
correcta, dejó esto de lado señalando que la nave espacial sería hermética y
que transportaría su propia atmósfera interna, igual que llevaría provisiones
de alimentos y bebidas. Por lo tanto, respirar no es un problema.

La segunda dificultad es la del «terrible frío» del espacio exterior. Esto
Dodge se lo tomo mas en serio.

Sin embargo, es un problema que tiende a ser sobreestimado. Con seguridad,
cualquier trozo de materia que se encuentre en el espacio profundo y lejos de
cualquier fuente de radiación, alcanzaría una temperatura equilibrada de unos
tres grados absolutos, de modo que ésta puede considerarse «la temperatura del
espacio». Cualquier cosa que viaje desde la Tierra a la Luna, sin embargo, no
se encuentra alejada de una fuente de radiación. Se halla cerca del Sol, como
lo están la Tierra y la Luna, y bañada durante todo el trayecto por la
radiación solar.

Y lo que es más, el vacío del espacio es un excelente aislante del calor. Esto
era bien conocido en 1903, puesto que James Dewar había inventado el
equivalente del termo once años antes de que se escribiese el artículo. Es
seguro que existirá calor interior en la nave, aunque sólo sea por el calor
corporal de los mismos astronautas, y se perdería con mucha lentitud por la
radiación a través del vacío. (Es la única forma de perder calor en el espacio.)

Dodge cree que las naves tendrían que estar protegidas contra la pérdida de
calor con «unas paredes... muy bien acolchadas». También sugiere el suministro
de calor en forma de «grandes espejos parabólicos en el exterior [que]
arrojarían rayos de la luz solar concentrados a través de la ventana».

Esto es una estimación excesiva, puesto que nada parecido es necesario. El
aislamiento debe colocarse en el exterior de las naves, pero esto se hace con
el propósito de evitar la ganancia de demasiado calor durante el paso por la
atmósfera. La pérdida de calor no preocupa a nadie.

La tercera dificultad deriva del hecho de que la nave se hallaría en caída
libre durante la mayor parte, o la totalidad del viaje de la Tierra a la Luna,
por lo que los astronautas no experimentarán atracción gravitatoria. A esto
Dodge le quita importancia. señalando que «los platos podrían sujetarse a la
mesa. y las personas podrían saltar y flotar, aunque no pudieran andar».

No especula acerca de posibles cambios fisiológicos deletéreos, surgidos de la
exposición a una gravedad cero, y esto podría considerarse falta de visión. Una
vez más, este punto ha demostrado no ser un problema. En años recientes, ha
habido personas que han permanecido en condiciones de gravedad cero sin cesar
durante más de medio año y. aparentemente, no han mostrado efectos nocivos
permanentes.

El cuarto y último peligro que Dodge considera es la posibilidad de colisiones
meteóricas, pero (a pesar del hecho de que los escritores de ciencia-ficción
siguieron viéndolo como el mayor peligro durante otro medio siglo) Dodge
también rechazó esto, como estadísticamente insignificante. Y estuvo en lo
correcto al hacerlo.

No menciona el quinto peligro, el de los rayos cósmicos y otras partículas
cargadas eléctricamente, algo que, simplemente, no podía saber en 1903. Hubo
algunos recelos en este aspecto después del descubrimiento de los cinturones de
radiación en 1958, pero, como se demostró, no impidieron que la Humanidad
llegase a la Luna.



Así pues, Dodge decidió que no existían peligros en el espacio que impidiesen a
los seres humanos alcanzar la Luna, y estaba en lo cierto. En todo caso,
sobreestimó el peligro del supuesto frío espacial.

La siguiente cuestión era cómo recorrer realmente la distancia entre la Tierra
y la Luna. En este sentido, menciona cinco posibles «planes». (A uno le da la
impresión, aunque en realidad Dodge no lo diga, que esos cinco planes son los
únicos concebibles.)

El más simple es el «Plan de la Torre». Esto implicaría la construcción de un
objeto lo suficientemente alto para alcanzar la Luna, algo parecido al plan de
los constructores de la bíblica torre de Babel. Dodge menciona la torre Eiffel,
que se había construido catorce años antes, y que con una altura de 300 metros
era la estructura más elevada del mundo en la época en que se escribió el
artículo (y siguió siéndolo durante veintisiete años más).

Dice: «juntando la riqueza de todas las naciones se podría construir un
edificio de sólido acero de ocho o diez millas de altura, pero no mucho más,
por la simple razón de que las partes inferiores no podrían ser lo
suficientemente fuertes para soportar el peso que descansaría sobre ellas».
Para llegar a la Luna, se necesitaría «un material de construcción unas
quinientas veces más fuerte que el cemento armado, y eso tal vez no se
descubrirá nunca». (Nótese por ese «tal vez» que Dodge es un hombre cauteloso.)

Existen en el plan otras muchas deficiencias que Dodge no menciona. La Luna, al
tener una órbita elíptica en un ángulo respecto del plano ecuatorial de la
Tierra se aproximaría a la cumbre de la torre sólo en una ocasión de vez en
cuando, y cuando lo hiciera, la gravedad lunar produciría una gran tensión
sobre ella. El aire permanecería sólo en la parte baja de la torre, gracias a
la atracción de la gravedad terrestre, y existiría aún el problema de atravesar
los más o menos 300.000 kilómetros de distancia del perigeo de la Luna, después
de que se construyese la torre (dejando aparte el atravesarlo al construir la
misma). Hay que tachar el «Plan de la Torre».

Dodge no menciona la posibilidad de un «rascacielos de gancho», una larga
estructura vertical en una posición tal entre la Tierra y la Luna, que la
atracción gravitatoria de ambas la mantuviese en su sitio, y que se podría
utilizar para facilitar la travesía de la Tierra a la Luna. Personalmente, no
creo que esto fuese tampoco en absoluto práctico.



El segundo plan de Dodge es el «Plan del Proyectil». Esto implica el disparar
una nave con un cañón gigantesco y hacerlo salir con la velocidad suficiente
para alcanzar la Luna (una vez correctamente apuntado). Es el método empleado
por Julio Verne en su obra De la Tierra a la Luna, que se publicó treinta y
ocho años antes, 1865.

Dodge señala que, para llegar a la Luna, el proyectil debe salir por la boca
del Cañón a la velocidad de 11,2 kilómetros por segundo (la velocidad de escape
de la Tierra), más un poco más para compensar las pérdidas producidas por la
resistencia del aire al pasar a través de la atmósfera. La nave espacial
tendría que acelerar, pasando del estado de reposo a 11,2 kilómetros por
segundo, en la longitud del ánima del cañón, y esto aplastaría por completo a
los pasajeros que estuviesen a bordo, sin dejarles ni un solo hueso entero.

Cuanto más largo fuese el cañón, más baja sería la aceleración, pero, dice
Dodge, «aunque el anima del cañón tuviese la imposible longitud de 60
kilómetros, los pobres pasajeros se verían sujetos durante once segundos a un
presión equivalente a cien hombres tumbados encima».

Pero supongamos que pudiéramos superar esta dificultad, e imaginemos que la
nave espacial sale por la boca del cañón con los pasajeros aún vivos. La nave
sería un proyectil, moviéndose en respuesta a la fuerza de la gravedad y nada
más. Sería incapaz de alterar su recorrido, como no puede hacerlo ninguna bala
de cañón.

Si la nave estuviese apuntada a la Luna, y finalmente, aterrizase en ella,
chocaría contra la misma a una velocidad de no menos de 2,37 kilómetros por
segundo (la velocidad de escape de la Luna). Y esto, como es natural,
significaría la muerte instantánea. O, como dice Dodge, «... a menos que
nuestra nave-obús pudiese llevar en su morro una pila de cojines de 3
kilómetros de altura con los que protegerse, el aterrizaje aún sería peor que
el despegue...».

Naturalmente, la nave no precisaría aterrizar en la Luna. Dodge no prosigue con
este plan, pero el cañón podría apuntarse con sobrehumana precisión para
esquivar la Luna, lo necesario y a la velocidad exacta para hacer que girase en
torno de ella obedeciendo a la gravedad lunar, y volviese de nuevo a la Tierra.

Si entonces la nave chocase de frente con la Tierra, lo haría a una velocidad
de no menos de 11,2 kilómetros por segundo, con lo que los pasajeros quedarían
abrasados por completo al pasar a través de la atmósfera de la Tierra, antes de
morir destrozados en la colisión con el sólido suelo o (muy poco mejor a
semejante velocidad), el océano. Y si la nave espacial alcanzase una ciudad,
mataría a muchos millares de inocentes también.

La puntería sobrehumana del principio podría traer la nave de regreso a la
Tierra justo lo suficientemente descentrada para atraparla en la gravedad de la
Tierra y ponerla en una trayectoria orbital dentro de las capas superiores de
la atmósfera terrestre. La órbita decaería gradualmente. Además, podría
disponerse algún paracaídas que se abriese y acelerase ese decaimiento e
hiciese descender sana y salva la nave.

Pero esperar todo eso de la puntería es esperar demasiado, aunque la
aceleración inicial no resultase mortífera. Hay que tachar el Plan del
Proyectil.



El tercer plan es el «Plan del Retroceso».

Dodge señala que un cañón puede disparar en un vacío y, al hacerlo,
experimentar un retroceso. Podemos imaginarnos una nave espacial que fuese una
especie de poderoso cañón que lanzase un proyectil hacia abajo, de modo que el
retroceso se produjese hacia arriba. Al retroceder, podría lanzar a otro
proyectil hacia abajo y se daría así un nuevo impulso hacia arriba.

Si la nave disparase proyectiles con la suficiente rapidez, retrocedería hacia
arriba cada vez más aprisa y, de hecho, iría retrocediendo hasta llegar a la
Luna.

Sin embargo, Dodge aduce que el retroceso es cada vez más grande a medida que
la masa del obús aumenta, y que «para ser efectivo, su peso [realmente, masa]
debería ser igual o superior al del mismo cañón».

Así pues, debemos imaginar un objeto que disparase la mitad de sí mismo,
dejando a la otra mitad desplazarse hacia arriba y disparar la mitad de lo que
le quedase a medida que ascendiese, moviéndose así hacia arriba más deprisa y
luego disparar la mitad de lo que ahora restase de si mismo, y así
sucesivamente, hasta que llegara a la Luna.

Pero ¿cómo habría de ser de grande una nave espacial, al principio, si tiene
que disparar la mitad de si misma, luego la mitad de lo que queda, luego la
mitad de lo que queda, y así sucesivamente? Dodge dice: «Sería necesario un
artefacto original del tamaño de una cadena de montañas para hacer aterrizar
simplemente una pequeña caja en la superficie lunar sin que sufriera daños.»
Por lo tanto, opina que el Plan del Retroceso es, aun menos práctico que el
Plan del Proyectil.



Llegamos al cuarto plan: «El Plan de la Levitación».

Este implica nada menos que protegerse, de alguna manera, de la fuerza de la
gravedad. Dodge admite que no se conoce ninguna pantalla contra la gravedad,
pero supone que tal vez sería posible descubrirla en alguna época futura.

En cierto modo, un globo lleno de hidrógeno parece anular la gravedad.
Realmente parece «caer» hacia arriba a través de la atmósfera y presentar
levitación (de una palabra latina que significa «ligero»), en vez de
gravitación (de una voz latina que significa «pesado»).

En su relato La aventura sin paralelo de un tal Hans Pfaall, publicado sesenta
y ocho años antes, en 1835, Edgar Allan Poe emplea un globo para viajar a la
Luna. Sin embargo, un globo simplemente flota en las capas más densas de la
atmósfera, y no neutraliza realmente la gravedad. Cuando se eleva hasta una
altura en que la atmósfera no es más densa que el gas contenido en el globo, ya
no asciende más. Poe imaginó un gas mucho menos denso que el hidrógeno (algo
que ahora sabemos que no existe, y que no puede existir), pero ni siquiera eso
habría elevado un globo más que una fracción del 1% de la distancia entre la
Tierra y la Luna. Dodge lo sabía y por eso no menciona los globos.

Lo que Dodge quería decir era una verdadera neutralización de la gravedad, tal
y como H. G. Wells empleó en su obra Los primeros hombres en la Luna, publicado
dos años antes, en 1901.

Naturalmente, si se neutralizara la gravedad se tendría un peso cero, pero ¿eso
por sí solo nos llevaría a la Luna? ¿No estaría una nave espacial con un peso
cero meramente sujeta a los caprichos del viento? ¿No iría simplemente a la
deriva de esta manera, y en una especie de movimiento browniano, y aun cuando
finalmente (un finalmente muy alejado, tal vez), llegara a la parte superior de
la atmósfera y siguiera más allá, no podría entonces estar apartándose de la
Tierra en una dirección al azar que sólo llegaría a las cercanías de la Luna
como resultado de una muy poco probable coincidencia?

No obstante, Dodge tenía una noción mejor de todo ello. Imagínense que están
ustedes en una nave espacial en reposo en el ecuador de la Tierra. La Tierra
gira sobre su eje, de modo que cada punto en el ecuador, incluyendo la nave
espacial, se mueve sobre el eje a una velocidad de unos 0,46 kilómetros por
segundo. Ésta es una velocidad supersónica (unos 1,5 Mach), y si intentasen
ustedes agarrarse a un objeto corriente que estuviese girando a su alrededor a
semejante velocidad, no podrían sujetarse durante la más pequeña fracción de
segundo.

Sin embargo, la Tierra es muy grande, y el cambio de dirección de la línea
recta en el tiempo de un segundo es tan pequeño, que la aceleración interior es
bastante moderada. La fuerza de la gravedad en la nave es lo suficientemente
fuerte para retenerla en la superficie de la Tierra, a pesar de la velocidad
con que la hace girar. (Tendría que dar vueltas alrededor de la Tierra a
diecisiete veces esta velocidad antes de que la gravedad cesase de ser lo
suficientemente fuerte para retenerla.)

Pero supongamos que la nave espacial posee una pantalla antigravedad que
protege todo su casco, y en un momento determinado se activa. Ahora, sin
gravedad que tire de ella es soltada de la Tierra como un terrón de fango de un
volante que gira. Se movería en una línea recta tangente a la curva de la
Tierra. La superficie de la tierra descendería bajo ella, con lentitud al
principio, pero cada vez más aprisa, y si se tuviese cuidado de activar la
pantalla justo en el momento oportuno, el vuelo de la nave cortaría finalmente
la superficie de la Luna.

Dodge no menciona que el movimiento curvo de la Tierra alrededor del sol
introduciría un segundo factor, y que el movimiento del Sol entre las estrellas
añadiría un tercer componente. Eso representaría, no obstante, unos ajustes
comparativamente menores.

El aterrizaje en la Luna sería mejor que en los planes anteriores, ya que una
nave espacial no afectada por la gravedad de la Luna no tendría que aproximarse
a la misma a la velocidad de escape. Una vez la nave estuviese casi tocando la
Luna, la pantalla antigravedad se desconectaría y la nave, sujeta de repente a
la relativamente débil gravedad de la Luna, caería desde unos pocos
centímetros, con una leve sacudida.

Pero ¿qué pasaría con el regreso? La Luna gira sobre su eje muy lentamente, y
un punto en su ecuador viaja a una velocidad de 1/100 de un punto en el ecuador
terrestre. El empleo de la pantalla antigravedad en la Luna daría a la nave
espacial sólo 1/100 de la velocidad que tenía al abandonar la Tierra, por lo
que el viaje desde la Luna a la Tierra sería 100 veces más largo que desde la
Tierra a la Luna.

No obstante, podemos descartar todo esto. Albert Einstein promulgó su teoría
general de la relatividad trece años después de que se escribiese el artículo
de Dodge, por lo que no se puede culpar a éste de no saber que esa pantalla
antigravedad es algo simplemente imposible. Hay que tachar el Plan de la
Levitación.



Dodge tiene más esperanzas en su quinto plan, «El plan de la Repulsión». Aquí
no confía sólo en algo que le permita neutralizar la gravedad, sino en alguna
clase de fuerza repulsiva que, de un modo activo, desequilibre la atracción
gravitatoria.

A fin de cuentas, existen dos clases de carga eléctrica y dos clases de polo
magnético, y, en cualquier caso, tanto las cargas como los polos se repelen
mutuamente. ¿No podría haber una repulsión gravitatoria igual que hay una
atracción gravitatoria, y no sería posible que las naves espaciales empleasen
algún día una combinación de ambas, unas veces alejándose de un cuerpo
astronómico y otras siendo atraídas hacia él, y no podría esto ayudarnos a
llegar a la Luna?

Dodge, realmente, no dice que pueda existir algo como la repulsión
gravitatoria, y su prudencia es buena, puesto que, según el posterior punto de
vista einsteiniano, la repulsión gravitatoria es imposible.

Sin embargo, Dodge menciona la presión de la luz, señalando que, en algunos
casos, puede contrarrestar la fuerza de la gravedad. Emplea como ejemplo las
colas de los cometas. Cabría esperar que la gravedad atrae las colas hacia el
Sol, pero la presión de la luz solar las empuja en dirección opuesta, venciendo
así la gravitación.

En realidad, aquí se equivoca, puesto que resulta que la presión de la luz
solar es demasiado débil para realizar eso. Es el viento solar el que lo
efectúa.

La presión de la luz podría emplearse como una fuerza motivadora, seguramente,
pero sería demasiado débil para actuar contra la cercana atracción de un cuerpo
de cierto tamaño o, en lo que se refiere a eso, contra la resistencia del aire.
En primer lugar, una nave espacial tendría que encontrarse en pleno espacio
profundo, y debería tener velas que fuesen sumamente sutiles y de un área de
muchos kilómetros cuadrados.

Elevar una nave espacial desde la superficie de la Tierra hacia la Luna por la
presión de la luz, o cualquier cosa de este tipo, resulta imposible. Hay que
tachar el Plan de la Repulsión.



Y esto es todo. Dodge era un hombre inteligente y con conocimientos, que
comprendía con claridad la ciencia (la de 1903); sin embargo, si consideramos
sólo sus cinco planes tal y como los describe, ninguno de ellos tiene la más
mínima posibilidad de permitir a los seres humanos viajar de la Tierra a la
Luna.

¡Y, sin embargo, se ha hecho! Mi padre estaba vivo cuando se escribió ese
artículo, y vivió para ver a los seres humanos pisar la Luna.

¿Cómo es esto posible?

¿Ya se han percatado de la palabra que Dodge omitió? ¿Se han dado cuenta de que
no vio el camión? ¡No mencionó el cohete!

No había ninguna razón para que lo omitiera. Los cohetes se conocían desde
hacía ocho siglos. Se habían empleado en la paz y en la guerra. En 1687, Newton
había explicado a fondo el principio del cohete. Incluso antes, en 1656, Cyrano
de Bergerac, en su relato Un viaje a la Luna hizo una lista de siete maneras de
llegar a la Luna, e incluyó a los cohetes como uno de los métodos.

Así pues ¿cómo es que Dodge lo excluyó? No porque no fuese un hombre agudo. En
realidad, al final de su artículo fue lo suficientemente brillante para ver
algo, en 1903, por lo que yo he estado trabajando como un loco para que la
gente lo comprendiera ahora, ocho décadas después. (Hablaré de ello en el
capítulo siguiente.)

No, no mencionó los cohetes porque los mejores de nosotros en ocasiones no
vemos el camión. (Me pregunto, por ejemplo, qué camiones estamos dejando de ver
ahora mismo.)

Dodge casi lo consiguió con su plan del retroceso, pero sólo porque cometió un
disparate. Pensó que, para conseguir un retroceso decente, el cañón debía
disparar un obús que tuviese una masa por lo menos igual a sí mismo, y eso es
un error.

Lo que cuenta en el disparo y en el retroceso, en la acción y en la reacción,
es el momento. Cuando una bala sale de un arma con cierto momento, esta última
debe ganar un momento igual en la dirección opuesta, y el momento es igual a la
masa multiplicada por la velocidad. En otras palabras, una masa pequeña
produciría el suficiente retroceso si se moviese a suficiente velocidad.

En los cohetes, los vapores calientes expelidos se mueven hacia abajo a gran
velocidad, y lo hacen continuamente, por lo que el cuerpo del cohete se impulsa
hacia arriba con sorprendente aceleración, considerando la pequeña masa del
vapor expulsado. Aún sigue haciendo falta una gran masa para hacer llegar a la
Luna un objeto comparativamente pequeño, pero la diferencia se halla muy lejos
de lo que Dodge temía.

Además, el efecto de retroceso es continuo durante tanto tiempo como esté
ardiendo el combustible y los vapores se expulsen, y esto es equivalente a un
proyectil que es desplazado centenares de kilómetros a lo largo de un cañón. La
aceleración se hace lo suficientemente pequeña para ser soportable.

La posesión de un depósito de reserva de combustible, una vez el cohete se
encuentra ya camino de la Luna, significa que el cohete se puede maniobrar; se
puede frenar su descenso a la Luna; puede despegar de nuevo hacia la Tierra a
voluntad; y puede maniobrar de modo apropiado para entrar en la atmósfera
terrestre.

Y esto es todo realmente, excepto por dos coincidencias, una moderada y la otra
disparatada, y ya saben lo que me gustan las coincidencias.

La coincidencia moderada es ésta: El mismo año en que se escribió ese artículo
para el Munsey's Magazine, Konstantin Tsiolkovski comenzaba una serie de
artículos en una revista de aviación rusa, que trataban de la teoría de los
cohetes aplicada, específicamente, a los viajes espaciales. Fue el primer
estudio científico de esta clase, de modo que la moderna cohetería astronáutica
empezó exactamente en la época en que Dodge especulaba acerca de todo menos de
los cohetes.

La coincidencia disparatada es ésta: Inmediatamente después del articulo de
Dodge, en el que no mencionaba la palabra «cohete» ni se daba cuenta de que era
el cohete, y sólo el cohete, lo que permitiría que los seres humanos lograsen
la gran victoria de llegar a la Luna, apareció, naturalmente, otro artículo, ¿y
cuál creen que era el título de este artículo?

No se molesten en adivinarlo. Se lo diré.

Se titulaba La gran victoria del cohete.

No, no es que alguien corrigiese la omisión de Dodge. Sólo es un relato de
ficción, con el subtítulo: «La estratagema con la que Willie Fetherston ganó
una carrera y una novia».

Y en esta historia, El cohete es el nombre de un caballo.





XIV. DONDE TODO EL CIELO ES RESPLANDOR





Un amigo mío, que es editor (casi todos mis amigos parecen ser escritores,
editores, o directores de publicaciones, lo cual es muy raro..., o tal vez no
sea tan raro), me pidió que escribiese un libro de quintillas humorísticas para
niños.

—Que sean sencillas —me pidió con gravedad, habiéndose enterado de algunas de
mis hazañas previas en esta dirección—. Es decir, si sabes hacer ese tipo de
cosas.

—Naturalmente que sé hacerlas —respondí, en el tono agraviado que empleo cuando
alguien sugiere que existe algún estilo en el que no sé escribir si me lo
propongo.

—Muy bien, pues. Quiero cincuenta.

Así que, una semana después, le entregué mis quintillas, él me preguntó:

—¿Estás seguro de que has hecho cincuenta?

No podía creerlo. En realidad me había dado pie para aquello que más había
soñado. No obstante, disimulándolo, le pregunté de una forma desenvuelta:

—¿Puedo leerte mi última quintilla?

Y lo hice:





50. FINAL





Algunos dicen que mis rimas son una birria,

otros que tengo a la poesía tirria.

Pero no lo tomo en cuenta,

pues ahora que la ocasión se presenta,

las he acabado. Contadlas. ¡Son cincuenta!



Quedó perplejo.

—No te creo —dijo —Estás improvisando. Déjame ver eso.

Le mostré la página. Estaba todo allí.

—¿Cómo sabías que dudaría del número? —pregunto.

—¿Y lo preguntas? ¿Tú con tu desagradable y suspicaz naturaleza?

(No es así, por favor compréndalo. Se trata de una persona deliciosa, como lo
son todos mis amigos escritores/editores/directores de publicaciones, para mi
infinita dicha.)

Lo mejor de la situación es que mi amigo quedó tan superaterrado por lo
apropiado de mi última quintilla, que aceptó las cincuenta sin pedir una sola
revisión o sustitución. Ello prueba el poder de un final fuerte, y esto me hace
volver al artículo de 1903. en el Munsey's Magazine, del que he hablado en el
capítulo anterior.



Si lo recuerdan, el artículo de Ernest Green Dodge, licenciado en Letras,
titulado ¿Pueden los hombres visitar la Luna?, daba una lista de cinco maneras
posibles por las que se podría visitar la Luna, cada una de las cuales era por
completo imposible, aunque había omitido un método el de los cohetes, que era
en realidad posible, y que fue el que se usó finalmente.

Sin embargo, en la última sección del artículo, consideraba brevemente esta
pregunta: «¿Qué utilidad tiene la Luna, en el caso de que el hombre consiga
llegar hasta ella?»

Señalaba que carece de vida, de aire y de agua, y que es «inenarrablemente
fría» durante su larga noche. En esto tiene razón, pero luego continúa y comete
el curioso error de decir que la temperatura en la Luna «está por debajo del
punto de congelación incluso a mediodía».

En realidad, pasaría otro cuarto de siglo antes que se llevasen a cabo
delicadas mediciones de la temperatura de la superficie lunar. De todos modos,
considerando que los rayos del Sol alcanzan la superficie de la Luna de una
manera tan concentrada como cuando llegan a la Tierra, y que en la Luna no
existen corrientes de aire ni agua que alejen el calor y lo dispersen de una
forma más o menos al azar por todo el Globo, y que en la Luna el resplandor del
Sol se mantiene sin interrupción durante catorce días en un solo lugar,
resultaba razonable (y de hecho inevitable), incluso en 1903, llegar a la
conclusión que, durante el día lunar se alcanzaban elevadas temperaturas.

En realidad, la temperatura de la Luna en su ecuador, a mediodía, se encuentra
un poco por encima del punto de ebullición del agua.

De todos modos, aunque Dodge se equivocase en la letra, estaba acertado en el
espíritu, puesto que una temperatura tan elevada aún haría que la Luna fuese
menos agradable que otra que estuviera por debajo del punto de congelación.

Dodge señala que, a pesar de esto, «los hombres podrían habitar allí, durante
algún tiempo, en unas casas de paredes gruesas, herméticas, y podrían salir al
exterior con ayuda de unos trajes también herméticos». Ahora los llamamos
trajes espaciales, y los astronautas vivirán bajo tierra, con mayor
probabilidad que en «casas», pero la pregunta sigue en pie: ¿Para qué pasar por
tantos problemas?

Dodge da cinco respuestas que, en mi opinión, consiguen tocar todos los puntos.
Consideremos, por turno, cada una de ellas.

1) «Los científicos encontrarían en los eriales lunares un campo nuevo para la
exploración.»

Naturalmente. en el año 1903 se hallaba en todo su apogeo la exploración polar.
Hombres intrépidos se encaminaban tanto al Polo Norte como al Polo Sur con gran
determinación. Robert E. Peary alcanzó el primero en 1909, y Roald Amundsen el
segundo en 1911.

Es posible que Dodge tuviese en mente ese tipo de exploración, y, de ser así,
no contó lo suficiente con los avances técnicos. Satélites colocados en órbita
en la Luna enviaron miles de fotografías a la Tierra y a partir de ellas se
pudo elaborar un mapa completo de la Luna sin que ningún ser humano tuviese que
abandonar la Tierra. Esto prácticamente no dejó nada que hacer a los
exploradores de tipo clásico como Peary/Amundsen.

Sin embargo, la afirmación sigue siendo correcta. Los científicos encontrarían
en la Luna un campo para la exploración, si hablamos de la búsqueda de sutiles
fragmentos de pruebas geológicas, físicas y químicas que arrojarían luz sobre
la pasada historia de la Luna (y, asimismo, del Sol. la Tierra y del Sistema
Solar en general). Esto va se está haciendo con las rocas lunares traídas por
los astronautas del Apolo, pero podría realizarse de una forma más efectiva y
con mayores detalles si existiera una base permanente en la Luna.

2) «Los astrónomos podrían plantar allí sus telescopios, libres de su más serio
inconveniente: la atmósfera terrestre.»

Aquí no hay nada que discutir. Estamos planeando poner telescopios de un tamaño
mediano en órbita en torno de la Tierra, por lo que se podría suponer que la
Luna no se necesita realmente. ¿Y si suponemos, sin embargo, que deseamos
emplear un sistema de radiotelescopio realmente grande fuera de la creciente
interferencia de las ondas de radio emitidas por la cada vez más potente
tecnología terrestre? La plataforma que nos proporcionaría el lado más alejado
de la Luna. con más de 3.000 kilómetros de rocas protegiéndola de la Tierra,
sería algo que no tendría paralelo. (En el tiempo en que Dodge escribía, la
proeza de Guglielmo Marconi de enviar ondas de radio a través del Atlántico se
había producido menos de dos años atrás. No podemos culpar a Dodge por no soñar
en algo parecido a la radioastronomía. ¿Quién lo hubiera hecho entonces?)

3) «Los turistas de la clase adinerada y aventurera no dejarían de visitar el
satélite, y podrían mantenerse costosos hoteles para acomodarlos.»

Recuerden que esto era en 1903, cuando se esperaba de los retoños de las
familias dirigentes británicas que fuesen a África o la India para ayudar a la
construcción del Imperio, y donde las clases superiores, privadas de un honesto
trabajo, se veían forzados a ocuparse en frivolidades tales como el alpinismo y
la caza mayor. (¿Se notan mis prejuicios?) Sin embargo, estoy seguro de que
llegará a haber turismo lunar, pero confío en que ello será, en el mayor grado
posible, para todas las «clases».

4) «Es muy probable que se descubran vetas de metales preciosos, yacimientos de
diamantes y una gran abundancia de azufre, en un mundo que tiene un carácter
tan altamente volcánico.»

Es indudable que Dodge creía que la Luna era de naturaleza «altamente
volcánica» porque daba por supuesto que los cráteres eran producto de volcanes
activos en otro tiempo. En la actualidad está bastante claro que los cráteres
son el resultado del bombardeo meteórico en los primeros estadios de la
formación del Sistema Solar, cuando había aún fragmentos de materia uniéndose
para formar mundos. De todos modos, esos grandes choques podrían haber roto la
corteza y permitido que brotara el magma para formar los mares lunares. Así que
dejaremos esto.

Pero ¿y lo de «vetas de metales preciosos, yacimientos de diamantes»? Sabemos
ahora que no existen minas de plata, oro, platino o diamantes, pero demos por
supuesto que Dodge no podía saberlo en 1903.

Incluso así, supongamos que se encontrasen en gran abundancia en la Luna esos
metales preciosos y diamantes. ¿Y qué? La tarea de ir hasta allí para
obtenerlos. y luego traerlos, aumentaría tanto su coste que resultaría más
barato seguir hurgando en la agotada corteza terrestre.

Aun cuando, de alguna manera, el avance tecnológico hiciera posible traer todas
esas cosas «preciosas» de un modo barato, no tendría ninguna utilidad. Dodge
cometió el error de confundir objetos costosos con objetos valiosos. El oro, la
plata, el platino y los diamantes son caros y codiciados porque son raros. Los
diamantes pueden usarse en la industria como abrasivos. el platino para objetos
de laboratorio, el oro para empastes en odontología. y la plata en películas
fotográficas, pero si todos esos materiales fuesen tan comunes como el hierro,
los usos que pudiéramos imaginar para ellos resultarían insuficientes para
consumir más de una pequeña fracción de la cantidad de la que se dispondría.

Quedaría su empleo como adornos, puesto que estas cosas, el oro y los diamantes
en particular, son innegablemente bellos. No obstante, si fuesen tan corrientes
que estuviesen al alcance de todos, ya no serían codiciados. No creo necesario
discutir sobre este punto.

De ello se deduce, pues, que carece de importancia el que haya o no en la Luna
metales preciosos o gemas. Lo que necesitamos para que merezca la pena ir a la
Luna es que haya algún producto valioso, más bien que costoso, y que pueda
usarse en la Luna o en el espacio cercano.

Dodge se acerca más al blanco al mencionar el azufre. El azufre no es una
sustancia bella, ni una cosa que sea codiciada por sí misma. Sin embargo,
constituye la base del ácido sulfúrico que, dejando aparte materias básicas
tales como la energía, el aire, el agua y la sal, es la sustancia individual
más útil en las industrias químicas.

Pero aunque Dodge se equivoque en sus ejemplos, tiene razón en el fondo, puesto
que la corteza lunar puede emplearse como fuente de diversos metales
estructurales, de arcilla, de suelo, de cemento, de vidrio, de oxigeno, todo lo
cual constituye materias primas para la construcción de estructuras en el
espacio. En realidad, si vamos a tener una tecnología espacial, ésta estará
apoyada, principalmente, por la explotación en la Luna.

A continuación Dodge entra en su punto final. y llegamos al final fuerte del
que he hablado en la introducción de este capítulo. Dice: «La población mundial
es capaz de un gran crecimiento... Y las necesidades mundiales de fuerza motriz
[energía] está creciendo mucho más rápidamente que la población.»

En esto Dodge está totalmente acertado, pero resulta obvio que cualquier
persona que pensara lo hubiera visto, incluso en 1903, de haberse molestado en
pensar en esa dirección. No obstante, supongo que muy pocas personas, en 1903,
hubieran sentido alarma alguna en lo referente a este asunto. La Humanidad
occidental estaba aún en la cresta de la ola del optimismo del siglo XIX, y
todavía faltaban once años para que la Primera Guerra Mundial hiciese añicos
todo esto.

Sin embargo. Dodge prosiguió y puso el dedo en algo que le señaló como un
hombre dos generaciones por delante de su tiempo. Dice: «Nuestros
abastecimientos de carbón y madera son limitados, y muy pronto quedarán
agotados».

En tiempos de Dodge, ya se utilizaban fracciones del petróleo como combustible,
pero aún en muy pequeña escala. Dodge no previó que la proliferación de los
motores de combustión interna en todo, desde coches a aviones, haría que el
petróleo. en el transcurso de medio siglo, alcanzase la condición de principal
combustible de la Humanidad, dejando al «carbón y a la madera» en la sombra.

No obstante esto no afecta a lo bien fundado de su observación, puesto que el
petróleo se halla en cantidad más limitada que el carbón, y. a diferencia de la
madera, no es renovable. En resumen, el carbón y el petróleo es probable que
algún día se agoten el petróleo mucho antes que el carbón, y la madera sola no
podrá sustentar nuestra actual población y tecnología. Entonces ¿qué podemos
hacer?

Dodge conoce fuentes alternativas de energía. Dice: «Los saltos de agua pueden
hacer mucho. Los molinos de viento pueden hacer no poco.» La implicación es
clara en cuanto a que. de todos modos, por si mismos no pueden ser suficientes.
Existen otras fuentes alternativas que no menciona: la energía de las olas, las
corrientes oceánicas, mareas, diferencias de temperatura entre la superficie y
las profundidades tanto de la tierra como del mar, etcétera. Todos ellos son, o
pueden ser útiles, pero tal vez todos juntos aún no resulten suficientes.

No menciona (ni siquiera soñaba con ello, supongo) la energía nuclear, aunque
su existencia había sido descubierta unos pocos años antes, y H. G. Wells había
especulado sobre el asunto ya en 1901. De todos modos, en 1903 era aún un poco
pronto y no voy a regañar a Dodge por haberlo pasado por alto.

Sin embargo. Dodge sigue diciendo: «Las maquinas solares con espejos cóncavos
para reunir los rayos del Sol se han puesto últimamente en práctica. y en el
futuro llegaran a realizar maravillas, aunque sus recursos, en nuestra
atmósfera pesada y nubosa, no son ilimitados. Pero las máquinas solares
funcionarán con mayor ventaja en la Luna que en la Tierra.»

Encuentro esto notable. Estaba pronosticando las centrales de energía solar en
el espacio cuarenta años antes de que yo especulase acerca de ello en mi relato
Razón, y sesenta años antes de que los científicos comenzasen a pensar
seriamente en ellas. Me pregunto si ésta no podría ser la primera mención
razonable de una cosa así. (Si alguno de mis Gentiles Lectores sabe de un caso
anterior, científico o de ciencia-ficción, me gustaría conocerlo).

En realidad, Dodge piensa en la energía solar en términos de una concentración
de los rayos del Sol. una concentración que daría más calor en un pequeño lugar
de lo que ocurriría de otra forma. Los grandes espejos concentrarían la luz
sobre un depósito de agua, haciéndola hervir y produciendo así vapor. De este
modo tendríamos una máquina de vapor, ocupando la luz solar el lugar del carbón
como productor del vapor. Esto tendría la ventaja de que el Sol, a diferencia
del carbón, no se agotaría nunca o, por lo menos, no lo haría en miles de
millones de años.

Dodge, al explicar las ventajas de la Luna, muestra con claridad que está
pensando en una máquina de vapor, puesto que dice que la máquina lunar
trabajaría mejor «debido, en parte, a la ausencia de nubes y neblinas, pero
principalmente por la baja temperatura a la que los vapores condensados se
descargarían desde los cilindros». (Aquí, una vez más, Dodge actúa creyendo que
la superficie lunar sería muy fría incluso bajo un sol esplendoroso.)

Sin embargo, en 1903. un empleo crecientemente importante de las máquinas de
vapor consistía en hacer girar un generador para producir corriente eléctrica.
Ese uso se fue haciendo cada vez más importante en las décadas que siguieron,
pero, incluso en 1903, hubiera sido posible preguntarse si la luz del Sol en la
Luna no podría convertirse directamente en electricidad, en lugar de tener que
hacerlo mediante la máquina de vapor. A fin de cuentas, esa conversión directa
(«fotoelectricidad») ya se conocía.

En 1840, el físico francés Alexandre Edmond Becquerel mostró que la luz podía
producir ciertos cambios químicos que, a su vez, podían producir corrientes
eléctricas. Esto no era por completo una conversión directa de la luz en
electricidad, pero presentaba una relación.

Algo más directo implicaba el elemento selenio, que, junto con su gemelo el
telurio, se parece mucho al azufre en sus propiedades químicas. De ambos, el
telurio, aunque es el menos común, fue el primero en descubrirse.

El telurio fue descubierto en 1783 por un mineralogista austríaco, Franz Joseph
Muller. El descubrimiento fue confirmado en 1798 por el químico alemán Martin
Heinrich Klaproth, que cuidó de conceder todo el crédito a Müller. Fue Klaproth
quien dio al nuevo elemento su nombre, telurio, de la voz latina que designa la
Tierra. Al parecer eligió este nombre porque había descubierto anteriormente un
elemento al que había denominado uranio, según el recién descubierto planeta
Urano, que, a su vez, había sido llamado así por el dios griego de los cielos.
Así, los dos elementos llevaban el nombre de la Tierra y el cielo.

En 1817, el químico sueco Jöns Jakob Berzelius descubrió unas trazas de una
sustancia desconocida en el ácido sulfúrico, algo que él tomó por un compuesto
del telurio. Tras examinarlo más detenidamente, decidió, en 1818, que lo que
había encontrado era una sustancia que no contenía telurio, sino un elemento
extraño similar al mismo en sus propiedades. Quiso equilibrar la «Tierra» que
el telurio presentaba, y dado que «cielo» ya se había usado, eligió «Luna», y
llamó al nuevo elemento selenio, según la diosa griega de la Luna.

El selenio existe en diferentes formas, dependiendo de la disposición de sus
átomos. Una de esas formas es de un color gris plateado que, en ocasiones se
llama «selenio gris». Éste muestra ciertas propiedades metálicas y posee, por
ejemplo, una leve tendencia a conducir una corriente eléctrica, aunque otras
formas del elemento no lo hacen.

La tendencia es muy pequeña, pero, en 1873, Willoughby Smith observó que,
cuando el selenio gris se expone a la luz solar, la conductividad eléctrica del
elemento aumenta marcadamente. En la oscuridad, la conductividad disminuye,
tras un breve intervalo, hasta alcanzar de nuevo el bajo nivel original. El
descubrimiento no suscitó gran interés en la época, pero fue la primera
demostración de una conversión directa de la luz en electricidad.

Luego, en 1888, el físico alemán Heinrich Rudolf Hertz estaba experimentando
con corrientes eléctricas obligadas a saltar a través de un entrehierro
(experimentos que dieron como resultado el descubrimiento de las ondas radio).
Vio que, cuando brillaba la luz ultravioleta en el lado cargado negativamente
del entrehierro, la corriente eléctrica lo saltaba con mayor facilidad que al
contrario. Esta vez el mundo de la ciencia escuchó, y suele atribuirse a Hertz
el mérito del descubrimiento del efecto fotoeléctrico aunque existía ya en el
hallazgo, por parte de Smith, de la conducta del selenio, quince años antes.

El efecto fotoeléctrico se produce porque la luz puede hacer salir los
electrones de los átomos, si se dan las apropiadas longitudes de onda y los
átomos apropiados. Los físicos no tuvieron explicación para los detalles
exactos del efecto hasta 1905, cuando Albert Einstein aplicó al problema la
entonces nueva teoría del cuanto, y consiguió con ello el premio Nobel.

Sin embargo, la aplicación práctica de un fenómeno observado no tiene por qué
esperar a la explicación científica apropiada.

Por ejemplo, en 1889, sólo un año después de la demostración de Hertz del
efecto fotoeléctrico, dos físicos alemanes, Johann P. L. J. Elster y Hans
Friedrich Geitel, estaban trabajando juntos sobre este fenómeno.

Pudieron demostrar que algunos metales presentaban el efecto fotoeléctrico con
mayor facilidad que otros. (Es decir, que los electrones eran más fácilmente
liberados de algunos tipos de átomos que de otros.) Los metales álcali eran más
sensibles al efecto, y los metales álcalis más comunes eran el sodio y el
potasio. Por tanto, Elster y Geitel trabajaron con una aleación de sodio y
potasio, y descubrieron que una corriente podía ser forzada a través de ellos y
por un entrehierro sin dificultad en presencia de luz visible, pero no en la
oscuridad.

Esta fue la primera «célula fotoeléctrica», o «fotocélula», y se emplea para
medir la intensidad de la luz. A mayor intensidad, mayor corriente eléctrica, y
mientras la primera era difícil de medir directamente, la segunda resultaba muy
fácil de medir.

Aunque los científicos podían. y lo hicieron, emplear la fotocélula de
sodio-potasio con fines científicos, resultaba muy poco práctica para la vida
cotidiana. El sodio y el potasio son sustancias sumamente activas y peligrosas.
y requieren el mayor de los cuidados en su manipulación.

Aproximadamente en la misma época en que Elster y Geitel producían su
fotocélula. un inventor estadounidense, Charles Fritts, utilizaba la rara
propiedad del selenio gris que Smith había observado con anterioridad. Fritts
preparó pequeñas obleas de selenio, revestidas con una delgada capa de oro. Las
incorporó a un circuito eléctrico de tal forma que una corriente sólo fluía
cuando las obleas de selenio (otro tipo de fotocélula) estaban iluminadas.

Así pues, las fotocélulas existían va desde hacía unos cuatro años cuando Dodge
escribió su articulo en Munseys Magazine. Sin embargo, eran unos objetos raros,
y no puedo culpar a Dodge si no había oído hablar de ellos. Y lo que es más,
aunque las conociese, apenas parecían ser, en aquel tiempo, más que pequeños
artilugios condenados para siempre a usos menores, y ciertamente no candidatos
a la conversión en gran escala de la luz solar en energía útil. En realidad, a
pesar de las grandilocuentes alegaciones de Fritts, la fotocélula de selenio
convertía en electricidad menos del 1% de la luz que caía sobre ella, una
eficacia espantosamente baja.

De todos modos, las fotocélulas de selenio podrían utilizarse para unos
interesantes propósitos menores. El más familiar de ellos para el público en
general es el «ojo eléctrico».

Supongamos que una puerta está equipada con algún dispositivo que puede
mantenerla abierta si se deja que funcione sin impedimentos. Supongamos,
además, que una pequeña corriente eléctrica puede accionar un relé que active
otro mayor que sirva para cerrar la puerta. La pequeña corriente eléctrica pasa
a través de un circuito que incorpora una fotocélula de selenio.

Imaginemos a continuación una pequeña fuente de luz en un lado de la puerta que
envía un débil rayo a través de ésta hasta la fotocélula de selenio que se
halla en el otro lado. Mientras ese pequeño rayo existe, la fotocélula de
selenio permite el paso de la pequeña corriente que activa el relé y mantiene
las puertas cerradas.

Si, en cualquier momento, se produce una interrupción del rayo de luz, incluso
durante muy poco tiempo, la fotocélula de selenio, momentáneamente en la
oscuridad, se resiste a permitir que pase la corriente. La débil corriente
falla, el relé no es activado, y ya no hay nada que mantenga las puertas
cerradas. Por lo tanto, la puerta se queda abierta hasta que la luz funciona de
nuevo y entonces se cierra.

Una persona que se aproxime a la puerta bloquea la luz con su cuerpo apenas
llega allí. La puerta se abre «por si misma» un momento para permitirle pasar,
y luego se cierra otra vez.

(Siempre he creído que si alguien no supiera nada acerca de ojos eléctricos, se
podría hacer que le observara a uno acercarse a la puerta y entonces gritar:
«¡Ábrete, Sésamo!» Durante un desconcertante momento. el observador creería
encontrarse en el cuento de Alí Babá de Las mil y una noches. Eso es lo que
Arthur C. Clarke intenta decir cuando afirma que la tecnología avanzada
equivale a la magia para un no iniciado.)



La fotocélula de selenio, y las fotocélulas en general, no fueron mejoradas de
forma perceptible hasta mediado el siglo XX. En 1948, los científicos de Bell
Telephone inventaron el transistor (véase X representa lo desconocido, del
mismo autor), y eso lo cambió todo. El transistor funciona porque pueden
liberarse electrones de átomos como los del silicio o el germanio. Por lo
tanto, la investigación en el campo de los transistores significa investigar
algo que podría presentar un efecto fotoeléctrico.

Esto, en realidad, no resultó inmediatamente obvio, y cuando Darryl Chapin, de
Bell Telephone, estaba buscando alguna fuente de electricidad que pudiese
emplearse para los sistemas telefónicos en áreas aisladas (algo que mantuviese
en funcionamiento los sistemas si fallaban las fuentes tradicionales), probó
las fotocélulas de selenio. No funcionó. No podía convertirse en electricidad
una cantidad suficiente de luz solar para hacerlo de uso práctico.

No obstante, en otra sección de Bell Telephone, Calvin Fuller estaba trabajando
con la clase de obleas de silicio empleadas en los transistores y halló, más o
menos accidentalmente, que la luz solar producía en ellas una corriente
eléctrica. Fuller y Chapin se unieron y produjeron la primera célula solar
práctica.

Las primeras células solares tenían una eficacia del 4%, y con el tiempo
consiguieron llegar al 16%.

A partir de este punto fue posible soñar con la energía solar de una manera
mucho más sofisticada que los espejos cóncavos que imaginara Dodge. Supongamos
que hubiera varios kilómetros cuadrados de células solares instaladas en alguna
zona desértica, donde la luz solar fuera relativamente estable. ¿ No
producirían una corriente continua de electricidad, no contaminada e
interminable, en grandes cantidades?

El inconveniente es que una célula solar, aunque individualmente sea poco cara,
en las enormes cantidades necesarias para revestir una gran zona del espacio de
la Tierra resultaría prohibitivamente costosa. Y añádase a esto los elevados
gastos para un mantenimiento apropiado después de la instalación.

No obstante, las células solares se han empleado para fines menores, como para
propulsar los satélites en órbita, y han demostrado funcionar allí
perfectamente. (Yo utilizo una calculadora de bolsillo alimentada por células
solares, por lo que carece de pilas y no las necesitará nunca.)

Lo que debemos lograr es que las células solares sean más baratas, más eficaces
y más fiables. En vez de tener que emplear grandes cristales únicos de silicio,
de los que pueden desprenderse pequeñas astillas, podría llegar a ser posible
utilizar silicio amorfo compuesto por diminutos cristales trabados, cuya
producción sería mucho más barata.

Y en vez de instalar células solares campo sobre campo, cubriendo vastas
extensiones de tierras desérticas, donde el aire no es perfectamente
transparente (especialmente cuando el Sol está bajo), podríamos instalarías en
la Luna, donde durante dos semanas seguidas todo el cielo es resplandor y no
hay aire que interfiera; o incluso en el espacio, donde casi nunca es de noche
y todo el firmamento está lleno de luz solar casi siempre.

De este modo, el sueño romántico de Dodge podría, finalmente, hacerse realidad.





XV. ¡ARRIBA!





La semana pasada me encontraba en Boston para la inauguración de un nuevo
edificio en el Centro Médico de la Universidad de Boston. A fin de cuentas, soy
profesor de Bioquímica allí, y debo hacer algo para demostrarlo de vez en
cuando.

Di una charla en el almuerzo, y antes me entrevistaron y me dijeron que dicha
entrevista aparecería al día siguiente en el USA Today, pero yo no lo vi. (A
pesar de la reputación de que poseo un ego monstruoso, por lo general consigo
no verme en los periódicos o en la televisión. Me pregunto el porqué. ¿Será
porque no tengo un ego monstruoso?)

Alguien me dijo, un par de días después:

—Ayer salió una entrevista suya en el USA Today.

—¿De veras? —exclamé. —No la vi. ¿Era interesante? —Decían que usted no va en
avión —fue la respuesta.

¡Gran noticia! Cada vez que me entrevistan aparece esto. Ningún entrevistador,
durante un número considerable de años, ha dejado de preguntarme por qué no voy
en avión. Naturalmente, la respuesta es que tengo miedo a volar, y no tengo el
menor interés en corregir ese temor. Pero ¿por qué? ¿Por qué eso ha de salir
siempre en los titulares?

Cuando sugiero que carece de importancia el que no vaya en avión, el
entrevistador siempre se siente obligado a reflexionar sobre el hecho curioso
de que, en mi imaginación, recorro el Universo de una punta a otra y. sin
embargo, no vuelo en la vida real.

¿Por qué, pregunto una vez más? También escribo novelas policíacas y nunca he
matado a nadie, o escribo cosas fantásticas, sin realizar encantamientos en la
vida real.

Me cansa un poco el ser una fuente constante de asombro para todos simplemente
porque no voy en avión, y a veces pienso que me hubiera librado de este
problema si jamás se hubiera pensado en todo este asunto del volar.

Así que vamos a considerar los orígenes de eso de ascender a los cielos. y
planteémonos una pregunta: ¿Cómo se llamaba el primer aeronauta? No, la
respuesta no es Orville Wright.



La gente siempre ha querido volar. Supongo que lo que les dio esta idea, en
primer lugar, fue el hecho de que existían algunos seres vivos que lo hacían.
Existen en la actualidad tres grupos de animales que han desarrollado el vuelo
verdadero: insectos, aves y murciélagos. (También existe un cuarto grupo: los
reptiles voladores del mesozoico, en la actualidad extintos, pero su existencia
fue desconocida para los seres humanos hasta el siglo XIX.)

Todos los organismos voladores tienen algo en común: alas que baten contra el
aire. Sin embargo, cada variedad posee alas de un tipo característico. Los
seres humanos han atribuido a cada tipo de alas unos caracteres míticos
adecuados, y han conseguido de este modo dejar muy clara la relativa
popularidad de las tres. Así, demonios y dragones tienen alas de murciélago;
las hadas, diáfanas alas de mariposa, y los ángeles están equipados con grandes
alas de pájaro.

Cuando los seres humanos soñaron con volar, recurrieron a cosas mágicas:
alfombras que volaban al oír una palabra mágica, caballos de madera que volaban
al darle vueltas a una clavija mágica, etcétera. Cuando se pedía cierto
realismo, se imaginaba que la criatura voladora poseía alas. El ejemplo más
famoso es Pegaso, el caballo alado.

Entre los antiguos nadie pareció percatarse de que todos los organismos que
volaban eran pequeños. Los insectos son diminutos, los murciélagos, por lo
general, tienen el tamaño de un ratón, e incluso las más grandes aves voladoras
son mucho más pequeñas que muchos de los animales que no vuelan (o incluso que
aves no voladoras como los avestruces). Si se hubieran percatado de ello, la
gente tal vez habría deducido que no había modo razonable de que unas criaturas
auténticamente grandes pudiesen volar. No podía haber pitones con alas
(dragones), ni caballos alados, ni hombres con alas.

Si la gente ignoraba esta obvia (retrospectivamente) deducción tal vez era
porque les parecía que había algo, aparte de la pequeñez, que constituía la
clave del volar. Las aves eran las criaturas voladoras por excelencia, y lo que
tenían que no poseían las no aves era: plumas.

Y lo que es más: las plumas son fáciles de asociar con el vuelo. Son tan
ligeras que se han convertido en imagen de esa cualidad. El cliché es: «Ligero
como una pluma». Una pequeña pluma cubierta de pelusa flotará en el aire,
elevándose con cada soplo de viento casi como si tratase de volar por sí misma,
incluso sin el impulso de una vida interior.

Así pues, parecía natural suponer que, si un hombre tuviese que volar, no
debería proveérsele de alas sino de plumas.

Así, cuando Dédalo en el mito griego, quiso huir de Creta, se fabricó unas alas
pegando plumas con cera. Él y su hijo Icaro, equipados con esos conglomerados
de plumas en forma de alas, pudieron volar, no gracias a algo siquiera
vagamente aerodinámico, sino gracias a las propiedades aeronáuticas de las
plumas. Cuando Icaro voló demasiado alto y, por lo tanto, demasiado cerca del
Sol, la cera se derritió, las plumas se separaron y él se precipitó al suelo y
se mató.

En realidad, sólo las aves vuelan gracias a las plumas, y ningún ser humano o
artefacto construido por él ha volado nunca batiendo unas alas, estuviesen
éstas provistas o no de plumas. Cuando se logró la propulsión activa a través
del aire, fue por unas hélices que giraban o por los tubos de escape de un
reactor, método que no emplea ningún organismo que vuele de modo natural.



Sin embargo, no es necesario volar para viajar a través del aire y ser
aeronauta. Es decir, no es necesario moverse independientemente del viento.
Basta moverse con el viento y aprovechar las corrientes ascendentes para no
descender bajo la atracción inexorable de la gravedad; por lo menos, durante
algún tiempo. Ese movimiento con el viento se llama «planeo».

Algunas veces, aunque pueden volar perfectamente, de vez en cuando planean
durante considerables períodos de tiempo, con las alas extendidas y mantenidas
firmes. Cualquiera que observe a un ave que haga esto tendrá la impresión de
que planear es más divertido que volar. El vuelo requiere un esfuerzo constante
y enérgico, mientras que el planear es reposado.

Algunos animales (tales como las ardillas voladoras, el lemur volador, los
falangeros voladores y otros) que no pueden volar, pueden, no obstante planear.
Sus «vuelos» son naturalmente, muy limitados cuando los comparamos con los de
los voladores auténticos. Los planeadores son más pasivos que activos: se
mueven bajo el control del aire y no bajo el de su voluntad.

No obstante, es mucho más sencillo emular el planeo que el vuelo. Cualquier
cosa ligera y plana, que presente una gran superficie al aire, puede llegar a
deslizarse a través de éste. Si se construye un objeto planeador lo
suficientemente ligero y lo bastante grande y se idea una forma de hacerlo
maniobrar desde el suelo, aprovechando las corrientes ascendentes, se tiene una
cometa, algo que se ha usado como juguete en el Asia oriental desde los tiempos
antiguos.

Cuanto mayor es la cometa, cuanto mayor es su área superficial en comparación
con su peso total, mayor sería el peso ajeno que llevara. Si se hace una cometa
lo suficientemente grande (y, sin embargo, lo bastante fuerte), puede llevar a
un ser humano. Esto es así particularmente si se desarrolla la ciencia
aerodinámica y si una gran cometa (o «planeador») tiene una forma con la que se
incremente su eficacia. En 1891, el aeronauta alemán Otto Lilienthal
(1848-1896) construyó el primer planeador capaz de llevar a un ser humano, y
navegó por los aires con él. (Por desgracia, cinco años después Lilienthal
murió al estrellarse su planeador.)

Todos sabemos que los planeadores tienen el aspecto de frágiles aviones sin
motores o hélices. En realidad, en 1903, cuando los hermanos Wilbur Wright
(1867-1912) y Orville Wright (1871-1948) inventaron el aeroplano, lo hicieron
añadiéndole un motor y una hélice a un planeador que habían mejorado de varias
formas.

Así pues, ¿podemos decir que Otto Lilienthal fue el primer aeronauta? No, si lo
hiciéramos nos equivocaríamos, pues Lilienthal no fue el primero por más de un
siglo. Al parecer, existe una tercera manera de viajar provechosamente a través
del aire





[5]: no se trata de volar, ni de planear, sino de flotar.



Desde los más remotos inicios del pensamiento humano, la gente debió de notar
que el humo de una fogata se eleva en el aire y que, cerca de un fuego, los
objetos ligeros como fragmentos de ceniza, de hollín, de plumas u hojas se
elevan con el humo.

Indudablemente, ni uno entre un millón de aquellos que observaron esto pensó en
ello en absoluto. Sin embargo, los filósofos griegos lo hicieron, puesto que su
oficio consistía en darle sentido al Universo. Aristóteles, en su resumen de la
ciencia de su tiempo, elaboró esto hacia el año 340 a. de J.C.

Existen cinco sustancias básicas que forman el Universo: tierra, agua, aire,
fuego y éter. Estas están dispuestas en capas concéntricas. La tierra se halla
en el centro, es una esfera sólida. Alrededor se encuentra una capa de agua (no
suficiente para formar una capa completa, y por ello aparecen expuestos los
continentes). En torno de la tierra y del agua hay una capa de aire, y a su
alrededor una capa de fuego (normalmente invisible, pero que puede verse alguna
vez como el destello de un relámpago). En el auténtico exterior se halla el
éter, que compone los cuerpos celestes.

Cada sustancia tenía su lugar y, cuando por alguna razón salía de ésta, se
apresuraba a regresar. De este modo, cualquier objeto sólido suspendido en el
aire caía hacia la tierra en cuanto se le soltaba. Por otra parte, el agua o el
aire atrapados bajo tierra tenderán a elevarse si se les suelta. En particular,
un fuego, una vez iniciado se esforzará por alcanzar su lugar por encima del
aire. Ésta es la razón de que las llamas se eleven. El humo, que contiene
muchas partículas ardientes, también se desplaza hacia arriba a través del
aire, y con tanta fuerza que puede llevar consigo partículas ligeras no
flamígeras por lo menos durante algún tiempo.

Esta era una explicación muy razonable, dados los conocimientos de la época, y
el asunto ya no se puso más en tela de juicio.

Naturalmente, existían problemas en esta explicación. Una piedra soltada en la
superficie de una charca se hunde en el agua y, al final, reposa en el fondo de
tierra, como cabría esperar según la teoría de Aristóteles. Sin embargo, la
madera, que al igual que una piedra es sólida y, por tanto, se pensaría que es
una forma de tierra, si se suelta en la superficie de una charca se quedaría
allí, flotando indefinidamente en el agua.

Una explicación aristotélica podría ser que la madera contiene una mezcla de
partículas de aire que imparten suficiente movimiento ascendente natural para
hacerla flotar, y esto tampoco es un mal intento de explicación.

El matemático griego Arquímedes (287-212 a. de J.C.), no obstante, elaboró el
principio de la flotabilidad. Esta explicaba la flotación comparando las
densidades de los objetos sólidos con el agua. Un sólido que fuera menos denso
que el agua flotaría en ella. La flotación fue, de este modo, tratada en
términos cuantitativos, y no meramente cualitativos. Midiendo la densidad no
sólo se podía predecir que una sustancia flotaría, sino también exactamente
hasta dónde se hundiría en el agua antes de empezar a flotar. También explicaba
por qué un objeto que no flotaba reducía, sin embargo, su peso cuando se le
sumergía en agua, y exactamente en cuánto se reduciría su peso.

En resumen, la explicación de Arquímedes era mucho más satisfactoria que la de
Aristóteles.

De esto se dedujo que el principio de flotabilidad podría aplicarse también al
aire. Algo menos denso que el aire se elevaría en éste, exactamente igual que
algo menos denso que el agua ascendería si se sumergiese en agua. Sin embargo,
esta analogía no se le ocurrió a nadie hasta dieciocho siglos después de la
época de Arquímedes, simplemente porque nadie pensó en el aire de ninguna
manera análoga al agua. En realidad, el aire no era reconocido como sustancia.

El punto decisivo se presentó en 1643, cuando el físico italiano Evangelista
Torricelli (1608-1647) demostró que la atmósfera (y, por lo tanto, cualquier
muestra de aire) poseía un peso mensurable. En realidad, podía aguantar una
columna de mercurio de 76 centímetros de altura (una columna así constituyó el
primer barómetro). De esta forma, se reconoció finalmente el aire como materia,
una materia muy atenuada, pero materia al fin y al cabo.

A partir del descubrimiento de Torricelli, se podía razonar que, si un volumen
dado de cualquier sustancia pesaba menos que el mismo volumen de aire, esa
sustancia sería menos densa que el aire y se elevaría.

Luego, en 1648, el matemático francés Blaise Pascal (1623-1662) persuadió a su
cuñado para que subiera a una montaña local con dos barómetros y demostrase que
el peso de la atmósfera se reducía con la altura. En realidad, el peso bajó de
tal manera, que resultó evidente que la densidad del aire decrecía con la
altitud.

Esto significaba que una sustancia menos densa que el aire se elevaría hasta
alcanzar una altura en la que su densidad fuera igual a la del aire más sutil.
Entonces no se elevaría más.

Hasta aquí todo bien, pero no había ninguna sustancia conocida que fuera menos
densa que el aire. Incluso el menos denso de los líquidos y sólidos ordinarios
que conocían los seres humanos de aquella época era centenares de veces más
denso que el aire.

Pero, ¿qué cabe decir de ninguna sustancia en absoluto? ¿Qué pasa con la nada?

Cuando Torricelli construyó su barómetro, había un espacio por encima de la
parte superior de la columna de mercurio que no contenía más que trazas de
vapor de mercurio. Constituyó el primer vacío creado por seres humanos, y un
vacío es, ciertamente, menos denso que el aire.

Y lo que es más, en 1650, un físico alemán, Otto von Guericke (1602-1686),
inventó una bomba de aire que, por primera vez, podía (con arduos esfuerzos)
producir un volumen considerable de vacío.

Así pues, hacia 1670. un físico italiano, Francesco de Lana (1631-1687), se
convirtió en el primero en sugerir la construcción de algo que flotase en el
aire. Señaló que si se vaciara una delgada esfera de cobre, en ese caso el peso
total del cobre alcanzaría un promedio superior al volumen de la esfera (sin
aire dentro que añadir al peso) y sería menor que el de un volumen igual de
aire. Semejante esfera vaciada se elevaría. Si la esfera se fabricase lo
suficientemente grande, y si gran parte de ella se uniese a alguna clase de
barquilla ligera, el conjunto se elevaría en el aire llevando a un hombre.

En realidad, el proyecto no era práctico. Si una esfera de cobre fuera lo
suficientemente delgada para alzarse tras ser vaciada el cobre sería demasiado
delgado para resistir la presión del aire a la que se vería expuesto. Se
derrumbaría si se la vaciase. Si la esfera fuese lo bastante gruesa para
soportar la presión del aire, sería demasiado gruesa para tener como promedio
menos de la densidad del aire en cualesquiera circunstancias prácticas. Sin
embargo, De Lana fue el primero en prever la creación de un «globo».



No obstante, la noción de De Lana de emplear un vacío para la flotabilidad, no
constituyó el final. En los años 1620, el químico flamenco Jan Baptista van
Helmont fue el primero en reconocer que existían diferentes gases (también fue
el primero en emplear esta palabra), y que el aire no era único. En particular,
fue el primero en estudiar lo que ahora llamamos anhídrido carbónico (véase
capítulo IX).

Era posible que existiese un gas que fuese menos denso que el aire y que, por
lo tanto, flotase en el aire, pero en ese caso no se trataría del anhídrido
carbónico, puesto que éste es 1,5 veces más denso que el aire. Sin embargo, no
hubo nadie hasta los años 1760 que midiese las densidades de gases concretos,
por lo que hasta entonces nadie pudo especular de modo razonable con globos
llenos de gas.

En 1766, el químico inglés Henry Cavendish (1731-1810) consiguió un gas por
medio de la acción de ácidos sobre metales. Descubrió que era muy inflamable y,
por lo tanto, lo llamó «gas de fuego». Midió su densidad y vio que era sólo
0,07 veces la del aire. Esto constituyó un récord de la baja densidad de las
sustancias normales en las condiciones de la superficie de la Tierra que ha
perdurado hasta hoy.

En 1784, Cavendish descubrió que el hidrógeno, al arder, formaba agua, por lo
que el químico francés Antoine Laurent Lavoisier (1743-1794) lo llamó
«hidrógeno» (de las voces griegas que significan «productor de agua»).

Supongamos ahora que tenemos un volumen de aire que pese 1 kilogramo. Ese mismo
volumen de vacío pesaría 0 kilogramos, y si podemos imaginarnos colgando pesos
en ese volumen de vacío, podríamos colgar 1 kilogramo para que pesase igual que
el mismo volumen de aire (y eso elevaría la densidad media del sistema hasta la
del aire). Así se evitaría que el vacío ascendiera.

Si en vez de esto tomásemos el mismo volumen de hidrógeno, que tendría un peso
de 0,07 kilogramos deberíamos tener un peso de 0,93 kilogramos en él para que
su peso fuera igual al del mismo volumen de aire y evitar que ascendiera. En
otras palabras, el hidrógeno tendría un sorprendente 93% de la flotabilidad del
vacío, y es muchísimo más fácil llenar un contenedor con hidrógeno que tener
que vaciarlo.

Y lo que es más, el hidrógeno, en condiciones normales, tendría el mismo número
de moléculas por unidad de volumen que el aire. Aunque las moléculas de
hidrógeno son más ligeras que las de aire, las moléculas de hidrógeno se mueven
más deprisa y, al final, el momento de las moléculas (y por lo tanto la
presión) es el mismo en ambos casos.

Esto significa que mientras el vacío, cuando se usa por su efecto de
flotabilidad, debe estar contenido en un metal lo suficientemente grueso para
resistir la presión del aire, lo cual añade al sistema un peso prohibitivo, la
situación es del todo diferente con el hidrógeno. La presión del hidrógeno
dentro del contenedor equilibraría la presión del aire exterior, de modo que el
contenedor mismo sería tan fino y ligero como fuese posible, mientras fuese
razonablemente hermético y no permitiese que el hidrógeno se difundiese hacia
afuera, o que el aire se difundiese hacia dentro.

Cabria pensar, pues, que en cuanto Cavendish hubo descubierto la baja densidad
del hidrógeno él, o posiblemente alguna otra persona, habría pensado en su
efecto de flotabilidad y se habría dedicado a confeccionar un globo. Pero no
fue así.

Por clara que pueda ser la visión retrospectiva, la previsión puede ser
notablemente baja incluso para un científico de primera clase como Cavendish.

En realidad, el hidrógeno acabó no teniendo nada que ver con la invención del
globo.



Esto nos hace retroceder a la cuestión anterior del humo que asciende. ¿Por qué
asciende el humo, cuando está compuesto por partículas que, individualmente,
son más densas que el aire y contiene gases, como el anhídrido carbónico, que
también son más densas que el aire?

La clave de la respuesta llegó en 1676, cuando un físico francés, Edmé Mariotte
(1620-1684), observó que el aire se expande cuando se calienta. Si una cantidad
dada de aire se expande, su cantidad fija de masa se extiende en un volumen más
grande, lo cual es otra forma de decir que su densidad disminuye. En otras
palabras, el aire caliente es menos denso que el aire frío, y posee un efecto
flotabilidad. Cuanto más cálido sea el aire, mayor será el efecto de
flotabilidad. Esto se hizo patente en 1699 mediante los estudios acerca de los
gases realizados por un físico francés, Guillaume Amontons (1663-1705).

Una fogata ordinaria de madera calienta el aire a su alrededor a una
temperatura de hasta 700ºC, y la densidad del aire a dicha temperatura es de
sólo la mitad de la del aire ordinario. Este aire caliente posee la mitad del
efecto de flotabilidad del hidrógeno (o del vacío, pongamos por caso). La
columna de aire caliente se eleva vigorosamente y lleva consigo otros gases y
los materiales ligeros que constituyen el humo.

Existen ventajas del aire caliente sobre el hidrógeno que compensan el que
aquél no tenga tanta flotabilidad. El aire caliente se obtiene con facilidad,
todo lo que se necesita es fuego. Por otra parte, el hidrógeno es
comparativamente difícil de reunir en cantidad. Además, el aire caliente no es
inflamable, mientras que el hidrógeno es en realidad explosivo. Por otro lado,
la flotabilidad del hidrógeno es permanente, mientras que el aire caliente
pierde flotabilidad con rapidez al enfriarse, por lo que no simplemente se ha
de tener fuego al principio, sino que hay que mantenerlo mientras se desee
permanecer en el aire.

Uno podría suponer que, tan pronto como se conoció la baja densidad y por lo
tanto, la flotabilidad del aire calentado, alguien pensaría en un globo y
trataría de construirlo, pero esto es visión retrospectiva. Pasó un siglo antes
de que esta idea se le ocurriera a alguien.

Los hermanos Joseph Michel Montgolfier (1740-1810) y Jacques Étienne
Montgolfier (1745-1799) fueron dos de los dieciséis hijos de un acaudalado
fabricante de papel. Uno de sus antepasados (según la tradición familiar) había
aprendido la técnica de la fabricación del papel en una prisión de Damasco en
la época de las cruzadas, y la había traído de Oriente.

Los hermanos habían observado cómo se elevaban objetos en el aire caliente
producido por los fuegos, y el hermano mayor había estado leyendo cosas acerca
de los nuevos descubrimientos de los gases y, de alguna forma, tuvo la idea del
globo lleno de aire caliente.

Primero lo intentaron en casa. En noviembre de 1782, quemaron papel debajo de
una bolsa de seda con una abertura en la parte inferior. El aire del interior
de la bolsa se calentó y ésta se elevó hasta el techo. Repitieron el
experimento al aire libre, y la bolsa subió hasta una altura de 20 metros (es
decir, la altura de una casa de seis pisos). Lo intentaron con bolsas cada vez
más grandes y, finalmente, decidieron hacer una demostración pública.

El 5 de junio de 1783, en la plaza del mercado de su ciudad natal, los hermanos
emplearon una gran bolsa de lino, de 10,5 metros de diámetro, y la llenaron con
aire caliente. Habían invitado a todos los de la ciudad a presenciar el
experimento, y la multitud vio cómo el globo se elevaba 2 kilómetros en el aire
y permanecía en el mismo por espacio de diez minutos, durante los cuales
descendió con lentitud a medida que el aire contenido se enfriaba. Recorrió 2,5
kilómetros durante su descenso. Fue una demostración electrizante y creó una
auténtica sensación.

La noticia viajó hasta París, y allí un físico francés, Jacques Alexandre César
Charles (1746-1823), se enteró de ello. Al instante pensó en el hidrógeno.

El 27 de agosto de 1783, preparó una demostración propia en París. Empleó 225
kilogramos de ácido y 450 kilogramos de bolitas de hierro para producir el
hidrógeno. El gas brotó y entró por la abertura de la bolsa que había encima,
desplazando la mayor parte del aire. Cuando se soltó el globo, se elevó 1
kilómetro en el aire. El hidrógeno fue saliendo lentamente de la bolsa, pero
mientras perdía altura viajó 25 kilómetros en 45 minutos antes de alcanzar el
suelo.

Cuando lo hizo, los campesinos de los alrededores, que no sabían nada acerca de
globos, y que sólo podían suponer que se trataba de un vehículo que volaba a
través del aire (hoy lo llamaríamos un ovni) transportando invasores de algún
otro mundo, lo atacaron valientemente con guadañas y horcas y lo destruyeron.

Esos globos eran simples bolsas. No obstante, quedó claro que se podían colgar
pesos en los globos, que harían más lenta su ascensión y limitarían su altura,
pero que, de todos modos, no destruirían el efecto de flotabilidad. Los
Montgolfier, que ya tenían esto en mente, planearon la demostración más
sensacional ante la Corte francesa en Versalles.

El 19 de setiembre de 1783, emplearon un globo de un tamaño récord, pues tenía
un diámetro de 13 metros. Bajo el mismo había una cesta de mimbre en donde se
había colocado un gallo, un pato y una oveja. La cestilla también contenía un
brasero de metal donde se alojaba el combustible. Este se encendió y el globo
se llenó de aire caliente. Lo soltaron y se elevó en el aire ante los ojos de
una multitud de 300.000 personas (entre las que se incluían el rey y la reina
de Francia y Benjamín Franklin). El globo, con su carga de animales, recorrió
tres kilómetros antes de caer una vez consumido el combustible y enfriado su
contenido de aire. La primera persona presente cuando el globo aterrizó fue un
joven físico francés, Jean Francois Pilátre de Rozier (1756-1785).

Los animales no sufrieron el menor daño, y fueron los primeros seres vivos
transportados por el aire gracias a un mecanismo realizado por el hombre.

Pero si lo había hecho una oveja, ¿por qué no también un hombre? Este era
claramente el siguiente paso. El rey Luis XVI, que había quedado fascinado por
la demostración, se mostró inquieto acerca de los vuelos tripulados. Parecía
algo demasiado peligroso, y sugirió que se podía pedir a los criminales
condenados que se presentasen voluntarios para ello, con la promesa del perdón
si sobrevivían.

Sin embarco, Pilátre de Rozier pidió este honor. Él y un noble francés,
Francois Laurent, marqués de Arlandes, discutieron su caso con la reina Maria
Antonieta, la convencieron y ella convenció al rey.

El 20 de noviembre de 1783, Pilátre de Rozier y el marqués de Arlandes subieron
a una cesta de mimbre y ascendieron en un globo lleno de aire caliente. Fueron
transportados 8 kilómetros en 23 minutos, y aterrizaron sanos y salvos.

Ellos fueron los primeros aeronautas,120 años antes de los hermanos Wright y
108 años antes de Lilienthal.

Pilátre de Rozier fue otra vez el primero en realizar algo notable un año y
medio después.

El 7 de enero de 1785, se cruzó el canal de la Mancha por primera vez en globo.
A bordo iban un francés Jean Pierre Francois Blanchard (1750-1809), que fue el
inventor del paracaídas, y un norteamericano, John Jeffries (1744-1819).

El 15 de junio de 1785, Pilátre de Rozier y otro francés, Jules Romain,
trataron de repetir la proeza en sentido contrario. Sin embargo, el fuego
empleado para calentar el aire del globo prendió en el tejido del globo,
incendiándolo, y los dos aeronautas murieron tras caer desde 1.500 metros de
altura.

Así que el primer aeronauta, como una especie de Icaro real, murió en el primer
desastre aeronáutico.





Sexta parte





CRONOLOGÍA





XVI. LOS DIFERENTES AÑOS DEL TIEMPO





Una anécdota más acerca de mi operación de bypass y no volveré a hablar de
ella. (Por lo menos, lo intentaré.)

Cuando me enteré de que, durante un período de tiempo, estaría conectado a una
máquina corazón-pulmón, me inquietaba el hecho de si el anestesista tendría el
debido cuidado de que mi cerebro, en particular, recibiese un abundante
suministro de oxígeno. El cerebro consume una cuarta parte del oxígeno que usa
el cuerpo, y me pareció que si le faltaba, aunque fuese por poco tiempo, podría
resultar dañado.

Yo no deseaba que sufriera ningún daño, ni siquiera el más marginal. Había
logrado una vida muy agradable aprovechando mi excelentemente aguzado cerebro,
y no deseaba que éste se embotase.

Expresé mis temores al internista de mi familia, el bueno de Paul, el médico
más atento del mundo.

—No te preocupes, Isaac —me dijo. —Cuidaré de que todos comprendan la
situación, y yo mismo haré pruebas.

Y así lo hizo. No lo recuerdo, pero me contó lo sucedido. Aunque realmente no
recobré del todo el conocimiento hasta las diez de la mañana siguiente, me
revolví de vez en cuando ya desde los primeros momentos, de modo que hubo
conatos de respuesta, seguidos de un regreso al semicoma provocado por la
anestesia.

A las diez de la mañana, unas horas después de que se terminara la operación,
mis ojos al fin se abrieron y Paul estaba allí de pie.

—Hola, Paul... —susurré roncamente, según me contó. Se inclinó hacia mí.

—Hola, Isaac. Inventa una quintilla que hable de mí.

Parpadeé un par de veces, susurré:

Una vez había un viejo doctor llamado Pablito

Con un pene sobremanera pequeñito...

A lo cual, Paul respondió con austeridad:

—No sigas. Isaac. Estás bien.

Cuando me lo contó al día siguiente, quedé en extremo aliviado, puesto que ello
significaba que podría continuar escribiendo. Y aquí está...



Probablemente, se habrán encontrado varias veces con un pequeño instrumento
pedagógico que permite que la historia de la Tierra se comprima en un año, y
luego indique en qué momento del año han tenido lugar los distintos
acontecimientos ocurridos en la historia de la Tierra. Esto da una visión más
fácil de captar del paso del tiempo y de la relativa posición cronológica de
los diferentes fragmentos y aspectos del mismo.

Naturalmente, se descubre que la Humanidad nació bastante tarde, el último día
del año, y se comprende nuestra insignificancia en la cronología del planeta.

Esto no es una peculiaridad sólo de la historia de la Tierra, sino de todas las
facetas de cualquier clase de historia. Siempre vemos las cosas cercanas a
nosotros con gran detalle, mientras que cuanto más lejos miramos, más borrosas
vemos las cosas y con menos interés. Los tiempos contemporáneos siempre parecen
muy largos y detallados, mientras que los lejanos tiempos pasados nos parecen
breves y poco interesantes.

Por ejemplo, cojamos una historia escolar de los Estados Unidos que trate del
periodo de tiempo que va desde el viaje de Colón, en 1492 hasta la actualidad.
Dividamos el libro en la Declaración de Independencia y observemos cuántas
páginas se dedican a los períodos de exploraciones y coloniales, y cuántas
páginas se destinan al periodo de los Estados Unidos como nación independiente.
No tengo un libro así para comprobarlo, pero supongo que se dividiría en una
proporción de 1 a 6.

Esto parece correcto por un buen número de razones y no lo discuto, pero el
escolar medio (o el adulto, pongamos por caso) que hojee un libro así, no
podría evitar el tener la vaga noción que la división estrictamente cronológica
es similar: que los Estados Unidos como nación independiente ha durado mucho
más que el relativamente breve período colonial que le precedió.

Para ver cuál era realmente la situación, empleemos el truco de comprimir un
período de tiempo en un año arbitrario, y comprimamos también la cronología,
sin distorsión, en los días de ese año.

Así, el primer asentamiento permanente de los ingleses en lo que ahora es el
territorio de los Estados Unidos tuvo lugar en Jamestown, Virginia, el 14 de
mayo de 1607. Llamémosle a eso Minuto del Nuevo Año: 12:01,1 de enero. Llamemos
al momento actual Minuto del Viejo Año: 11:59, 31 de diciembre. El tiempo
transcurrido desde el establecimiento de Jamestown hasta ahora (en el momento
en que escribo) es de 377 años. Esto significa que cada día de nuestro «Año
Estados Unidos» es igual a 1,03 años reales.





1. AÑO DE ESTADOS UNIDOS





Si estudian esta tabla, puede sorprenderles el que durante casi la mitad del
tiempo en que los descendientes de los ingleses vivieron en lo que es ahora
territorio estadounidense no existieran los Estados Unidos. No fue hasta casi
la mitad del año cuando los Estados Unidos fueron legalmente independientes por
un tratado con Gran Bretaña.

Sin embargo, lo que encuentro más sorprendente es que cuando llegó el día V-J
aún no era diciembre. A fin de cuentas, yo recuerdo el día V-J como si hubiese
sido ayer. ¿Cómo puede haber pasado todo un Mes de Estados Unidos desde
entonces? Bueno, así es. Han pasado ahora casi treinta y nueve años desde el
día V-J, y esto es casi una quinta parte de la duración total de la
independencia estadounidense.

Casi me hace sentirme viejo.



Podemos hacer esto en una escala cada vez mayor. Supongamos, por ejemplo, que
comenzamos con el desembarco de Colón en San Salvador el 12 de octubre de 1492.

Esto incluiría toda la extensión de tiempo en la que Norteamérica fue
penetrada, explorada y ocupada por las potencias europeas. Si lo comprimimos en
el «Año de Norteamérica», descubrimos que abarcamos un período igual a 492
años, de modo que el Día de Norteamérica tiene una duración de 1,34 años reales.





2. EL AÑO DE NORTEAMÉRICA





Obsérvese que, durante el primer tercio de todo el tiempo en que los europeos
rondaron por nuestras costas y por el interior del continente norteamericano,
esos europeos eran casi todos españoles. No fue hasta el 25 de marzo cuando los
ingleses llegaron a Norteamérica para quedarse.

Y durante los 5/9 del tiempo en que los europeos de cualquier clase estuvieron
en Norteamérica, no existían los Estados Unidos.



Naturalmente, hubo Historia antes de los Estados Unidos e incluso antes de la
Norteamérica europea. Muchísima. La Historia de este tipo se suele dividir en
Edad Antigua, Edad Media (o Medievo) y Edad Moderna. Sospecho que la mayoría de
la gente supone que esos tres períodos tienen aproximadamente la misma
duración. Todo lo más, podrían imaginar que los tiempos modernos constituyen el
periodo más largo, porque es el que ocupa más espacio en nuestros libros de
Historia.

Veamos, entonces. La Historia comienza con la escritura. La escritura hace
posible registrar crónicas, dar nombres, fechas, lugares. Sin la escritura,
debemos inferir las cosas a partir de los objetos, y nunca podemos determinar
el tipo de detalle que hace de la Historia lo que es.

Según sabemos ahora, la primera escritura la inventaron los sumerios,
posiblemente ya en 3200 a. de J.C. Por lo tanto, empecemos el «Año de la
Historia» con el 3200 a. de J.C. como 1 de enero. Eso nos da una extensión de
5,l84 años hasta la actualidad, por lo que cada Día de la Historia equivale a
14,2 años reales.





3. AÑO DE LA HISTORIA





Observen que, cuando ya ha pasado la primera mitad del Año de la Historia, los
grandes días de Grecia aún no han empezado. Nosotros, al igual que los antiguos
griegos, somos un producto de la segunda mitad de la Historia.

Toda la primera parte del Año de la Historia está dominada por los reinos
asiáticos. Grecia ocupa el Mes de la Historia de julio. Roma el de agosto. El
70% del Año de la Historia ha transcurrido ya antes de que la Edad Antigua
llegue a su fin. En otras palabras, los tiempos antiguos (aunque se les conceda
menos atención en los libros modernos) duran dos veces más que los tiempos
medievales y la edad moderna juntos.

Mientras la Edad Antigua dura 8,5 Meses de la Historia, la Edad Media dura sólo
2 Meses de la Historia y la Edad Moderna sólo ha durado 1 Mes de la Historia.

En el Año de la Historia menciono la Revolución inglesa de 1688, la Revolución
americana de 1776 y la Revolución francesa de 1789. Cada una de ellas
contribuyó a la norma moderna del liberalismo y de los derechos humanos. Pero
observen que no se estableció hasta la segunda mitad de diciembre del Año de la
Historia, y que incluso así sólo en una pequeña parte del mundo. y aún
precariamente.

Uno no puede más que suspirar.



En realidad, la civilización es anterior a la escritura. La palabra
«civilización» procede de la voz latina que designa «ciudadano», es decir,
«habitante de la ciudad». Datemos, pues, la civilización desde la fundación de
las primeras pequeñas ciudades (como, por ejemplo, Jericó, en Palestina).

El principio de la civilización puede establecerse (un poco arbitrariamente)
hacia el año 8.000 a. de J.C., o hacia el 10.000 A. P. («Antes del Presente»).
Hacia aquella época, grupos de personas en el Asia occidental aprendieron a
domesticar plantas y animales. Pasaron de ser recolectores de alimentos a
agricultores y ganaderos. Esto permitió una mayor concentración de gente en un
área dada, y condujo de modo inevitable a la fundación de ciudades.

Si comenzamos «El Año de la Civilización» en 8000 a. de J.C., esto nos da una
duración de 9.984 años y hace que cada Día de la Civilización tenga 27,35 años
reales de duración.





4. EL AÑO DE LA CIVILIZACIÓN





La fecha tradicional de la creación bíblica a la que alude el Año de la
civilización es 4004 a. de J.C., tal y como determinó el arzobispo Ussher, y
aún aparece en la mayoría de las ediciones de la Biblia del rey Jacobo. Sin
embargo, en aquel tiempo la Civilización ya había durado las dos quintas partes
de su extensión total.

Más de la mitad del período de civilización transcurrió antes que se
construyera la Gran Pirámide. Creemos que el lapso de tiempo desde nuestras
vidas hasta las pirámides constituye algo enorme, pero antes había transcurrido
un periodo aún mayor de civilización sin pirámides. No sólo era una
civilización sin pirámides, sino completamente analfabeta.

En realidad, esta primera mitad de la civilización, sin escritura ni pirámides,
era imperfecta y rudimentaria según nuestras pautas y existió sólo en una
pequeña parte del mundo, pero no debemos despreciarla. Somos lo que somos hoy
porque nos hemos basado en los logros de esos analfabetos. Una valoración
imparcial de lo que hicieron nos llevaría a la conclusión de que ellos tuvieron
que realizar una tarea mucho más dura que la nuestra, y que lograron mucho más
si tenemos en cuenta con qué tuvieron que trabajar.



En realidad, incluso antes de que hubiese ciudades y agricultura, los seres
humanos efectuaron grandes progresos y, de modo notable, mostraron que eran
grandes artistas e ingeniosos cazadores y fabricantes de utensilios. El Homo
sapiens sapiens («el hombre moderno») demostró a través de su existencia mucho
ingenio y adaptabilidad, y es sumamente arbitrario definir la civilización en
términos de un avance particular como la construcción de ciudades. La historia
del «hombre moderno» constituye un avance firme y continuado.

Así pues, ¿qué podemos decir del «Año Humano»? Supongamos que empezamos en el
año 35.000 a. de J.C. (37.000 A. P.), época en la que el «hombre moderno» era
el único homínido que vivía en la Tierra, aunque sólo en los continentes de
África y Eurasia. La duración total de 36.984 años significa que cada Día
Humano tiene una duración real de 101,3 años.





5.EL AÑO HUMANO





Más de la mitad de la duración del Año Humano transcurrió antes de que
apareciese el arte rupestre, y pasaron casi tres cuartas partes de dicha
duración antes de que comenzase lo que llamamos civilización. Sólo la última
cuarta parte de la historia del «hombre moderno» ha mostrado civilización en
alguna parte.

Los Estados Unidos han existido durante sólo dos Días Humanos.



Naturalmente, existieron homínidos antes del hombre moderno. En realidad, el
Homo sapiens existió antes del hombre moderno. Los llamados hombres de
Neanderthal (Homo sapiens neanderthalensis) fueron de la misma especie que
nosotros y pudieron (y presumiblemente lo hicieron) cruzarse con nuestros
antepasados. Sus genes pueden hallarse entre nosotros.

Y antes de los Neanderthales existieron otras especies más pequeñas, con menor
cerebro que el género Homo, y antes que ellos hubo criaturas con cerebros aún
más pequeños que no eran Homo, pero que aún pertenecían a los homínidos, y que
caminaban erguidos, poseían manos como las nuestras y, en general, estaban más
cercanos de nosotros en detalles anatómicos que de los monos.

Los primeros homínidos de los que podemos estar seguros fueron los
australopitecinos, que vivieron en el sudeste y este de Africa, no más grandes
que los niños de nuestra propia especie, pero que caminaban erguidos como
nosotros hacemos y que tenían las manos libres para explorar y manipular el
Universo.

Puede que hicieran su aparición hace unos 4.000.000 de años y, aunque se habla
de otros homínidos aún anteriores, comenzaré «el Año Homínido» en 4.000.000 a.
de J.C. Esto significaría que cada Día Homínido tendría una duración de 10.920
años reales.





6. EL AÑO HOMÍNIDO





Durante la primera mitad del Año Homínido, los australopitecinos fueron los
únicos homínidos existentes. Sólo después de haber transcurrido el 95% del Año
Homínido hizo su aparición el Homo sapiens. El «hombre moderno» es una criatura
sólo de la última semana. y toda la civilización se apretuja en el último día.

Inmediatamente, durante los siete octavos del tiempo en que los homínidos
existieron sobre la Tierra, lo hicieron sin emplear el fuego. El desarrollo de
este uso fue el mayor logro de los tiempos del presapiens. Este fue un logro
del Homo erectus, pues se han encontrado restos de fogatas de campamento en las
cavernas que albergaron los huesos del hombre de Pekín.



Los homínidos no son los únicos organismos que han dejado restos fósiles a
través de los cuales podemos rastrear la historia paleontológica. Antes de los
homínidos existieron unos primates anteriores y otros mamíferos antes de ellos,
y también no mamíferos e invertebrados. Un rico registro de fósiles se remonta
unos 600.000.000 de años.

Establezcamos el «Año Fósil» y comencemos en el 600.000.000 a. de J.C. Cada Día
Fósil tendría así una duración de 1.644.000 años reales.





7. EL AÑO FÓSIL





Como ven, en el primer cuarto del Año Fósil no existió vida terrestre, y no
hubo vertebrados terrestres durante las tres octavas partes del Año Fósil.

Los reptiles aparecieron sólo cuando había transcurrido más de la mitad del Año
Fósil. y los dinosaurios dominaron el otoño Fósil. Los homínidos son criaturas
de los cuatro últimos Días

Fósiles, el hombre moderno pertenece a los últimos 45 Minutos Fósiles, y toda
la historia se amontona en los últimos 10 Minutos Fósiles.



Pero hubo vida antes de los fósiles. La única razón de que los fósiles
apareciesen tan repentinamente hace 600.000.000 de años es que hubo un anterior
florecimiento evolutivo que produjo conchas y otras partes duras de unos
organismos cada vez más complejos. y fueron esas partes las que se fosilizaron
con facilidad.

Antes de esos animales complejos existieron otros organismos pequeños, de
cuerpo blando, que no se fosilizaban bien, y antes de ellos, organismos
microscópicos que pudieron dejar sólo los rastros más inapreciables.

Sin embargo, se han encontrado esos rastros, y los paleontólogos han seguido la
vida remontándose casi hasta el principio de la existencia de la Tierra.

Por lo tanto, vamos a establecer el «Año Terrestre» y comenzarlo hace
4.600.000.000 de años, época en la que la Tierra adoptó, más o menos, su forma
actual (al igual que el Sol, y todo el Sistema Solar en general). Cada Día
Terrestre tiene, pues, una duración de 12.600.000 años reales.





8. EL AÑO TERRESTRE





Como ven, si tomamos la Tierra como un todo, ésta pasó tal vez una cuarta parte
de su existencia como un Globo carente de vida. Durante los nueve décimos de su
existencia. la tierra permaneció sin vida. Testimonio de la dificultad de la
tierra árida como vehículo para la vida es el hecho de que esa vida terrestre
sea un producto de sólo el último Mes Terrestre.

Los dinosaurios son criaturas únicamente de mediados de diciembre en la Tierra,
y la duración de la existencia homínida es sólo cuestión de las 7 1/2 últimas
Horas Terrestres. El hombre moderno ha estado sobre la Tierra sólo durante los
5 3/4 Minutos Terrestres, y la Historia es algo más o menos sólo de los últimos
35 Segundos Terrestres.

Pero aún no hemos acabado. Dedicaré el último capítulo a lapsos de tiempo aún
mayores.





XVII. LOS DIFERENTES AÑOS DEL UNIVERSO





Voy a contarles la única vez en que, durante una cálida amistad de cuarenta y
cinco años con mi colega escritor Lester del Rey, le dejé cortado.

No resulta fácil. Nunca permite ningún ataque verbal sin un contraataque
inmediato, siempre encuentra la réplica apropiada, y jamás vacila en darla,
excepto en mi caso, aquella vez.

Él, yo y otros dos amigos íbamos en un taxi, y por alguna razón yo estaba
hablando de mi patriarcal padre y de las incontables amonestaciones morales que
me hacía, puesto que había creído siempre que sólo sometiéndome eternamente, en
mi impresionable infancia, a las enseñanzas de los grandes sabios judíos,
podría impedir que me extraviara en los vericuetos de la inmoralidad y del
vicio.

—Recuerda, Isaac —me decía, con aquel sonsonete melodioso con que se inculcaban
las lecciones morales judías —que si vas por ahí con bums (esta palabra era
siempre pronunciada con gran énfasis, para indicar el más inenarrable desprecio
y revulsión moral) puedes pensar que los cambiarás y convertirás en personas
decentes, pero no será así. ¡No! ¡Nunca! En vez de ello, si vas con bums, serán
ellos los que te convertirán a ti en un bum.

A lo cual interpuso Lester al instante:

—Entonces ¿por qué sigues yendo aún con bums, Isaac?

Y yo respondí sin la menor vacilación:

—Porque te quiero, Lester, ésa es la razón.

Esa fue la primera y única vez, en mi larga experiencia con él, que Lester
estalló en carcajadas, tan fuertes que se vio incapaz de responder. Y lo que es
más, tuve a los otros dos tipos del taxi (que, naturalmente, también se reían)
como testigos.

Pensé en esto hace unos días. cuando estaba siendo entrevistado por alguien que
me preguntó:

—Doctor Asimov, de todos los diferentes tipos de escritos que usted hace ¿con
cuál disfruta usted más?

Ya me habían preguntado esto muchas veces anteriormente (los entrevistadores me
lo han preguntado todo muchísimas veces), así que no tuve que pensar lo más
mínimo. Respondí:

—Con lo que disfruto más es con mis ensayos mensuales para la revista Fantasy
and Science Fiction... Hace más de un cuarto de siglo que los escribo sin haber
fallado una sola vez.

El entrevistador pareció dudar.

—¿Y eso es porque le pagan bien?

No respondí. En realidad el precio de esos ensayos es más bajo que el de
cualquier otra cosa que escriba, pero los haría por nada, si tuviese que
hacerlo.

—¿Pero por qué?

Y la respuesta llegó sin el menor titubeo por mi parte:

—Porque los quiero, señor, ésa es la razón.

Y así es. Tal vez exista por ahí algún Gentil Lector que, en secreto, crea que
nadie en el mundo disfruta más con esos ensayos que él (o ella). En tal caso,
el Gentil Lector(a) está equivocado(a). Soy yo el que más disfruto.

Dicho esto, continuaremos en el punto en que nos quedamos en el capítulo
anterior.



En el capítulo precedente, elegí varios espacios de tiempo significativos
—Historia de los Estados Unidos, Historia de la civilización, Historia de los
Homínidos, etc., comprimiéndolos en un año y señalando los acontecimientos más
importantes (sin distorsión relativa) a lo largo de todo el año. Eso nos daba,
con más exactitud que el modo corriente de tratar con las fechas, lo que me
parecía una noción dramática de lo que había sucedido.

La última compresión que llevé a cabo fue la de la historia de 4,6 mil millones
de años del planeta, es decir, de la Tierra, formando de este modo el «Año
Terrestre». Esto mostraba, por ejemplo, que si la Tierra había tomado su forma
actual al principio del 1 de enero, el registro fósil en los tiempos de las
rocas cámbricas no apareció hasta el 12 de noviembre, los dinosaurios se
extinguieron el 26 de diciembre y los primeros homínidos aparecieron a las
17.30 del 31 de diciembre, mientras que nuestros registros históricos no
cubrían más que los últimos cuarenta y cinco segundos del Año Terrestre.

¿Hay algo que podamos hacer para cubrir un lapso de tiempo aún mayor?

Obviamente todo el Universo tuvo un principio. en el instante de la gran
explosión (Big Bang). El momento en que ocurrió ese Big Bang no puede
determinarse con tanta facilidad o tan exactamente como el momento en que la
Tierra y el resto del Sistema Solar tomaron su forma actual, y existe una
controversia entre los astrónomos al respecto. Sin embargo, 15 mil millones de
años es una cifra plausible y es la que, hasta que exista alguna buena prueba
de lo contrario, empleo por lo general en mis escritos.

Así pues, podemos tomar esa fecha de l5.000.000.000 de años A. P. (antes del
presente) como el inicio del Universo, y lo llamaré Minuto del Año Nuevo: el
momento exacto de la medianoche que desemboca en el 1 de enero. El momento
actual es el instante preciso de la medianoche que pone fin al siguiente 31 de
diciembre. Para cubrir todo ese espacio vital del Universo en un solo e
imaginario «Año del Universo», cada día de ese año imaginario (cada «Día del
Universo»), debe tener una extensión de 41.000.000 de años auténticos.

En realidad, un número enorme de acontecimientos vitalmente importantes que
moldearon la naturaleza del Universo tuvo lugar en los primeros segundos
después del Big Bang, incluso en los primeros microsegundos después del Big
Bang. Como resultado de ello, sería inevitable pasar por alto muchas cosas si
tratásemos de describirlo todo en un año medido de la forma aritmética
Corriente. Lo que se necesita realmente es una escala logarítmica, e hice algo
así en mi obra Contando los eones.

No obstante, seguiré utilizando una escala aritmética ordinaria para el Año del
Universo, como he hecho en los diversos «años» del capítulo precedente. y
mostraré lo que me sea posible de esta manera. (Proseguiré la numeración de las
diferentes tablas donde la he dejado en el capítulo precedente.)





9. EL AÑO DEL UNIVERSO





Como ven, el Universo atravesó la primera octava parte de su historia sin
nuestra galaxia, y tal vez sin ninguna clase de galaxia. (Inicialmente, esto
depende de cuál de las versiones actuales del Big Bang sea la exacta. Algunas
recientes postulan un «universo inflacionario», en el que, después del Big
Bang, tuvo lugar una repentina e increíblemente rápida expansión, y esto puede
significar que las galaxias existieron casi desde el principio. Por desgracia,
no estoy seguro. Aún no he conseguido entender ese Universo inflacionario.)

En cualquier caso, no hay duda de que el Universo existió durante largo tiempo,
probablemente los siete décimos de su existencia, sin nuestro Sistema Solar. Si
es cierto, como algunos mantienen (aunque yo no acabo de creérmelo), que la
vida en la Tierra es la única vida en el Universo, en ese caso el Universo pasó
las tres cuartas partes de su existencia como una vasta esterilidad, carente
incluso de la vida más simple. (¿Cómo puede ser esto creíble?)

No obstante, lo que más me sorprende es que la vasta duración no reduzca algo
tan insignificante como la historia humana a la inconmensurabilidad. ¡En
absoluto! El período durante el cual los seres humanos han escrito crónicas de
alguna clase u otra ocupa, en realidad, diez Segundos del Universo.
(Naturalmente, los diez últimos.)

Podría pensarse que, al considerar la vida del Universo, he agotado todas las
tablas útiles. ¿A qué puedo apelar que sea más extenso y mayor que la vida
total en todo el Universo?

Verán, la extensión no lo es todo. Podemos buscar algo útil en otras
direcciones. Por ejemplo...

El Sol, con su familia de planetas, viaja constantemente por el centro de la
galaxia de la Vía Láctea en una órbita casi circular, y completa una revolución
en unos 200.000.000 de años.

Supongamos que damos por sentado que la órbita del Sol ha sido estable, que no
se ha visto seriamente afectada por perturbaciones estelares durante su
existencia. No tenemos ninguna prueba de este supuesto, pero tampoco existe
razón para suponer que la órbita haya sufrido graves cambios en algún momento.
Y si no existen pruebas de lo uno ni de lo otro, parece acertado quedamos con
la suposición razonable más simple, y optaremos por la estabilidad.

En ese caso, significaría que en los 4.600.000.000 de años de la historia del
Sistema Solar ha habido tiempo para que el Sol y los planetas hayan orbitado en
torno del centro galáctico 23 veces.

A continuación, imaginémonos a un observador en un punto fijo de la galaxia (en
relación con su centro), desde el que viese al Sol encenderse y empezar a
brillar exactamente en el momento de pasar delante de él. ¿Qué vería si
permaneciese allí y estudiase la Tierra cada vez que el Sol regresase después
de un intervalo de 200.000.000 de años?

Si comprimimos la vida del Sistema Solar en un solo «Año del Sistema Solar»,
cada órbita del Sistema Solar en torno del centro galáctico duraría 15,87 días
del Sistema Solar, y cada uno de esos días representaría 548.000 años reales.
Podríamos preparar una tabla que dé a la formación de la Tierra el número 0, y
luego numerar cada giro a lo largo de su senda orbital del 1 al 23. El
resultado sería el siguiente:





10. AÑO DEL SISTEMA SOLAR





Déjenme explicarles brevemente algunos puntos. Por «evolución química» me
refiero a la construcción gradual de moléculas complejas a partir de otras
simples, a expensas de varias fuentes de energía tales como rayos solares
ultravioleta, relámpagos y calor interior de la Tierra.

Los procariotas (a los que he mencionado brevemente en el capítulo anterior)
son células simples considerablemente más pequeñas que las de nuestros cuerpos,
y que carecen de complejidad interna. Carecen, por ejemplo, de un núcleo, y su
equipo genético está distribuido de modo general por la célula. Los procariotas
que aún florecen hoy son bacterias y algas cianofíceas. Ambas son muy
parecidas, con la diferencia de que las cianofíceas (que, dicho sea de paso, no
son realmente algas) pueden fotosintetizar, y las bacterias no.

Los eucariotas son células mucho más grandes, con una considerable organización
interna, incluyendo (en particular) un núcleo. «Eucariota» deriva de una voz
griega y significa «buen núcleo», mientras que procariota significa «antes del
núcleo». Los protozoos y las verdaderas algas son células eucariotas simples,
animales y plantas respectivamente. Todos los organismos multicelulares que hay
en la Tierra en la actualidad (incluyéndonos a nosotros mismos, como es
natural) están formados por células eucariotas.

Los procariotas multicelulares son poco más que colonias de bacterias, y
constituyeron un callejón sin salida. Si las bacterias y las cianofíceas
sobreviven aún hoy, a pesar de la competencia, es porque ocupan toda clase de
nichos que nada más puede o quiere ocupar. y porque son increíblemente fecundas.

Al mirar la Tierra con intervalos fijos, se puede hacer uno una buena idea de
la aceleración del índice de evolución. Durante las primeras cinco vueltas en
torno del centro galáctico, la Tierra carecía de vida. Durante las siguientes
doce vueltas, no llevaba encima nada más avanzado que las células procariotas.

No fue hasta finalizada la decimoctava vuelta, momento en el que ya se habían
alcanzado las tres cuartas partes de la edad actual de la Tierra, cuando
comenzaron a desarrollarse células procariotas.

Pero luego las cosas se aceleraron. A la vuelta siguiente conseguimos el
potencial de un buen registro fósil para ayudarnos. gracias a la aparición de
organismos multicelulares complejos con partes que se fosilizaban con
facilidad. Otra vuelta y se colonizó la tierra. Otra más. y aparecieron los
dinosaurios.

Y luego se produjo toda la dramática historia de la ascensión y caída de los
dinosaurios, el ascenso de los mamíferos y la llegada de los homínidos y del
hombre moderno, todo ello comprimido en la vuelta más reciente del Sistema
Solar en torno del centro galáctico.

Sólo cabe preguntarnos qué podrá verse en la siguiente vuelta, dentro de
200.000.000 de años.



Hasta ahora hemos considerado la evolución de la Tierra desde un punto de vista
del Universo, hablando del Big Bang y de revoluciones galácticas, y ha llegado
el momento de justificar el título de este ensayo, abandonando la Tierra, y
vamos a considerar la evolución de las estrellas —el Sol en particular, —en vez
de la vida terrestre.

Hace casi cinco mil millones de años, el Sistema Solar existía como una gran
nube de polvo y gas, una nube que tal vez había existido desde que la galaxia
se formase, miles de millones de años antes. Algún impulso tal vez la explosión
de una supernova cercana hizo contraerse la nube de gases del Sistema Solar.
Como resultado de ello su intensidad gravitatoria creció, y la contracción se
activó aún más. Finalmente, al cabo de diez o veinte millones de años, el
centro de la nube se había contraído hasta una densidad y temperatura
suficientes para iniciar la fusión del hidrógeno. El centro de la condensación
«se encendió» y se convirtió en una estrella, aunque en las regiones exteriores
unos cuerpos más pequeños y, por tanto, con superficies frías (los planetas) se
estaban formando.

Después de esto, el Sol mantuvo su producción de energía mediante una constante
fusión del hidrógeno, que constituía con mucho la mayor parte de su contenido,
en un helio en cierta medida más complejo. El helio, más denso que el
hidrógeno, se reunió en el centro solar y este núcleo de helio se fue haciendo
cada vez más grande, mientras se formaba más helio y se vertía para unirse a él.

A medida que el núcleo de helio adquiría más masa. su propia intensidad
gravitatoria le hizo condensarse en una mayor densidad y temperatura. Para
cuando el Sol haya usado el 10 % de su hidrógeno original total algo que aún
tardará en suceder varios miles de millones de años, el núcleo de helio se
habrá hecho lo suficientemente denso y caliente para que tenga lugar la fusión
del helio en carbono.

Entre el momento en que se inició la fusión del hidrógeno y el momento en que
empezó la fusión del helio, la producción de radiación del Sol fue
razonablemente constante, como ocurriría con cualquier estrella. Durante este
período de tiempo, el Sol, o cualquier otra estrella, se dice que permanece en
la «secuencia principal».

En el caso del Sol, se estima que permanecerá en su secuencia principal durante
10 mil millones de años.

Una vez el helio comienza a arder, el núcleo de helio se calienta tremendamente
y se expande. También calienta la envoltura de hidrógeno exterior. que asimismo
se expande. El Sol se hace cada vez más grande y su superficie más exterior en
expansión se hace gradualmente más fría hasta el simple calor rojo, aunque la
superficie en expansión le proporciona un calor total que aumenta
constantemente. a pesar del enfriamiento de las partes.

El Sol alcanzaría su volumen máximo como «gigante roja» tal vez 1.5 mil
millones de años después de haber empezado a arder el helio, por lo que su
existencia total desde la ignición hasta ser gigante roja sería de 11,5 mil
millones de años. (Naturalmente. el Sol continuará existiendo y desarrollándose
después de haberse convertido en una gigante roja totalmente formada, pero en
este capítulo no iremos más allá.)

Otras estrellas experimentan los mismos cambios, aunque no necesariamente con
la misma velocidad. Las estrellas con más masa que el Sol lo hacen todo con
mayor rapidez. Al tener más masa, tienen un campo gravitatorio más intenso y se
contraen más rápidamente. se hacen más densas y más calientes también más
rápidamente, y llegan antes a la ignición. Después de ésta, funden su hidrógeno
con mayor rapidez, y llegan al estadio de gigante roja también con más rapidez
y. en realidad, se convierten en una gigante roja más grande. Cuanto más masa
tiene una estrella, más hidrógeno contiene para la fusión, pero el índice de
fusión aumenta considerablemente más deprisa que la masa de la estrella, por lo
que cuanto mayor sea la estrella, más breve será la permanencia en la secuencia
principal.

Una estrella con tres veces más masa que el Sol, por ejemplo, completará su
contracción en tal vez 3 millones de años, en vez de los 20 millones que parece
que ha tardado el Sol. Permanecerá en la secuencia principal sólo durante una
cuarta parte de mil millones de años y será una gigante roja plenamente
desarrollada unos cuantos millones de años después de eso. Así pues, supongamos
que preparamos un «Año Solar» en el que la existencia del Sol, desde la
ignición hasta el pleno desarrollo de estrella roja, se comprime en un año.
Dado que el Año Solar tendría una duración de 11,5 mil millones de años reales,
cada Día Solar comprendería 31.500.000 años reales. De ese modo podemos
elaborar una tabla de la vida de las estrellas con más masa.





11. EL AÑO SOLAR





Como ven, el Sol está todavía en su vigorosa mediana edad, sin que haya
transcurrido la mitad de su vida útil. No hay ninguna necesidad de preocuparse
por el hecho de que, inexorablemente, después de que comience a arder el helio,
el Sol se hará cada vez más caliente, con lo que la vida en la Tierra será
imposible. En realidad, cuando el Sol sea una gigante roja desarrollada se
expandirá hasta estar lo bastante cerca de la Tierra para calentarla hasta
convertirla en cenizas. Incluso puede que llegue a absorberla.

Sin embargo, deberán transcurrir al menos cinco mil o seis mil millones de años
antes de que ese calor realmente se produzca y habría que tener un optimismo
incurable para suponer que no habremos conseguido encontrar algo diferente como
medio de eliminarnos nosotros mismos. No tendremos que esperar a que el Sol nos
abrase.

Aun cuando sobrevivamos, para el tiempo en que el helio comience a arder,
habremos evolucionado hacia algo del todo irreconocible como humano (aunque
siempre podemos, de algún modo, confiar en que sea algo mejor que lo humano).

Si nosotros, o una especie sucesora, existimos cuando el Sol se encuentre en la
ignición del helio, es inconcebible que nuestro nivel técnico no haya alcanzado
el punto en que nos permita abandonar la Tierra con facilidad y retirarnos al
sistema extrasolar, donde el nuevo y enorme calor total del Sol será algo
beneficioso en lugar de todo lo contrario. En realidad, podemos estar seguros
de que, mucho antes de que el calor del Sol se convierta en un problema, la
Humanidad o sus descendientes habrán trasladado los escenarios de su actividad
a planetas que giren en torno a otras estrellas más jóvenes, o a mundos
artificiales independientes.

A propósito, se les podría ocurrir que, si una estrella como Beta del Centauro
se abre camino a través de su secuencia principal en sólo cinco Horas Solares y
media y desaparece, por así decirlo, antes de la salida del Sol del primer día
del año, ¿cómo puede Beta del Centauro brillar serenamente en los cielos del
hemisferio meridional exactamente ahora mismo?

Ah... La Tabla 11 se basa en la suposición de que todo un grupo de estrellas de
diversas masas (pero todas con más masa que el Sol) entrara en ignición al
mismo tiempo. Este no es el caso de las estrellas reales de la galaxia en la
que nos encontramos. Beta del Centauro tiene una vida total en la secuencia
principal de no más de 10 millones de años. y brilla ahora en el firmamento
porque se formó hace menos de 10 millones de años.

Todas las estrellas con más masa que el Sol son unos relativos recién llegados
a escena. De otro modo, todas se habrían convertido ya en gigantes rojas y se
encontrarían en la actualidad en estado de colapso. Numerosas galaxias en
espiral (incluida la Vía Láctea) están aún sembradas de nubes de polvo y gas, y
éstas pueden, en las condiciones apropiadas, condensarse en muchedumbres de
estrellas. Existen extensiones pequeñas e intensamente oscuras, llamadas
«glóbulos Bok» (por el astrónomo Bart J. Bok, que fue el primero en llamar la
atención sobre ellas. y pueden ser estrellas que se encuentren en proceso de
formación mientras las observamos.



Igual que existen estrellas con más masa que el Sol, y que, por lo tanto, son
más grandes, más luminosas, más calientes y de vida más breve, también existen
estrellas con menos masa que el Sol y que, por tanto, son más pequeñas, menos
luminosas y de vida más larga.

Las estrellas pequeñas no salpican mucho el firmamento, nos damos mucha más
cuenta de las más grandes y brillantes. Sin embargo, en el caso de las
estrellas, como en casi cualquier grupo grande de sustancias similares, ya sean
galaxias, guijarros o insectos, las más pequeñas son más numerosas que las más
grandes. Por cada estrella con tanta masa como, o incluso con más masa que el
Sol, existen seis o siete estrellas que tienen menos masa que el Sol.

Las estrellas más pequeñas son lo suficientemente frías para estar sólo al rojo
vivo. A diferencia de las gigantes rojas, las estrellas pequeñas no tienen el
suficiente tamaño para compensar la oscuridad de sus partes. Las estrellas
pequeñas son, por tanto, apagadas, tan apagadas que, por cerca que se
encuentren de nosotros, incluso en este caso sólo pueden verse con telescopio.

Esas estrellas pequeñas se denominan enanas rojas. y son tan tacañas con su
energía. que duran sorprendentemente mucho tiempo. Una enana roja muy pequeña,
una sólo lo bastante grande para mantener una débil fusión nuclear, puede
conseguir que su relativamente escaso suministro de combustible le dure 200 mil
millones de años en la secuencia principal. Esto significa que ninguna enana
roja ha abandonado nunca la secuencia principal. El Universo, simplemente, no
es lo bastante viejo para que alguna de ellas haya dejado de existir.



Vamos a establecer ahora un «Año de Enana roja», con lo que quiero decir 200
mil millones de años comprimidos en un solo año (lo cual nos da una cifra mayor
que toda la vida presente del Universo, mucho mayor), y veremos qué aspecto
tienen las estrellas desde este punto de observación. Cada Día de Enana Roja,
con este sistema, tendría una duración de 548.000.000 de años.





12. EL AÑO DE LA ENANA ROJA





Si pudiéramos imaginar que una enana roja tiene conciencia y observa el
Universo, ésta vería, más bien sardónicamente, que todos los grandes petardos,
van y vienen con rápidos destellos, mientras que ella y sus compañeras enanas
rojas arden constantemente en su forma apagada y tranquila.

Con seguridad, surgirían nuevos petardos, pero es del todo probable que las
enanas rojas continuarían brillando después de ellos también. En realidad,
cuando el gas y el polvo de esas diversas galaxias que poseen tales nubes
(muchas galaxias están exentas de polvo) hayan llegado a consumirse, y todas
las estrellas brillantes hayan pasado al estadio de gigante roja y se hayan
derrumbado y apagado, entonces el Universo brillará débilmente a la luz de las
únicas estrellas normales que queden, es decir, las enanas rojas.

Pero finalmente, si el Universo es abierto y se sigue expandiendo eternamente,
la última enana roja también se apagará. y no quedará absolutamente ninguna
estrella en su secuencia principal.





[1] Estoy resistiéndome al impulso de explicar las distintas unidades
eléctricas. Eso quedará para otro ensayo en otra ocasión.





[2] Nunca he negado dicho permiso. ¡Sería descortés!





[3] Adrastea es el nombre de una ninfa que cuidó a Zeus niño, junto con
Amaltea. Tebes era una niña que fue hija de un dios-río y, como ya han
adivinado ustedes, Zeus la vio una vez y lo que siguió era inevitable. Metis es
la más interesante de las tres, puesto que fue una titanesa, perteneciente a la
generación más antigua de deidades y que, según su nombre, personificaba la
sabiduría. Se la considera la primera esposa de Zeus, pero Zeus temió que
pudiese alumbrar a un hijo que le derrocase, igual que él había hecho con su
padre, Cronos. Por lo tanto, Zeus se tragó a Metis, que desde entonces le
aconsejó desde su estómago (una forma de conseguir educación). Nueve meses
después irrumpió Atenea por la cabeza de Júpiter, armada por completo y
profiriendo su grito de guerra.





[4] Los nombres de los satélites saturnianos figuran y se explican en
«Rolicall» en Of time and Space and Other things (Doubleday, 1965). Los nombres
de los satélites de los planetas más allá de Saturno se dan también allí con
una excepción





[5] Descartemos el caer o saltar de un acantilado, ser llevado por un tornado u
otros sucesos destructivos de este tipo.




This file was created


with BookDesigner program


bookdesigner@the-ebook.org


20/01/2009



Table of Contents

Isaac Asimov El monstruo subatómico

INTRODUCCIÓN

Primera parte FÍSICA I. EL MONSTRUO SUBATÓMICO

II. E PLURIBUS UNUM

III. LAS DOS MASAS

IV. EL GENERAL VICTORIOSO

Segunda parte ASTRONOMÍA V. ACTUALIZACIÓN DE LOS SATÉLITES

VI. EL BRAZO DEL GIGANTE

VII. EL MUNDO DEL SOL ROJO

VIII. EL AMOR HACE GIRAR EL MUNDO

Tercera parte QUÍMICA IX. LAS PROPIEDADES DEL CAOS

X. VERDE, VERDE, VERDE ES EL COLOR...

Cuarta parte BIOLOGÍA XI. MAS PENSAMIENTOS ACERCA DEL PENSAMIENTO

XII. VOLVIENDO AL PUNTO DE PARTIDA

Quinta Parte TECNOLOGÍA XIII. ¿QUÉ CAMIÓN?

XIV. DONDE TODO EL CIELO ES RESPLANDOR

50. FINAL

XV. ¡ARRIBA!

Sexta parte CRONOLOGÍA XVI. LOS DIFERENTES AÑOS DEL TIEMPO

1. AÑO DE ESTADOS UNIDOS

2. EL AÑO DE NORTEAMÉRICA

3. AÑO DE LA HISTORIA

4. EL AÑO DE LA CIVILIZACIÓN

5.EL AÑO HUMANO

6. EL AÑO HOMÍNIDO

7. EL AÑO FÓSIL

8. EL AÑO TERRESTRE

XVII. LOS DIFERENTES AÑOS DEL UNIVERSO

9. EL AÑO DEL UNIVERSO

10. AÑO DEL SISTEMA SOLAR

11. EL AÑO SOLAR

12. EL AÑO DE LA ENANA ROJA




